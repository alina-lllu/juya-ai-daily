<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:webfeeds="http://webfeeds.org/rss/1.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>橘鸦AI早报</title><link>https://imjuya.github.io/juya-ai-daily/</link><description>资讯内容由AI辅助生成，可能存在错误，请以原始信息出处和官方信息为准。</description><atom:link href="https://imjuya.github.io/juya-ai-daily/rss.xml" rel="self" type="application/rss+xml"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://imjuya.github.io/juya-ai-daily/icon.png</url><title>橘鸦AI早报</title><link>https://imjuya.github.io/juya-ai-daily/</link><width>144</width><height>144</height></image><language>zh-CN</language><lastBuildDate>Sat, 28 Feb 2026 01:00:18 +0000</lastBuildDate><itunes:image href="https://imjuya.github.io/juya-ai-daily/icon.png"/><webfeeds:icon>https://imjuya.github.io/juya-ai-daily/icon.png</webfeeds:icon><webfeeds:logo>https://imjuya.github.io/juya-ai-daily/icon.png</webfeeds:logo><item><title>2026-02-28</title><link>https://imjuya.github.io/juya-ai-daily/issue-11/</link><description>AI 早报 2026-02-28 视频版：哔哩哔哩 ｜ YouTube 概览 要闻 OpenAI完成1100亿美元融资并与亚马逊达成战略合作 ↗ #1 开发生态 Google Antigravity 恢复部分账户但重申禁用第三方工具 ↗ #2 Anthropic重置Claude Code用户速率限制 ↗ #3 谷歌将终止Gemini 3 Pro Preview服务 ↗ #4 行业动态 Anthropic与美国战争部因AI安全限制爆发冲突。 ↗ #5 OpenAI发布心理健康功能更新并回应诉讼合并 ↗ #6 七家科技巨头将签署AI数据中心用电协议 ↗ #7 前瞻与传闻 阿里千问AI眼镜将于MWC亮相并开启预约 #8 OpenAI完成1100亿美元融资并与亚马逊达成战略合作 #1 OpenAI完成总额1100亿美…</description><content:encoded><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260228/202602280838126724411110_cover_fe2e.png" alt=""></p>
<h1>AI 早报 2026-02-28</h1>
<p><strong>视频版</strong>：<a href="https://www.bilibili.com/video/BV1UPA4zLENA">哔哩哔哩</a> ｜ <a href="https://www.youtube.com/watch?v=b9y6XDxIGDk">YouTube</a></p>
<h2>概览</h2>
<h3>要闻</h3>
<ul>
<li>OpenAI完成1100亿美元融资并与亚马逊达成战略合作 <a href="https://openai.com/zh-Hans-CN/index/scaling-ai-for-everyone/">↗</a> <code>#1</code></li>
</ul>
<h3>开发生态</h3>
<ul>
<li>Google Antigravity 恢复部分账户但重申禁用第三方工具 <a href="https://x.com/antigravity/status/2027435365275967591">↗</a> <code>#2</code></li>
<li>Anthropic重置Claude Code用户速率限制 <a href="https://x.com/trq212/status/2027232172810416493">↗</a> <code>#3</code></li>
<li>谷歌将终止Gemini 3 Pro Preview服务 <a href="https://discuss.ai.google.dev/t/migrate-from-gemini-3-pro-preview-to-gemini-3-1-pro-preview-before-march-9-2026/127062">↗</a> <code>#4</code></li>
</ul>
<h3>行业动态</h3>
<ul>
<li>Anthropic与美国战争部因AI安全限制爆发冲突。 <a href="https://www.anthropic.com/news/statement-department-of-war">↗</a> <code>#5</code></li>
<li>OpenAI发布心理健康功能更新并回应诉讼合并 <a href="https://openai.com/index/update-on-mental-health-related-work/">↗</a> <code>#6</code></li>
<li>七家科技巨头将签署AI数据中心用电协议 <a href="https://www.foxnews.com/politics/scoop-trump-brings-big-tech-white-house-curb-power-costs-amid-ai-boom">↗</a> <code>#7</code></li>
</ul>
<h3>前瞻与传闻</h3>
<ul>
<li>阿里千问AI眼镜将于MWC亮相并开启预约 <code>#8</code></li>
</ul>
<hr>
<h2><a href="https://openai.com/zh-Hans-CN/index/scaling-ai-for-everyone/">OpenAI完成1100亿美元融资并与亚马逊达成战略合作</a> <code>#1</code></h2>
<blockquote>
<p><strong>OpenAI</strong>完成总额<strong>1100亿美元</strong>的新一轮融资，投前估值达<strong>7300亿美元</strong>，其中<strong>亚马逊</strong>注资<strong>500亿</strong>，<strong>英伟达</strong>与<strong>软银</strong>各注资<strong>300亿</strong>。伴随融资，<strong>OpenAI</strong>与<strong>亚马逊</strong>建立多年期战略合作伙伴关系，将<strong>OpenAI Frontier</strong>平台引入<strong>AWS</strong>，同时，<strong>OpenAI</strong>与<strong>AWS</strong>的算力协议扩大至<strong>1000亿美元</strong>，并在<strong>Amazon Bedrock</strong>上共同构建“有状态运行时环境”，帮助企业无需管理底层设施即可处理多步工作流和持久化记忆。而<strong>微软Azure</strong>继续保持对<strong>OpenAI</strong>无状态API的独家云服务权。此外，<strong>OpenAI</strong>深化了与<strong>英伟达</strong>的合作，将在<code>Vera Rubin</code>系统上使用共<strong>5吉瓦</strong>的专用推理与训练算力。</p>
</blockquote>
<p><strong>OpenAI</strong>完成总额<strong>1100亿美元</strong>的新一轮融资，投前估值达<strong>7300亿美元</strong>。本轮融资由<strong>亚马逊</strong>注资<strong>500亿美元</strong>，<strong>英伟达</strong>与<strong>软银</strong>各注资<strong>300亿美元</strong>。目前，<strong>ChatGPT</strong>周活跃用户已突破<strong>9亿</strong>，付费用户超<strong>5000万</strong>。本轮融资使<strong>OpenAI</strong>基金会在集团中所持股份价值增至<strong>1800亿美元</strong>以上。</p>
<p>伴随融资，<strong>OpenAI</strong>与<strong>亚马逊</strong>建立多年期战略合作，将<strong>OpenAI Frontier</strong>平台引入<strong>AWS</strong>，并共同开发“有状态运行时环境”。该环境将在<strong>Amazon Bedrock</strong>原生提供，专为持续性多步工作流设计，能建立持久化工作上下文，预计未来数月内上线。作为合作的一部分，<strong>AWS</strong>成为<strong>OpenAI Frontier</strong>的独家第三方云分发渠道。</p>
<p>双方同时将现有的<strong>380亿美元</strong>多年期算力协议扩大至<strong>1000亿美元</strong>，期限为8年。<strong>OpenAI</strong>承诺通过<strong>AWS</strong>基础设施消耗约<strong>2GW</strong>的<code>Trainium</code>算力，此协议涵盖至2027年交付的下一代<code>Trainium4</code>芯片。</p>
<p>此外，<strong>OpenAI</strong>深化了与<strong>英伟达</strong>的合作，将在<strong>Vera Rubin</strong>系统上使用共<strong>5GW</strong>的专用推理与训练算力。</p>
<p>值得注意的是，<strong>OpenAI</strong>与<strong>微软</strong>的合作伙伴关系保持不变，<strong>Azure</strong>仍是<strong>OpenAI</strong>无状态API的独家云服务商，所有相关调用（包括通过第三方）均托管于<strong>Azure</strong>，<strong>OpenAI</strong>的第一方产品也继续托管在<strong>Azure</strong>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/fe2e0c0c-3a73-4341-bce6-78045719b005/d12dd1ca-4c29-4fd8-a5d6-2c96a61df41e/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://openai.com/zh-Hans-CN/index/scaling-ai-for-everyone/">https://openai.com/zh-Hans-CN/index/scaling-ai-for-everyone/</a></li>
<li><a href="https://openai.com/zh-Hans-CN/index/amazon-partnership/">https://openai.com/zh-Hans-CN/index/amazon-partnership/</a></li>
<li><a href="https://www.aboutamazon.com/news/aws/amazon-open-ai-strategic-partnership-investment">https://www.aboutamazon.com/news/aws/amazon-open-ai-strategic-partnership-investment</a></li>
<li><a href="https://openai.com/zh-Hans-CN/index/introducing-the-stateful-runtime-environment-for-agents-in-amazon-bedrock/">https://openai.com/zh-Hans-CN/index/introducing-the-stateful-runtime-environment-for-agents-in-amazon-bedrock/</a></li>
<li><a href="https://openai.com/zh-Hans-CN/index/continuing-microsoft-partnership/">https://openai.com/zh-Hans-CN/index/continuing-microsoft-partnership/</a></li>
</ul>
<hr>
<h2><a href="https://x.com/antigravity/status/2027435365275967591">Google Antigravity 恢复部分账户但重申禁用第三方工具</a> <code>#2</code></h2>
<blockquote>
<p><strong>Google Antigravity</strong> 宣布正在恢复因使用第三方工具受限的账户权限，但明确指出使用第三方工具登录仍违反服务条款。官方建议，若需配合 <strong>Gemini</strong> 使用第三方编码 <code>Agent</code>，应转而使用 <code>Vertex</code> 或 <code>AI Studio</code> API 密钥。</p>
</blockquote>
<p>Google Antigravity 官方宣布，正在恢复此前因使用第三方工具受限的账户权限。官方重申，使用 <code>Claude Code</code>、<code>OpenClaw</code> 或 <code>OpenCode</code> 等第三方软件登录仍违反服务条款，可能导致账户被暂停或终止。对于有第三方编码 Agent 需求的用户，官方建议转用 <code>Vertex</code> 或 <code>AI Studio</code> API 密钥，并承诺未来将提供明确的恢复指导。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/fe2e0c0c-3a73-4341-bce6-78045719b005/59df8400-dc8b-4fd3-bb7c-cdf50f58054a/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/antigravity/status/2027435365275967591">https://x.com/antigravity/status/2027435365275967591</a></li>
<li><a href="https://antigravity.google/docs/faq#why-can%27t-i-use-third-party-software-eg-claude-code-openclaw-opencode-with-my-antigravity-login">https://antigravity.google/docs/faq#why-can't-i-use-third-party-software-eg-claude-code-openclaw-opencode-with-my-antigravity-login</a></li>
</ul>
<hr>
<h2><a href="https://x.com/trq212/status/2027232172810416493">Anthropic重置Claude Code用户速率限制</a> <code>#3</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 修复导致 <code>Claude Code</code> 额度异常消耗的 <code>Prompt Caching</code> Bug，并重置了所有用户的速率限制。</p>
</blockquote>
<p><strong>Anthropic</strong> 官方已重置所有 <strong>Claude Code</strong> 用户的 Rate Limits，以修复因 <code>Prompt Caching</code> 功能 Bug 导致的额度消耗过快问题。该故障已在 <code>2.1.62</code> 版本中通过热修复解决，官方建议用户立即执行 <code>claude update</code> 命令升级至最新版本，确保额度计算恢复正常。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/fe2e0c0c-3a73-4341-bce6-78045719b005/4542e1c0-3c02-4f2e-bb59-43e9821ba527/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/trq212/status/2027232172810416493">https://x.com/trq212/status/2027232172810416493</a></li>
</ul>
<hr>
<h2><a href="https://discuss.ai.google.dev/t/migrate-from-gemini-3-pro-preview-to-gemini-3-1-pro-preview-before-march-9-2026/127062">谷歌将终止Gemini 3 Pro Preview服务</a> <code>#4</code></h2>
<blockquote>
<p>Google宣布将于 <strong>2026年3月9日</strong> 正式停用 <strong>Gemini API</strong> 和 <strong>Google AI Studio</strong> 上的 <code>Gemini 3 Pro Preview</code> 模型。</p>
</blockquote>
<p>Google官方宣布，将于 <strong>2026年3月9日</strong> 正式停止 <code>Gemini API</code> 和 <code>Google AI Studio</code> 上的 <code>Gemini 3 Pro Preview</code> 模型服务，并建议开发者尽快迁移至 <code>Gemini 3.1 Pro Preview</code>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/fe2e0c0c-3a73-4341-bce6-78045719b005/dc115d83-9b8b-4ca3-bcca-fca8615757c4/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://discuss.ai.google.dev/t/migrate-from-gemini-3-pro-preview-to-gemini-3-1-pro-preview-before-march-9-2026/127062">https://discuss.ai.google.dev/t/migrate-from-gemini-3-pro-preview-to-gemini-3-1-pro-preview-before-march-9-2026/127062</a></li>
</ul>
<hr>
<h2><a href="https://www.anthropic.com/news/statement-department-of-war">Anthropic与美国战争部因AI安全限制爆发冲突。</a> <code>#5</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 因拒绝战争部关于解除大规模国内监控和完全自主武器的限制，被正式列为国家安全供应链风险。特朗普下令联邦机构将停用 <code>Anthropic</code> 相关技术。美战争部长发文称，禁止美军承包商与其合作。</p>
</blockquote>
<p><strong>Anthropic</strong>因拒绝解除针对“大规模国内监控”和“完全自主武器”的AI安全限制，与美国战争部爆发冲突。CEO <strong>Amodei</strong>声明，即便面临被列为供应链风险等威胁，公司绝不妥协。</p>
<p>战争部长<strong>Hegseth</strong>随后宣布，依据特朗普指令，正式将<strong>Anthropic</strong>列为国家安全供应链风险，禁止美军承包商与其合作，设<code>6个月</code>过渡期切换供应商。联邦机构将停用<strong>Anthropic</strong>相关技术。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/fe2e0c0c-3a73-4341-bce6-78045719b005/c9707e58-dcd0-4a8e-af2a-320e17e75896/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/fe2e0c0c-3a73-4341-bce6-78045719b005/c9707e58-dcd0-4a8e-af2a-320e17e75896/m002.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.anthropic.com/news/statement-department-of-war">https://www.anthropic.com/news/statement-department-of-war</a></li>
<li><a href="https://x.com/SecWar/status/2027507717469049070">https://x.com/SecWar/status/2027507717469049070</a></li>
</ul>
<hr>
<h2><a href="https://openai.com/index/update-on-mental-health-related-work/">OpenAI发布心理健康功能更新并回应诉讼合并</a> <code>#6</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 公布 <strong>ChatGPT</strong> 周活用户已超 <strong>9 亿</strong>，并即将推出“可信联系人”功能，允许成年用户指定联系人在其需额外支持时接收通知，同时正通过模拟长期对话的新评估方法增强 <code>model</code> 对情绪困扰的检测能力。</p>
</blockquote>
<p>OpenAI近期更新心理健康工作，官方数据显示 <strong>ChatGPT</strong> 周活用户已超 <strong>9亿</strong>。在 <strong>2025年9月</strong> 家长控制功能见效基础上，公司正与专家合作即将推出“可信联系人”功能，允许成年用户指定联系人在需支持时获通知；同时通过模拟长期对话的新评估方法，增强模型检测情绪困扰能力。针对加州法院合并审理多起相关诉讼，<strong>OpenAI</strong> 声明将秉持事实与尊重隐私原则应对，承诺在法律程序外继续改进技术，引导用户获取现实支持。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://openai.com/index/update-on-mental-health-related-work/">https://openai.com/index/update-on-mental-health-related-work/</a></li>
</ul>
<hr>
<h2><a href="https://www.foxnews.com/politics/scoop-trump-brings-big-tech-white-house-curb-power-costs-amid-ai-boom">七家科技巨头将签署AI数据中心用电协议</a> <code>#7</code></h2>
<blockquote>
<p>据报道，<strong>Amazon</strong>、<strong>Google</strong>、<strong>Microsoft</strong>以及<strong>OpenAI</strong>等七家科技巨头将于下月初齐聚白宫，签署“纳税人保护承诺”。这些企业将承诺为新建的<code>AI数据中心</code>自行建设、引进或购买电力，确保<code>AI</code>产业发展不会影响美国老旧电网运行，也不会推高普通民众的电费账单。</p>
</blockquote>
<p>据报道，<strong>Amazon</strong>、<strong>Google</strong>、<strong>Meta</strong>、<strong>Microsoft</strong>、<strong>xAI</strong>、<strong>Oracle</strong> 及 <strong>OpenAI</strong> 将于 <strong>3月4日</strong> 齐聚白宫，签署“纳税人保护承诺”。为应对老旧电网无法满足 <strong>AI</strong> 巨大电力需求的挑战，上述科技巨头承诺将为新建数据中心“建设、带来或购买”独立电力供应。此举旨在确保随着 <strong>AI</strong> 产业发展，美国普通民众的电费账单不会上涨，通过能源自主策略消除公众抵触情绪，解决基础设施瓶颈。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/fe2e0c0c-3a73-4341-bce6-78045719b005/0ebe132e-1671-4ad4-a3f9-472f2d725ca6/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.foxnews.com/politics/scoop-trump-brings-big-tech-white-house-curb-power-costs-amid-ai-boom">https://www.foxnews.com/politics/scoop-trump-brings-big-tech-white-house-curb-power-costs-amid-ai-boom</a></li>
<li><a href="https://www.cnbc.com/2026/02/25/trump-tech-ai-data-center-electricity-price-pledge.html">https://www.cnbc.com/2026/02/25/trump-tech-ai-data-center-electricity-price-pledge.html</a></li>
</ul>
<hr>
<h2>阿里千问AI眼镜将于MWC亮相并开启预约 <code>#8</code></h2>
<blockquote>
<p>阿里**“千问”<strong>宣布进军AI硬件领域，首款</strong>AI眼镜<strong>将在巴塞罗那</strong>MWC<strong>亮相并于</strong>3月初**开启全渠道预约，年内还将推出指环和耳机。</p>
</blockquote>
<p>阿里巴巴旗下<strong>千问</strong>宣布进军AI硬件，开启“软硬一体”战略。首款AI眼镜将于今年<strong>MWC</strong>亮相，<strong>3月初</strong>开启全渠道预约；年内还计划全球推出<strong>AI指环</strong>及<strong>AI耳机</strong>。此举旨在推动生成式AI进入“空间交互”阶段，利用传感器感知物理世界，将外卖、打车等服务无缝接入穿戴设备，构建AI时代第一入口。数据显示，<strong>千问App</strong>日活已突破<strong>7300万</strong>，春节期间单句指令下单量近<strong>2亿次</strong>。</p>
<hr>
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
]]></content:encoded><guid isPermaLink="false">https://github.com/imjuya/juya-ai-daily/issues/11</guid><pubDate>Sat, 28 Feb 2026 00:59:56 +0000</pubDate></item><item><title>2026-02-27</title><link>https://imjuya.github.io/juya-ai-daily/issue-10/</link><description>AI 早报 2026-02-27 视频版：哔哩哔哩 ｜ YouTube 概览 要闻 Google发布Nano Banana 2图像生成模型 ↗ #1 Claude Code推出跨会话记忆功能 ↗ #2 Google Translate 正式接入 Genimi ↗ #3 模型发布 QuiverAI推出SVG AI模型Arrow 1.0 ↗ #4 Perplexity开源pplx-embed系列文本嵌入模型 ↗ #5 纽约大学Solaris团队开源多人游戏世界模型 ↗ #6 开发生态 OpenAI推出Codex CLI 0.105.0更新 ↗ #7 Figma与Codex合作打通双向设计代码工作流 ↗ #8 Gemini CLI推出 v0.30.0更新 ↗ #9 Cursor 正式发布 Bugbot Autofi…</description><content:encoded><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260227/2026022708545369299532fb_cover_dca7.png" alt=""></p>
<h1>AI 早报 2026-02-27</h1>
<p><strong>视频版</strong>：<a href="https://www.bilibili.com/video/BV1KcA1zcEGQ">哔哩哔哩</a> ｜ <a href="https://www.youtube.com/watch?v=dNxKkc2A8O8">YouTube</a></p>
<h2>概览</h2>
<h3>要闻</h3>
<ul>
<li>Google发布Nano Banana 2图像生成模型 <a href="https://blog.google/innovation-and-ai/technology/ai/nano-banana-2/">↗</a> <code>#1</code></li>
<li>Claude Code推出跨会话记忆功能 <a href="https://x.com/trq212/status/2027109375765356723?s=61">↗</a> <code>#2</code></li>
<li>Google Translate 正式接入 Genimi <a href="https://blog.google/products-and-platforms/products/translate/translation-context-ai-update">↗</a> <code>#3</code></li>
</ul>
<h3>模型发布</h3>
<ul>
<li>QuiverAI推出SVG AI模型Arrow 1.0 <a href="https://app.quiver.ai">↗</a> <code>#4</code></li>
<li>Perplexity开源pplx-embed系列文本嵌入模型 <a href="https://research.perplexity.ai/articles/pplx-embed-state-of-the-art-embedding-models-for-web-scale-retrieval">↗</a> <code>#5</code></li>
<li>纽约大学Solaris团队开源多人游戏世界模型 <a href="https://github.com/solaris-wm/solaris">↗</a> <code>#6</code></li>
</ul>
<h3>开发生态</h3>
<ul>
<li>OpenAI推出Codex CLI 0.105.0更新 <a href="https://developers.openai.com/codex/changelog">↗</a> <code>#7</code></li>
<li>Figma与Codex合作打通双向设计代码工作流 <a href="https://www.figma.com/blog/introducing-codex-to-figma/">↗</a> <code>#8</code></li>
<li>Gemini CLI推出 v0.30.0更新 <a href="https://x.com/geminicli/status/2027137538545045876">↗</a> <code>#9</code></li>
<li>Cursor 正式发布 Bugbot Autofix <a href="https://cursor.com/cn/blog/bugbot-autofix">↗</a> <code>#10</code></li>
<li>Anthropic 推出开源开发者支持计划 <a href="https://claude.com/contact-sales/claude-for-oss">↗</a> <code>#11</code></li>
</ul>
<h3>产品应用</h3>
<ul>
<li>OpenAI为ChatGPT推出文件保存功能Library <a href="https://help.openai.com/en/articles/20001052-library-for-chatgpt">↗</a> <code>#12</code></li>
<li>Claude免费用户获享Connectors功能 <a href="https://x.com/claudeai/status/2027082240833052741">↗</a> <code>#13</code></li>
<li>微软推出Copilot Tasks研究预览版 <a href="https://x.com/mustafasuleyman/status/2027111503003107377">↗</a> <code>#14</code></li>
<li>Google Stitch官方上线Direct Edits功能 <a href="https://x.com/stitchbygoogle/status/2027082165490794824">↗</a> <code>#15</code></li>
</ul>
<h3>技术与洞察</h3>
<ul>
<li>DeepSeek携手清北发布DualPath推理系统 <a href="https://arxiv.org/abs/2602.21548">↗</a> <code>#16</code></li>
<li>Andrej Karpathy称AI编程Agent已实现颠覆性突破 <a href="https://x.com/karpathy/status/2026731645169185220">↗</a> <code>#17</code></li>
</ul>
<h3>行业动态</h3>
<ul>
<li>AMD投资25亿美元与Nutanix共建全栈AI平台 <a href="https://www.amd.com/en/newsroom/press-releases/2026-2-25-amd-and-nutanix-announce-strategic-partnership-to.html">↗</a> <code>#18</code></li>
<li>Intrinsic并入Google加速Physical AI发展 <a href="https://blog.google/alphabet/intrinsic-joins-google/">↗</a> <code>#19</code></li>
<li>OpenAI接连挖走Meta两位核心技术高管 <a href="https://zhidx.com/p/536431.html">↗</a> <code>#20</code></li>
</ul>
<h3>前瞻与传闻</h3>
<ul>
<li>DeepSeek据传正测试V4新模型并向华为授权 <code>#21</code></li>
<li>亚马逊据传将向OpenAI投资高达500亿美元 <a href="https://thein.fo/3OLENvI">↗</a> <code>#22</code></li>
<li>据传谷歌与Meta签署数十亿美元AI芯片协议 <a href="https://thein.fo/4r4VIqL">↗</a> <code>#23</code></li>
<li>GPT-5.3被曝或已上线Arena <a href="https://x.com/synthwavedd/status/2026800988401574068">↗</a> <code>#24</code></li>
<li>传Meta两款AI模型亮相测试平台 <a href="https://x.com/AILeaksAndNews/status/2027041400718848315">↗</a> <code>#25</code></li>
</ul>
<hr>
<h2><a href="https://blog.google/innovation-and-ai/technology/ai/nano-banana-2/">Google发布Nano Banana 2图像生成模型</a> <code>#1</code></h2>
<blockquote>
<p>Google正式发布图像生成模型<strong>Nano Banana 2</strong>，该模型结合了Pro版的高智能与Flash版的高速度，目前以<strong>1279分</strong>位列<strong>Image Arena</strong>榜首。它具备精准的文本渲染及多角色一致性生成能力，现已全面集成至<strong>Gemini</strong>应用、<strong>Google</strong>搜索及<strong>Vertex AI</strong>等产品中，并成为默认图像生成模型。开发者可立即通过API接入使用，其成本相比Pro版下降约<strong>50%</strong>。在<strong>Gemini</strong>应用中，<strong>Nano Banana 2</strong>接入了所有模型选项，付费订阅用户可以通过菜单重新生成图像，使用 <strong>Nano Banana Pro</strong> 进行生成。</p>
</blockquote>
<p>Google正式发布最新图像生成与编辑模型<strong>Nano Banana 2</strong>（<code>Gemini 3.1 Flash Image</code>）。该模型融合了<strong>Nano Banana Pro</strong>的高级智能与<code>Gemini Flash</code>的处理速度，旨在兼顾高质量与高效率。它集成了<code>Gemini</code>的真实世界知识库，支持通过实时网络搜索优化生成结果。其核心升级包括更精准的文本渲染与翻译能力，以及显著提升的主体一致性，支持在单次生成中维持最多5个角色和14个物体的特征。</p>
<p>在性能表现上，据Arena.ai数据显示，<strong>Nano Banana 2</strong>以<strong>1279分</strong>在Image Arena排名中位列第一。官方基准测试也显示其大幅优于<strong>GPT-Image 1.5</strong>、<strong>Seedream 5.0 Lite</strong>等模型。</p>
<p>在可用性与定价方面，<strong>Nano Banana 2</strong>现已集成至<strong>Gemini App</strong>、<strong>Google搜索</strong>、<strong>Vertex AI</strong>等全线产品，同时，其API成本相比<strong>Pro</strong>版显著降低，其中1K图像价格降幅约为<strong>50%</strong>。在<strong>Gemini</strong>应用中，<strong>Nano Banana 2</strong>成为了所有选项的默认图像生成模型，付费订阅用户可以通过菜单重新生成图像，使用 <strong>Nano Banana Pro</strong> 进行生成。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/f9d54594-02ce-45a9-a9dd-c702b9ea4882/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/f9d54594-02ce-45a9-a9dd-c702b9ea4882/m002.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/f9d54594-02ce-45a9-a9dd-c702b9ea4882/m003.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/f9d54594-02ce-45a9-a9dd-c702b9ea4882/m004.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/f9d54594-02ce-45a9-a9dd-c702b9ea4882/m005.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/innovation-and-ai/technology/ai/nano-banana-2/">https://blog.google/innovation-and-ai/technology/ai/nano-banana-2/</a></li>
<li><a href="https://blog.google/innovation-and-ai/technology/developers-tools/build-with-nano-banana-2/">https://blog.google/innovation-and-ai/technology/developers-tools/build-with-nano-banana-2/</a></li>
</ul>
<hr>
<h2><a href="https://x.com/trq212/status/2027109375765356723?s=61">Claude Code推出跨会话记忆功能</a> <code>#2</code></h2>
<blockquote>
<p><strong>Claude Code</strong> 已全面推出 <strong>Auto memory</strong> 功能，允许模型跨会话自动记忆项目上下文和用户偏好，并通过 <code>MEMORY.md</code> 文件实现持久化。该系统建立了包含组织、项目及用户级的层级化管理架构，用户可直接使用 <code>memory</code> 斜杠命令交互式管理记忆。</p>
</blockquote>
<p><strong>Claude Code</strong>现已全面推出<strong>Auto memory</strong>功能，旨在跨会话自动记忆项目上下文及用户偏好。该功能默认开启，通过在特定目录生成<code>MEMORY.md</code>作为<strong>Claude</strong>维护的持久化笔记，启动时自动加载前200行。系统构建了包含组织级、项目级、用户级及本地设置的分层记忆管理体系，并支持通过<code>.claude/rules/</code>目录及<code>@path</code>语法实现模块化规则配置。用户可利用<code>/memory</code>命令交互管理，或通过配置文件及环境变量精确控制功能启用状态。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/09ea6e64-5ded-4cbb-8a72-aa6d927edf62/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/trq212/status/2027109375765356723?s=61">https://x.com/trq212/status/2027109375765356723?s=61</a></li>
</ul>
<hr>
<h2><a href="https://blog.google/products-and-platforms/products/translate/translation-context-ai-update">Google Translate 正式接入 Genimi</a> <code>#3</code></h2>
<blockquote>
<p>Google Translate 正式接入 <code>Gemini</code> 大模型，推出了“替代选项”、“Understand”和“Ask”三项新功能，旨在帮助用户在从日常闲聊到专业会议的各种场景中精准把握语气与语境。目前该功能已在美国和印度地区的移动端应用上线，即将支持网页版。</p>
</blockquote>
<p>Google 官方宣布 <strong>Google Translate</strong> 引入由 <code>Gemini</code> 驱动的全新 AI 功能，旨在帮助用户在各类场景中精准把握语气与语境。此次更新新增三项核心功能：为习语和口语提供多样化表达变体的“替代选项”、展示翻译概览的“Understand”按钮，以及允许针对特定国家及方言进行交互式提问的“Ask”按钮。</p>
<p>目前，该新体验已在<strong>美国</strong>和<strong>印度</strong>地区的 <strong>Translate</strong> 应用（Android 和 iOS）上线，并即将支持 Web 端。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/b0094b0c-6e67-47be-9583-1faf8548a900/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/products-and-platforms/products/translate/translation-context-ai-update">https://blog.google/products-and-platforms/products/translate/translation-context-ai-update</a></li>
</ul>
<hr>
<h2><a href="https://app.quiver.ai">QuiverAI推出SVG AI模型Arrow 1.0</a> <code>#4</code></h2>
<blockquote>
<p><strong>QuiverAI</strong>发布了首款SVG AI模型<code>Arrow 1.0</code>并开启公测，它能将文本或图像转化为高细节的矢量图，效果十分惊艳。该公司同步宣布完成了<strong>830万美元</strong>的种子轮融资，由<strong>a16z</strong>领投。</p>
</blockquote>
<p><strong>QuiverAI</strong> 宣布推出 <code>Arrow 1.0</code> 模型测试版，官方称其为“首款 SVG AI 模型”，支持从图像和文本输入生成 SVG，旨在将用户创意转化为图形。公司创始人 <strong>Joan Rodriguez</strong> 同时透露，这家专注于前沿矢量设计的公司已完成 <strong>830 万美元</strong> 种子轮融资，本轮融资由 <strong>a16z</strong> 领投。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/ea7301a4-6934-4eab-9183-1e381a6cb9e4/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/ea7301a4-6934-4eab-9183-1e381a6cb9e4/m002.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/ea7301a4-6934-4eab-9183-1e381a6cb9e4/m003.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://app.quiver.ai">https://app.quiver.ai</a></li>
<li><a href="https://x.com/QuiverAI/status/2026792057893708072">https://x.com/QuiverAI/status/2026792057893708072</a></li>
</ul>
<hr>
<h2><a href="https://research.perplexity.ai/articles/pplx-embed-state-of-the-art-embedding-models-for-web-scale-retrieval">Perplexity开源pplx-embed系列文本嵌入模型</a> <code>#5</code></h2>
<blockquote>
<p>Perplexity发布并开源了基于 <code>Qwen3</code> 的 <code>pplx-embed</code> 系列SOTA文本Embedding模型，包含针对独立文本和RAG上下文优化的两个版本。</p>
</blockquote>
<p>Perplexity 正式发布了 <strong>pplx-embed</strong> 系列文本 Embedding 模型，旨在优化网络级检索任务。该系列包含针对独立文本优化的 <code>pplx-embed-v1</code>，以及专为RAG系统中上下文文档块设计的 <code>pplx-embed-context-v1</code>。两款模型均基于 <strong>Qwen3</strong> 架构并采用扩散预训练技术，提供 <strong>0.6B</strong>（1024维）和 <strong>4B</strong>（2560维）两种参数规格，支持 <strong>32K</strong> 上下文长度及MRL。据官方介绍，这些模型已在千万级文档的真实搜索场景中得到验证，并以MIT协议在Hugging Face开源。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/c7ebf9f3-3cfb-4505-b1eb-7926f3855a09/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://research.perplexity.ai/articles/pplx-embed-state-of-the-art-embedding-models-for-web-scale-retrieval">https://research.perplexity.ai/articles/pplx-embed-state-of-the-art-embedding-models-for-web-scale-retrieval</a></li>
<li><a href="https://huggingface.co/collections/perplexity-ai/pplx-embed">https://huggingface.co/collections/perplexity-ai/pplx-embed</a></li>
</ul>
<hr>
<h2><a href="https://github.com/solaris-wm/solaris">纽约大学Solaris团队开源多人游戏世界模型</a> <code>#6</code></h2>
<blockquote>
<p>纽约大学团队发布了首个针对《我的世界》的多人视频世界模型 <code>Solaris</code>，它能基于共享全局状态，同时为两名玩家生成视角一致的第一人称视频。</p>
</blockquote>
<p>纽约大学团队发布首个《我的世界》多人视频世界模型 <strong>Solaris</strong>，能基于全局状态生成双玩家视角一致的第一人称视频。发布包含自研数据引擎 <strong>SolarisEngine</strong>、基于 <code>DiT</code> 架构经 <strong>1260万帧</strong> 数据训练的模型及 <strong>Solaris Eval</strong> 评估基准。为解决长视野生成中的显存瓶颈，团队引入了“Checkpointed Self Forcing”技术。实验显示其在一致性与复杂任务上优于基线。项目已在 <strong>GitHub</strong> 和 <strong>Hugging Face</strong> 开源，代码基于 <code>JAX</code> 实现。推理需显存至少 <strong>48GB</strong> 的 GPU。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/e265c5d5-b524-46c6-a555-ca022db13597/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/solaris-wm/solaris">https://github.com/solaris-wm/solaris</a></li>
<li><a href="https://solaris-wm.github.io/">https://solaris-wm.github.io/</a></li>
<li><a href="https://huggingface.co/nyu-visionx/solaris">https://huggingface.co/nyu-visionx/solaris</a></li>
</ul>
<hr>
<h2><a href="https://developers.openai.com/codex/changelog">OpenAI推出Codex CLI 0.105.0更新</a> <code>#7</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 发布了 <code>Codex CLI</code> 更新，重点升级了终端交互体验与多智能体协作能力。用户现在可以在终端内按住空格键直接进行语音指令输入，并能通过 <code>CSV</code> 文件批量生成子代理来执行大规模任务。此外，新版本还新增了代码语法高亮、实时主题切换以及更灵活的审批控制机制，显著提升了开发效率。</p>
</blockquote>
<p><strong>OpenAI</strong> 发布 <strong>Codex CLI</strong> <code>0.105.0</code> 版本，重点优化终端界面、多代理工作流及系统稳定性。<strong>TUI</strong> 新增代码块与 diff 语法高亮、<code>/theme</code> 主题选择器及实验性语音听写功能；多代理工作流支持从 CSV 批量生成子代理并显示进度。新增 <code>/copy</code> 命令，改进审批控制与沙箱权限，修复 WebSocket、Linux 沙箱及 <code>js_repl</code> 等底层问题。部分社区用户将此称为 <strong>Codex</strong> 迄今最大更新，并讨论了子代理深度定制等能力。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/7e407f9a-aa65-46a3-af44-9d3e2088ffc2/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/20260227/20260227083920_3a4cf3dcc8.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://developers.openai.com/codex/changelog">https://developers.openai.com/codex/changelog</a></li>
<li><a href="https://github.com/openai/codex/releases">https://github.com/openai/codex/releases</a></li>
</ul>
<hr>
<h2><a href="https://www.figma.com/blog/introducing-codex-to-figma/">Figma与Codex合作打通双向设计代码工作流</a> <code>#8</code></h2>
<blockquote>
<p><strong>Figma</strong> 宣布与 <strong>OpenAI</strong> <strong>Codex</strong> 深度集成，通过 <code>Figma MCP server</code> 打通了设计画布与代码环境的双向工作流。</p>
</blockquote>
<p><strong>Figma</strong> 官方宣布，即日起通过 <strong>Figma MCP server</strong> 与 <strong>OpenAI Codex</strong> 深度集成，打通代码与设计画布的双向工作流。开发者现可在 Codex 桌面应用中利用 <code>get_design_context</code> 工具提取 Figma 文件的布局与样式信息生成代码；同时可通过 <code>generate_figma_design</code> 工具，将实时运行的应用界面自动转换为可编辑的 Figma Design 文件。此次集成实现了“代码-画布-代码”的完整闭环，支持设计变更无损同步回代码环境，用户可在 Codex 中直接安装该服务器以实现无缝迭代与协作。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/d559f68e-d8ee-4649-b68b-212bb290f58d/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.figma.com/blog/introducing-codex-to-figma/">https://www.figma.com/blog/introducing-codex-to-figma/</a></li>
<li><a href="https://developers.openai.com/blog/building-frontend-uis-with-codex-and-figma">https://developers.openai.com/blog/building-frontend-uis-with-codex-and-figma</a></li>
</ul>
<hr>
<h2><a href="https://x.com/geminicli/status/2027137538545045876">Gemini CLI推出 v0.30.0更新</a> <code>#9</code></h2>
<blockquote>
<p><strong>Gemini CLI</strong> 发布 <code>v0.30.0</code> 版本，已向所有使用 <strong>Gemini 3</strong> 的用户推送最新的 <code>3.1 Pro</code> 模型。此次更新实现了跨平台及工作区外的文件拖拽上传等交互体验优化功能。</p>
</blockquote>
<p>Gemini CLI 发布 <strong>v0.30.0</strong> 版本更新，核心模型升级至 <code>Gemini 3.1 Pro</code>，并将 <code>Gemini 3</code> 设为默认家族，预计未来几天向所有用户完成推送。此次更新优化了交互体验，支持跨平台及工作区外文件拖拽上传，增设权限确认，并为 Posix 用户提供了挂起与恢复功能，同时允许开启模型思考气泡完整模式。</p>
<p>生态扩展方面，新增 <code>Neo4J</code> 和 <code>Atlassian MCP</code> 扩展，支持自然语言查询与自动化。系统配置上，聊天会话默认保留期设为 <strong>30</strong> 天，实验性 Plan Mode 引入了 <strong>5</strong> 阶段顺序规划工作流。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/geminicli/status/2027137538545045876">https://x.com/geminicli/status/2027137538545045876</a></li>
</ul>
<hr>
<h2><a href="https://cursor.com/cn/blog/bugbot-autofix">Cursor 正式发布 Bugbot Autofix</a> <code>#10</code></h2>
<blockquote>
<p>Cursor 宣布正式向所有用户开放代码评审 Agent <strong>“Bugbot”</strong> 的 <strong>“Autofix”</strong> 功能。该功能可实现在 <code>Pull Request</code> 中自动发现并修复问题的闭环。</p>
</blockquote>
<p>Cursor 官方宣布，其代码评审 Agent “<strong>Bugbot</strong>” 的 “<strong>Bugbot Autofix</strong>” 功能已结束 beta 测试，正式向所有用户开放。该功能通过在独立虚拟机中启动云端 Agent 运行测试，实现了在 Pull Request 中自动发现并修复问题的闭环。</p>
<p>据官方数据，<strong>Bugbot</strong> 解决率已从 <strong>52%</strong> 提升至 <strong>76%</strong>，单次运行识别问题数量几乎翻倍，超 <strong>35%</strong> 的 <strong>Autofix</strong> 修改被合并。Cursor 团队未来将致力于实现自定义自动化工作流及持续代码库扫描。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/6613126a-e761-485f-8ff2-fbbf318fea70/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://cursor.com/cn/blog/bugbot-autofix">https://cursor.com/cn/blog/bugbot-autofix</a></li>
<li><a href="https://x.com/ericzakariasson/status/2027083181300830222">https://x.com/ericzakariasson/status/2027083181300830222</a></li>
</ul>
<hr>
<h2><a href="https://claude.com/contact-sales/claude-for-oss">Anthropic 推出开源开发者支持计划</a> <code>#11</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 启动“<strong>Claude for Open Source</strong>”计划，向符合资格的开源项目维护者及核心贡献者提供为期<strong>6个月</strong>的免费<strong>Claude Max</strong> <strong>20x</strong>使用权。名额上限为<strong>一万人</strong>。</p>
</blockquote>
<p>Anthropic正式推出**“Claude for Open Source”<strong>计划，旨在支持开源社区。该计划向符合资格的项目维护者及核心贡献者提供为期6个月的免费</strong>Claude Max** 20x使用权。申请标准主要面向拥有<strong>5,000</strong>以上<strong>GitHub Stars</strong>或月<strong>NPM</strong>下载量超<strong>100万</strong>的公共仓库活跃维护者；维护关键生态依赖但未达标者亦可申请。名额上限为<strong>10,000</strong>人，官方将滚动审核并通过邮件发送激活链接。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/d2742ef4-7954-437e-b634-e46199ff4946/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://claude.com/contact-sales/claude-for-oss">https://claude.com/contact-sales/claude-for-oss</a></li>
<li><a href="https://x.com/lydiahallie/status/2027129030571634721">https://x.com/lydiahallie/status/2027129030571634721</a></li>
</ul>
<hr>
<h2><a href="https://help.openai.com/en/articles/20001052-library-for-chatgpt">OpenAI为ChatGPT推出文件保存功能Library</a> <code>#12</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 正在为 <strong>ChatGPT</strong> 推出“Library”功能，可自动保存用户上传的文档、表格和图像等文件，并支持在不同对话间复用。</p>
</blockquote>
<p>OpenAI正在为 <strong>ChatGPT</strong> 推出“Library”功能，旨在自动保存用户上传的文档、图像等文件以便复用。用户可通过侧边栏或描述查找文件，并在新对话中通过“Add from library”选项添加。该功能支持手动管理，删除对话不连带删除文件，但不适用于 <strong>Temporary Chat</strong> 及 <strong>Health</strong> 模式。存储限制方面，通用文件上限 <strong>512MB</strong>，个人和组织用户分别享有 <strong>10GB</strong> 与 <strong>100GB</strong> 配额。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/8fc8f9f1-e740-4d0a-8d8f-f6cae147dc9a/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://help.openai.com/en/articles/20001052-library-for-chatgpt">https://help.openai.com/en/articles/20001052-library-for-chatgpt</a></li>
</ul>
<hr>
<h2><a href="https://x.com/claudeai/status/2027082240833052741">Claude免费用户获享Connectors功能</a> <code>#13</code></h2>
<blockquote>
<p><strong>Claude</strong>官方宣布，<strong>Connectors</strong>功能现已面向免费用户开放，可连接涵盖编程、设计及财务等领域的<strong>150多个</strong>第三方工具。</p>
</blockquote>
<p>Claude官方宣布，<strong>Connectors</strong>功能现已正式向免费计划用户开放。该功能支持接入涵盖编程、数据、设计、财务及销售等多个领域的<strong>150多个工具</strong>，旨在实现<strong>Claude</strong>与外部工作环境的交互。具体应用包括起草<code>Slack</code>消息、生成<code>Figma</code>图表及管理<code>Asana</code>时间线。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/8896d7e6-553f-415e-af2c-7a715e3a7eb4/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/claudeai/status/2027082240833052741">https://x.com/claudeai/status/2027082240833052741</a></li>
</ul>
<hr>
<h2><a href="https://x.com/mustafasuleyman/status/2027111503003107377">微软推出Copilot Tasks研究预览版</a> <code>#14</code></h2>
<blockquote>
<p>微软 <strong>Copilot</strong> 公布了新功能 <strong>Copilot Tasks</strong>，旨在推动 <strong>AI</strong> 从“对话”转向“执行”。用户无需编程，只需描述需求，系统即可自动处理任务。已开放候补名单。</p>
</blockquote>
<p>微软 <strong>Copilot</strong> 公布了新功能 <strong>Copilot Tasks</strong>，旨在推动 <strong>AI</strong> 从“对话”转向“执行”，核心理念为“少说话、多做事”。用户无需复杂设置或编程技能，仅通过描述任务，<strong>Copilot</strong> 即可自动处理。官方列举了三大应用场景：能将教学大纲转化为含模拟考试的学习计划；每周追踪房源并预约看房；每晚筛选紧急邮件并起草回复，同时自动退订促销邮件。目前，可申请加入候补名单等待体验该功能。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/bf172ce0-2fa5-4afd-a595-2ef6d00fda18/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/mustafasuleyman/status/2027111503003107377">https://x.com/mustafasuleyman/status/2027111503003107377</a></li>
</ul>
<hr>
<h2><a href="https://x.com/stitchbygoogle/status/2027082165490794824">Google Stitch官方上线Direct Edits功能</a> <code>#15</code></h2>
<blockquote>
<p>Google设计工具 <strong>Stitch</strong> 正式上线 <strong>Direct Edits</strong> 功能，用户现可直接在工具内部手动修改文本或图片，也能选中组件提示 <code>Gemini</code> 进行迭代更新，无需切换环境即可高效完成设计成品的最终润色。</p>
</blockquote>
<p>Google 旗下设计工具 <strong>Stitch</strong> 官方宣布上线 <strong>“Direct Edits”</strong> 功能，旨在解决设计生成后的细节微调痛点。针对现有 <strong>“Vibe Design”</strong> 模式虽能快速探索创意但难以进行修正错别字或替换图片等细微操作的问题，新功能支持用户直接在 <strong>Stitch</strong> 内部手动编辑，或选中特定组件指示 <code>Gemini</code> 生成更新版本。这种结合手动微调与 AI 辅助的方式，实现了从创意生成到细节完善的高效闭环。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/fdec840a-a8c4-4be4-9300-8c84780d8d36/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/stitchbygoogle/status/2027082165490794824">https://x.com/stitchbygoogle/status/2027082165490794824</a></li>
</ul>
<hr>
<h2><a href="https://arxiv.org/abs/2602.21548">DeepSeek携手清北发布DualPath推理系统</a> <code>#16</code></h2>
<blockquote>
<p><strong>DeepSeek</strong> 联合<strong>清华</strong>、<strong>北大</strong>发布论文，介绍了 <code>DualPath</code> 推理系统。该系统创新性地引入双路径 KV-Cache 加载机制，利用闲置的 Decode 引擎带宽，解决了 Agentic LLM 在多轮长上下文推理中的存储 I/O 瓶颈。在生产测试中，该系统吞吐量获得接近<strong>2倍</strong>的提升。</p>
</blockquote>
<p><strong>DeepSeek</strong> 联合<strong>清华大学</strong>与<strong>北京大学</strong>推出 <strong>DualPath</strong> 推理系统，旨在解决 Agentic <code>LLM</code> 多轮长上下文推理中的存储 I/O 瓶颈。该系统创新采用双路径 KV-Cache 加载机制，在保留传统存储路径的同时，利用闲置 Decode 引擎带宽经 <code>RDMA</code> 回传数据，并配合以网卡为中心的流量管理及全局动态调度策略。实验数据显示，在 <strong>DeepSeek-V3.2</strong> 等模型的生产负载测试中，<strong>DualPath</strong> 将离线推理吞吐量最高提升 <strong>1.87</strong> 倍，在线服务吞吐量平均提升 <strong>1.96</strong> 倍，且未违反 SLO，在千卡规模下具备近线性扩展能力。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/cf8fb0c0-8e18-413f-bdef-e84c7d9e8f94/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://arxiv.org/abs/2602.21548">https://arxiv.org/abs/2602.21548</a></li>
</ul>
<hr>
<h2><a href="https://x.com/karpathy/status/2026731645169185220">Andrej Karpathy称AI编程Agent已实现颠覆性突破</a> <code>#17</code></h2>
<blockquote>
<p>AI 专家 <strong>Andrej Karpathy</strong> 指出，自去年 <strong>12月</strong> 起，<code>Coding Agent</code> 的能力迎来拐点，已能自主解决复杂的长时任务，编程形态已发生根本改变，开发者需转向“Agentic Engineering”，将核心工作从代码执行转变为用英语管理 <code>Agent</code> 并验证结果。</p>
</blockquote>
<p>AI专家 <strong>Andrej Karpathy</strong> 指出，自去年 <strong>12月</strong> 起，<strong>Coding Agent</strong> 因模型质量与韧性提升迎来拐点，已具备处理复杂长时任务的能力。他以实战为例，仅通过英语指令，<strong>Agent</strong> 在约 <strong>30分钟</strong> 内自主完成了部署 <code>vLLM</code>、测试 <code>Qwen3-VL</code> 及构建 Web UI 等任务，将原本需耗费整个周末的工作自动化。</p>
<p>Karpathy 强调，编程正从“键入代码”转变为“管理 Agent”，未来核心在于通过 <code>Agentic Engineering</code> 构建 Orchestrator 管理并行实例。尽管技术尚不完美，仍需人工指导，但开发者核心任务已从“执行”转向“验证”，理解能力无法被外包。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/karpathy/status/2026731645169185220">https://x.com/karpathy/status/2026731645169185220</a></li>
</ul>
<hr>
<h2><a href="https://www.amd.com/en/newsroom/press-releases/2026-2-25-amd-and-nutanix-announce-strategic-partnership-to.html">AMD投资25亿美元与Nutanix共建全栈AI平台</a> <code>#18</code></h2>
<blockquote>
<p><strong>AMD</strong> 与云计算公司 <strong>Nutanix</strong> 达成多年战略合作，<strong>AMD</strong> 将总计投入 <strong>2.5 亿美元</strong>，于今年第二季度完成对 <strong>Nutanix</strong> 的股权投资，结合双方软硬件优势共同打造支持智能体 <code>AI</code> 的全栈式开放基础设施平台。</p>
</blockquote>
<p><strong>AMD</strong>与云计算公司<strong>Nutanix</strong>宣布达成多年战略合作，共同开发开放全栈<strong>AI</strong>基础设施平台。<strong>AMD</strong>将总计投资<strong>2.5亿美元</strong>，含以每股<strong>36.26美元</strong>收购<strong>1.5亿美元****Nutanix</strong>普通股（预计<strong>2026年Q2</strong>完成）及最高<strong>1亿美元</strong>研发推广资金。双方将整合<strong>AMD</strong>软硬件技术与<strong>Nutanix</strong>云平台，首批智能体<strong>AI</strong>平台预计<strong>2026年底</strong>上市。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/40426080-4bd1-4aaa-9080-1653d92da5eb/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.amd.com/en/newsroom/press-releases/2026-2-25-amd-and-nutanix-announce-strategic-partnership-to.html">https://www.amd.com/en/newsroom/press-releases/2026-2-25-amd-and-nutanix-announce-strategic-partnership-to.html</a></li>
</ul>
<hr>
<h2><a href="https://blog.google/alphabet/intrinsic-joins-google/">Intrinsic并入Google加速Physical AI发展</a> <code>#19</code></h2>
<blockquote>
<p><strong>Alphabet</strong> 旗下的机器人软件子公司 <strong>Intrinsic</strong> 正式并入 <strong>Google</strong>，将依托 <code>Gemini</code> 模型与 <strong>DeepMind</strong> 资源加速物理 AI 的发展。</p>
</blockquote>
<p><strong>Alphabet</strong> 旗下 <strong>Intrinsic</strong> 正式并入 <strong>Google</strong>，旨在利用其前沿 <strong>AI</strong> 资源加速 <code>Physical AI</code>（物理 AI）发展。<strong>Intrinsic</strong> 成立于 <strong>2021</strong> 年，致力于通过 <code>Flowstate</code> 平台降低工业机器人应用的开发门槛，执行如组装服务器、搬运 <strong>EV</strong> 电池等现实任务。</p>
<p>据媒体报道，<strong>Intrinsic</strong> 加入后将保持独立运营，并接入 <code>Gemini</code> 模型与 <strong>Google DeepMind</strong> 深度协作。其客户涵盖小型车间至 <strong>Foxconn</strong> 等巨头，计划于 <strong>2025</strong> 年底发布 <code>Vision AI</code> 模型。行业观察认为，此举是 <strong>Google</strong> 应对具身智能领域竞争的关键布局。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/bf0adeb5-0950-419c-b974-79419329463f/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/alphabet/intrinsic-joins-google/">https://blog.google/alphabet/intrinsic-joins-google/</a></li>
</ul>
<hr>
<h2><a href="https://zhidx.com/p/536431.html">OpenAI接连挖走Meta两位核心技术高管</a> <code>#20</code></h2>
<blockquote>
<p>OpenAI证实已从<strong>Meta</strong>超级智能实验室挖走两位核心大将，分别是前苹果基础模型负责人<strong>庞若鸣</strong>与<code>SAM 3</code>模型主导者<strong>张鹏川</strong>。</p>
</blockquote>
<p>OpenAI近期接连从<strong>Meta</strong>挖走两位核心华人AI研究员。据外媒报道，<strong>OpenAI</strong>证实前苹果AI负责人<strong>庞若鸣</strong>已于上周入职。<strong>庞若鸣</strong>于<strong>2025年7月</strong>以约<strong>2亿美元</strong>年薪加入<strong>Meta</strong>超级智能实验室负责基础设施。同时，<strong>Meta</strong>研究科学家<strong>张鹏川</strong>宣布将加入<strong>OpenAI</strong>，从事世界模型及机器人研究。<strong>张鹏川</strong>曾主导<code>SAM 3</code>及<code>Llama</code>视觉模块开发。两人均来自<strong>Meta</strong> <strong>2025年7月</strong>成立的超级智能实验室，该实验室近期面临人才流失，另有多名高管离职。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://zhidx.com/p/536431.html">https://zhidx.com/p/536431.html</a></li>
</ul>
<hr>
<h2>DeepSeek据传正测试V4新模型并向华为授权 <code>#21</code></h2>
<blockquote>
<p>据报道，<strong>DeepSeek</strong>正在内测代号为<code>V4 Lite</code>的新模型，并已向<strong>华为</strong>提供提前访问权以优化硬件适配，而<strong>英伟达</strong>和<strong>AMD</strong>目前未获授权。社交媒体爆料称，该模型支持<code>1M</code>上下文窗口及原生多模态，<code>SVG</code>生成效果在细节和准确性上均优于前代。</p>
</blockquote>
<p>据路透社及多家信源报道，<strong>DeepSeek</strong>正在测试未发布的<strong>V4</strong>模型，并向<strong>华为</strong>等国内供应商提供提前访问权以优化处理器软件，<strong>英伟达</strong>和<strong>AMD</strong>暂未获权。社交媒体爆料称，代号为“sealion-lite”的<code>V4 Lite</code>支持<code>1M</code>上下文窗口及原生多模态推理。流出的SVG示例显示，其在非思考模式下的表现优于上一代<code>V3.2</code>的思考模式。社区讨论认为，若该模型实现低成本长上下文推理，或将改变行业格局。目前<strong>DeepSeek</strong>官方尚未对此做出回应。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/725d7efa-2039-43a8-8489-c7178c75a865/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/725d7efa-2039-43a8-8489-c7178c75a865/m002.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/725d7efa-2039-43a8-8489-c7178c75a865/m003.png" alt=""></p>
<hr>
<h2><a href="https://thein.fo/3OLENvI">亚马逊据传将向OpenAI投资高达500亿美元</a> <code>#22</code></h2>
<blockquote>
<p>据报道，亚马逊正洽谈向 <strong>OpenAI</strong> 投资最高达 <strong>500亿美元</strong>，其中 <strong>350亿美元</strong> 资金将取决于 <strong>OpenAI</strong> 是否实现 <strong>AGI</strong> 或完成 <strong>IPO</strong>。作为合作条件，<strong>OpenAI</strong> 将扩大使用亚马逊 <code>Trainium</code> 芯片，并为 <strong>Alexa</strong> 开发定制模型。</p>
</blockquote>
<p>据 The Information 报道，<strong>亚马逊</strong>正洽谈向 <strong>OpenAI</strong> 投资高达 <strong>500 亿美元</strong>。交易拟分两阶段：初期投入 <strong>150 亿美元</strong>，剩余 <strong>350 亿美元</strong>视 <strong>OpenAI</strong> 实现 AGI 或完成 IPO 而定。此举源于 <strong>OpenAI</strong> 预计未来五年算力成本将达 <strong>6650 亿美元</strong>，需深化云合作，包括扩大使用 <strong>亚马逊 Trainium</strong> 芯片及为 <strong>Alexa</strong> 开发模型。此外报道指出，<strong>软银</strong>和<strong>英伟达</strong>计划各投资 <strong>300 亿美元</strong>，<strong>微软</strong>尚未决定是否跟投。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/2fe13718-5a0c-4f23-9e35-0bc321d445e4/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://thein.fo/3OLENvI">https://thein.fo/3OLENvI</a></li>
<li><a href="https://x.com/theinformation/status/2027146093616669040">https://x.com/theinformation/status/2027146093616669040</a></li>
</ul>
<hr>
<h2><a href="https://thein.fo/4r4VIqL">据传谷歌与Meta签署数十亿美元AI芯片协议</a> <code>#23</code></h2>
<blockquote>
<p>据 The Information 报道，<strong>Google</strong> 与 <strong>Meta</strong> 签署了价值数十亿美元的 AI 芯片协议；与此同时，<strong>Meta</strong> 因设计困境已废弃其最先进的内部 AI 训练芯片项目 <code>Metis</code>。</p>
</blockquote>
<p>据 The Information 独家报道，<strong>Google</strong> 已与 <strong>Meta</strong> 达成一项价值数十亿美元的 <strong>AI</strong> 芯片交易，此举进一步加剧了 <strong>Google</strong> 与 <strong>Nvidia</strong> 的市场竞争。同时，<strong>Meta</strong> 因设计困境已废弃其最先进的内部 <strong>AI</strong> 训练芯片项目。这一挫折凸显了科技巨头试图在硬件领域挑战 <strong>Nvidia</strong> 主导地位所面临的极高难度。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://thein.fo/4r4VIqL">https://thein.fo/4r4VIqL</a></li>
<li><a href="https://thein.fo/4chhFPC">https://thein.fo/4chhFPC</a></li>
</ul>
<hr>
<h2><a href="https://x.com/synthwavedd/status/2026800988401574068">GPT-5.3被曝或已上线Arena</a> <code>#24</code></h2>
<blockquote>
<p>X 平台消息称 <strong>GPT-5.3</strong> 已上线 <code>LM Arena</code>，代号为 <code>vortex</code> 和 <code>zephyr</code>。</p>
</blockquote>
<p>据X用户leo 🐾称，<strong>GPT-5.3</strong>已登陆<strong>LM Arena</strong>，代号为“<strong>vortex</strong>”和“<strong>zephyr</strong>”。社区反馈显示，目前Battle模式极难匹配到这两个模型，且列表中未见显示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/94b7092c-0954-4a6d-b511-440e3effd3c2/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/synthwavedd/status/2026800988401574068">https://x.com/synthwavedd/status/2026800988401574068</a></li>
</ul>
<hr>
<h2><a href="https://x.com/AILeaksAndNews/status/2027041400718848315">传Meta两款AI模型亮相测试平台</a> <code>#25</code></h2>
<blockquote>
<p>代号为 <strong>Mint</strong> 和 <strong>Chocolate</strong> 的 <code>AI 模型</code> 现身 <strong>Design Arena</strong> 平台，外界猜测其与 <strong>Meta</strong> 的 <code>Avocado</code> 模型有关。</p>
</blockquote>
<p>据社交媒体消息披露，两款代号为“Mint”和“Chocolate”的新<code>AI模型</code>近期现身Design Arena平台，其测试页面信息显示创建者为 <strong>Meta AI</strong>。针对模型背景，社区讨论推测其可能与 <strong>Meta</strong> 超智能团队的 <code>Avocado</code> 模型有关，但该说法尚未得到确切证实。目前， <strong>Meta</strong> 官方尚未对此发布正式声明。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dca7ff26-c262-4345-a268-41166e77e510/e29816f9-5dc7-46b0-b9f1-778e37a14fd5/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/AILeaksAndNews/status/2027041400718848315">https://x.com/AILeaksAndNews/status/2027041400718848315</a></li>
</ul>
<hr>
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
]]></content:encoded><guid isPermaLink="false">https://github.com/imjuya/juya-ai-daily/issues/10</guid><pubDate>Fri, 27 Feb 2026 01:49:31 +0000</pubDate></item><item><title>2026-02-26</title><link>https://imjuya.github.io/juya-ai-daily/issue-9/</link><description>AI 早报 2026-02-26 视频版：哔哩哔哩 ｜ YouTube 概览 要闻 NVIDIA公布创纪录财报，营收展望超出预期 ↗ #1 Claude Cowork引入定时任务功能 ↗ #2 Google AI创作工具Flow转型为图影一体化平台 ↗ #3 Google 在部分品牌手机上推出 Gemini 自动化功能 ↗ #4 模型发布 Multiverse Computing发布HyperNova 60B模型 ↗ #5 开发生态 Gemini CLI向付费层级全面开放Gemini 3.1 Pro ↗ #6 阿里云百炼Coding Plan上线第三方开源旗舰模型 ↗ #7 GitHub Copilot CLI正式发布并新增研究功能 ↗ #8 Opencode推出OpenCode Go订阅服务 ↗ #9 No…</description><content:encoded><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260226/20260226091449101122895c_cover_8545.png" alt=""></p>
<h1>AI 早报 2026-02-26</h1>
<p><strong>视频版</strong>：<a href="https://www.bilibili.com/video/BV1frfYBzEW4">哔哩哔哩</a> ｜ <a href="https://www.youtube.com/watch?v=NahFSuUKPvE">YouTube</a></p>
<h2>概览</h2>
<h3>要闻</h3>
<ul>
<li>NVIDIA公布创纪录财报，营收展望超出预期 <a href="https://nvidianews.nvidia.com/news/nvidia-announces-financial-results-for-fourth-quarter-and-fiscal-2026">↗</a> <code>#1</code></li>
<li>Claude Cowork引入定时任务功能 <a href="https://x.com/claudeai/status/2026720870631354429">↗</a> <code>#2</code></li>
<li>Google AI创作工具Flow转型为图影一体化平台 <a href="https://blog.google/innovation-and-ai/models-and-research/google-labs/flow-updates-february-2026/">↗</a> <code>#3</code></li>
<li>Google 在部分品牌手机上推出 Gemini 自动化功能 <a href="https://blog.google/innovation-and-ai/products/gemini-app/android-multi-step-tasks/">↗</a> <code>#4</code></li>
</ul>
<h3>模型发布</h3>
<ul>
<li>Multiverse Computing发布HyperNova 60B模型 <a href="https://huggingface.co/MultiverseComputingCAI/Hypernova-60B-2602">↗</a> <code>#5</code></li>
</ul>
<h3>开发生态</h3>
<ul>
<li>Gemini CLI向付费层级全面开放Gemini 3.1 Pro <a href="https://x.com/geminicli/status/2026767076786897312">↗</a> <code>#6</code></li>
<li>阿里云百炼Coding Plan上线第三方开源旗舰模型 <a href="https://mp.weixin.qq.com/s/ARwYrkHY8SxlPNQIAkQeaA">↗</a> <code>#7</code></li>
<li>GitHub Copilot CLI正式发布并新增研究功能 <a href="https://x.com/burkeholland/status/2026711387095888345">↗</a> <code>#8</code></li>
<li>Opencode推出OpenCode Go订阅服务 <a href="https://x.com/opencode/status/2026553685468135886">↗</a> <code>#9</code></li>
<li>Nous Research开源发布Hermes持久化AI Agent <a href="http://nousresearch.com/hermes-agent">↗</a> <code>#10</code></li>
</ul>
<h3>产品应用</h3>
<ul>
<li>Perplexity 推出通用AI数字员工Perplexity Computer <a href="https://www.perplexity.ai/hub/blog/introducing-perplexity-computer">↗</a> <code>#11</code></li>
<li>Adobe Firefly 推出Quick Cut视频AI剪辑功能 <a href="https://techcrunch.com/2026/02/25/adobe-fireflys-video-editor-can-now-automatically-create-a-first-draft-from-footage">↗</a> <code>#12</code></li>
<li>谷歌升级Circle to Search支持多物品识别 <a href="https://blog.google/products-and-platforms/products/search/circle-to-search-february-2026/">↗</a> <code>#13</code></li>
<li>Kilocode 发布KiloClaw <a href="https://www.producthunt.com/products/kiloclaw">↗</a> <code>#14</code></li>
<li>Tailscale与LM Studio联合推出LM Link <a href="https://tailscale.com/blog/lm-link-remote-llm-access">↗</a> <code>#15</code></li>
</ul>
<h3>技术与洞察</h3>
<ul>
<li>Cloudflare 联合 AI 一周推出 Next.js 替代项目 vinext <a href="https://blog.cloudflare.com/vinext/">↗</a> <code>#16</code></li>
<li>字节跳动研究揭示大型推理模型过度思考现象并推出高效解决方案 <a href="https://arxiv.org/abs/2602.08354">↗</a> <code>#17</code></li>
<li>OpenAI发布AI滥用威胁态势报告 <a href="https://openai.com/index/disrupting-malicious-ai-uses/">↗</a> <code>#18</code></li>
</ul>
<h3>行业动态</h3>
<ul>
<li>英伟达尚未向中国销售任何H200芯片 <a href="https://www.reuters.com/technology/nvidia-hasnt-sold-any-h200-ai-chips-china-despite-us-approval-official-says-2024-08-24/">↗</a> <code>#19</code></li>
<li>阶跃星辰StepFun获巨额融资并或赴港上市 <a href="https://www.bloomberg.com/quote/2536231D:CH">↗</a> <code>#20</code></li>
<li>Anthropic收购Vercept提升Claude计算机使用能力 <a href="https://www.anthropic.com/news/acquires-vercept">↗</a> <code>#21</code></li>
<li>Wayve宣布完成12亿美元D轮融资 <a href="https://wayve.ai/press/series-d/">↗</a> <code>#22</code></li>
<li>美国多州立法限制数据中心建设 <a href="https://www.nysenate.gov/legislation/bills/2025/S9144">↗</a> <code>#23</code></li>
</ul>
<h3>前瞻与传闻</h3>
<ul>
<li>马斯克确认Grok CLI即将推出 <a href="https://x.com/elonmusk/status/2026498946647171295">↗</a> <code>#24</code></li>
<li>谷歌或将推出Gemini 3.1 Flash图像模型 <a href="https://zhidx.com/p/536245.html">↗</a> <code>#25</code></li>
</ul>
<h3>其他</h3>
<ul>
<li>Anthropic延续访问已退役Claude Opus 3模型并为其开设博客 <a href="https://www.anthropic.com/research/deprecation-updates-opus-3">↗</a> <code>#26</code></li>
<li>开发者POM公开15.5万条Claude私人对话 <a href="https://github.com/peteromallet/dataclaw">↗</a> <code>#27</code></li>
<li>黑客借助Claude攻击墨西哥政府窃取数据 <a href="https://www.bloomberg.com/news/articles/2026-02-25/hacker-used-anthropic-s-claude-to-steal-sensitive-mexican-data">↗</a> <code>#28</code></li>
<li>腾讯元宝回应模型异常输出辱骂内容 <code>#29</code></li>
</ul>
<hr>
<h2><a href="https://nvidianews.nvidia.com/news/nvidia-announces-financial-results-for-fourth-quarter-and-fiscal-2026">NVIDIA公布创纪录财报，营收展望超出预期</a> <code>#1</code></h2>
<blockquote>
<p><strong>NVIDIA</strong> 公布 <strong>2026</strong> 财年 Q4 及全年财报，Q4 营收达 <strong>681.3</strong> 亿美元，同比增长 <strong>73%</strong>，超出预期；核心数据中心营收 <strong>623</strong> 亿美元。<strong>2026</strong> 财年全年营收 <strong>2159.4</strong> 亿美元。公司预计 <strong>2027</strong> 财年 Q1 营收为 <strong>780</strong> 亿美元，远超市场预期。</p>
</blockquote>
<p>NVIDIA公布2026财年第四季度及全财年财务报告，季度营收达创纪录的<strong>681.3亿美元</strong>，同比增长<strong>73%</strong>，超出市场预期；全年营收为<strong>2159.4亿美元</strong>，增长<strong>65%</strong>。核心数据中心业务季度营收同比增长<strong>75%<strong>至</strong>623亿美元</strong>。公司对2027财年第一季度营收预期为<strong>780亿美元</strong>（上下浮动2%），远超市场预期。</p>
<p>创始人兼CEO<strong>黄仁勋</strong>表示，Agentic AI的拐点已至，推理性能与Token经济学至关重要，并强调“推理现在等于收入”。CFO <strong>Colette Kress</strong>指出，需求正从五大云服务商向AI初创公司、企业及主权政府扩散。</p>
<p>产品方面，NVIDIA宣布<code>Rubin</code>平台，并已向客户出货首批<code>Vera Rubin</code>样本，预计2026年下半年开始生产出货。在关键细节上，CFO透露，NVIDIA在华<code>H20</code>芯片销售额约为<strong>6000万美元</strong>，尚无<code>H-200</code>芯片收入；因内存供应限制，游戏业务未来数季度供应将非常紧张。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/508b0985-c8d6-4d27-9dff-0069b5558408/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://nvidianews.nvidia.com/news/nvidia-announces-financial-results-for-fourth-quarter-and-fiscal-2026">https://nvidianews.nvidia.com/news/nvidia-announces-financial-results-for-fourth-quarter-and-fiscal-2026</a></li>
<li><a href="https://www.businessinsider.com/nvidia-q4-earnings-live-updates-ai-chips-rubin-jensen-huang-2026-2">https://www.businessinsider.com/nvidia-q4-earnings-live-updates-ai-chips-rubin-jensen-huang-2026-2</a></li>
</ul>
<hr>
<h2><a href="https://x.com/claudeai/status/2026720870631354429">Claude Cowork引入定时任务功能</a> <code>#2</code></h2>
<blockquote>
<p>Anthropic为其桌面工具<code>Claude Cowork</code>推出“定时任务”功能，支持在特定时间自动执行晨间简报、表格更新等重复性任务。</p>
</blockquote>
<p>Anthropic为其桌面工具<strong>Claude Cowork</strong>推出“定时任务”功能，允许<strong>Claude</strong>自动在特定时间完成如生成晨间简报、更新每周电子表格及准备周五团队演示等重复性任务。此次更新同时新增了侧边栏“自定义”标签页，用于集中管理插件、技能和连接器。官方强调，插件功能为该工具赋予了设计、工程和运营等领域的专业能力。</p>
<p>目前，<strong>Claude Cowork</strong>处于研究预览阶段，支持<code>macOS</code>和<code>Windows</code>平台，所有付费<strong>Claude</strong>计划用户均可使用。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/66bec4e7-dc85-4e1c-becc-764275e2db39/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/claudeai/status/2026720870631354429">https://x.com/claudeai/status/2026720870631354429</a></li>
</ul>
<hr>
<h2><a href="https://blog.google/innovation-and-ai/models-and-research/google-labs/flow-updates-february-2026/">Google AI创作工具Flow转型为图影一体化平台</a> <code>#3</code></h2>
<blockquote>
<p>Google 将其 AI 创意工作室应用 <strong>Flow</strong> 升级为图像与视频一体化工具，整合了 <code>Whisk</code> 和 <code>ImageFX</code> 的功能，并将 <code>Nano Banana</code> 模型集成至核心体验中。用户现在可在统一空间内免费生成高保真图像作为 <strong>Veo</strong> 视频素材，并能通过新增的套索工具和自然语言指令进行精准编辑。</p>
</blockquote>
<p>Google对其AI创意工作室应用 <strong>Flow</strong> 进行重大更新，将其转型为图像与视频的一体化工具，并重新设计了界面以提升创作效率。自去年上线以来，用户通过该工具已创建了超过 <strong>15亿</strong> 个图像和视频。</p>
<p>此次更新整合了 <code>Whisk</code> 和 <code>ImageFX</code> 的核心功能，并将 <code>Nano Banana</code> 模型完全集成至核心体验中。用户现可在统一工作空间内生成高保真图像，并将其直接用作 <code>Veo</code> 视频生成的素材，且图像生成功能免费。为了简化工作流，从 <strong>3月</strong> 开始，用户可选择将 <code>Whisk</code> 和 <code>ImageFX</code> 的项目及资产迁移至 <strong>Flow</strong> 库。</p>
<p>新版本引入了更灵活的资产管理功能，包括资产集合、视图切换及“@”符号快速引用。同时，<strong>Flow</strong> 提供了更精准的编辑控制：对于图像，用户可使用套索工具精确选区，并通过自然语言指令进行编辑；对于视频，则支持延长片段、添加或移除物体以及控制运镜。</p>
<p>Google官方人员 <strong>Josh Woodward</strong> 称，重新设计的 <strong>Flow</strong> 是增长最快的新AI产品之一，它与前沿创作者共创以适应未来工作流，并且运行速度实现了显著提升。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/5c33ab98-d4ec-4b0f-b561-196f10262f35/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/innovation-and-ai/models-and-research/google-labs/flow-updates-february-2026/">https://blog.google/innovation-and-ai/models-and-research/google-labs/flow-updates-february-2026/</a></li>
</ul>
<hr>
<h2><a href="https://blog.google/innovation-and-ai/products/gemini-app/android-multi-step-tasks/">Google 在部分品牌手机上推出 Gemini 自动化功能</a> <code>#4</code></h2>
<blockquote>
<p>Google宣布为 <strong>Galaxy S26</strong> 及 <strong>Pixel 10</strong> 系列引入由 <code>Gemini</code> 驱动的多项新功能，即将上线的 Beta 版支持长按电源键，让 AI 通过安全虚拟窗口在后台自动处理叫车或点餐等任务，首发美韩市场。<strong>Galaxy S26</strong> 更集成了端侧 <code>Gemini</code> 模型，可直接在本地进行通话诈骗检测并发出警报。</p>
</blockquote>
<p>近日，谷歌在 <strong>Samsung Unpacked 2026</strong> 上为 <strong>Galaxy S26</strong> 及 <strong>Pixel 10</strong> 系列宣布了多项 <strong>Gemini</strong> 驱动的新功能。核心是一项即将推出的 Beta 功能，用户长按电源键即可委托 <code>Gemini</code> 处理叫车、点餐等多步骤任务。该功能通过安全虚拟窗口在后台运行，初期仅支持食品、杂货和网约车类别的特定应用，并率先在美国和韩国推出。<br>
在安全方面，<strong>Galaxy S26</strong> 的三星电话应用集成了基于端侧 <code>Gemini</code> 模型的 <code>Scam Detection</code> 功能，可在通话中实时检测诈骗并发出警报。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/42b6b659-b4c1-4df6-83b3-328b4ba100d6/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/innovation-and-ai/products/gemini-app/android-multi-step-tasks/">https://blog.google/innovation-and-ai/products/gemini-app/android-multi-step-tasks/</a></li>
<li><a href="https://blog.google/products-and-platforms/platforms/android/samsung-unpacked-2026/">https://blog.google/products-and-platforms/platforms/android/samsung-unpacked-2026/</a></li>
<li><a href="https://blog.google/products-and-platforms/products/search/circle-to-search-february-2026">https://blog.google/products-and-platforms/products/search/circle-to-search-february-2026</a></li>
</ul>
<hr>
<h2><a href="https://huggingface.co/MultiverseComputingCAI/Hypernova-60B-2602">Multiverse Computing发布HyperNova 60B模型</a> <code>#5</code></h2>
<blockquote>
<p><strong>Multiverse Computing</strong> 发布了 <strong>HyperNova 60B 2602</strong> 语言模型，利用专有压缩技术将 <code>gpt-oss-120b</code> 缩减至 <strong>600</strong> 亿，同时保持仅 <strong>48</strong> 亿的激活参数。</p>
</blockquote>
<p><strong>Multiverse Computing</strong> 推出 <strong>HyperNova 60B 2602</strong> 语言模型，基于 <code>gpt-oss-120b</code> 并采用 <code>CompactifAI</code> 技术压缩。该模型拥有 <strong>60B</strong> 总参数和 <strong>4.8B</strong> 激活参数，旨在降低企业部署成本。其重点增强了原生工具调用能力，兼容 OpenAI 风格 Schema 及 Agent 工作流。由于主要使用英语数据训练，模型存在语言局限性，官方计划于 <strong>2026</strong> 年发布更多行业模型。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/c4fb53a1-1dca-4471-a1ab-2ebe1d048176/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://huggingface.co/MultiverseComputingCAI/Hypernova-60B-2602">https://huggingface.co/MultiverseComputingCAI/Hypernova-60B-2602</a></li>
<li><a href="https://techcrunch.com/2026/02/24/spanish-soonicorn-multiverse-computing-releases-free-compressed-ai-model">https://techcrunch.com/2026/02/24/spanish-soonicorn-multiverse-computing-releases-free-compressed-ai-model</a></li>
</ul>
<hr>
<h2><a href="https://x.com/geminicli/status/2026767076786897312">Gemini CLI向付费层级全面开放Gemini 3.1 Pro</a> <code>#6</code></h2>
<blockquote>
<p>Gemini CLI 官方宣布，<strong>Gemini 3.1 Pro</strong> 现已面向所有付费用户开放。其默认模型路由器 <code>Auto</code> 会为复杂提示词自动调用此 Pro 级模型，用户也可手动切换。</p>
</blockquote>
<p><strong>Gemini CLI</strong> 官方宣布，<strong>Gemini 3.1 Pro</strong> 现已面向所有付费层级用户开放。其默认模型路由器 <code>Auto</code> (<code>Gemini 3</code>) 会为复杂提示词自动调用此 Pro 级模型，用户也可通过 <code>/model</code> 命令手动指定。官方团队感谢用户耐心，并正与社区沟通以改进未来发布。<br>
然而，多位用户反馈了问题，包括频繁的 <code>429</code> 频率限制错误，以及部分拥有 <strong>Workspace Business</strong> 和 <strong>AI Expanded Access</strong> 的账户未被识别为付费层级。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/a4143666-bc99-49da-9c8a-0240b026025d/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/geminicli/status/2026767076786897312">https://x.com/geminicli/status/2026767076786897312</a></li>
</ul>
<hr>
<h2><a href="https://mp.weixin.qq.com/s/ARwYrkHY8SxlPNQIAkQeaA">阿里云百炼Coding Plan上线第三方开源旗舰模型</a> <code>#7</code></h2>
<blockquote>
<p>阿里云百炼Coding Plan 近期上线了 <strong>Qwen3.5</strong>、<strong>GLM-5</strong>、<strong>Kimi K2.5</strong> 等多款顶尖开源模型及编程专用模型。</p>
</blockquote>
<p>阿里云“<strong>百炼</strong>” Coding Plan 订阅服务上线了 <code>Qwen3.5</code>、<code>GLM-5</code>、<code>MiniMax M2.5</code>、<code>Kimi K2.5</code> 等开源模型，并新增 <code>Qwen3.5-Plus</code>、<code>Qwen3-Coder-Next</code> 等编程专用模型。针对 AI Agent 时代算力成本激增，平台推出低价方案：新用户首购享 <strong>2</strong> 折优惠，Lite 套餐首月 <strong>18000</strong> 次请求仅需 <strong>7.9</strong> 元。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/7dff0903-e767-4763-b597-80db2d75f8c5/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/ARwYrkHY8SxlPNQIAkQeaA">https://mp.weixin.qq.com/s/ARwYrkHY8SxlPNQIAkQeaA</a></li>
</ul>
<hr>
<h2><a href="https://x.com/burkeholland/status/2026711387095888345">GitHub Copilot CLI正式发布并新增研究功能</a> <code>#8</code></h2>
<blockquote>
<p><strong>Copilot CLI</strong> 宣布正式发布，同步新增 <code>slash research</code> 命令。该功能支持对全球开源仓库进行深度研究，并可生成报告快速分享给团队。</p>
</blockquote>
<p><strong>Copilot CLI</strong> 宣布已正式发布 (GA)，用户现可在工作环境中使用。此次更新引入了 <code>/research</code> 命令，该功能结合 <strong>GitHub</strong> 高级代码搜索工具与 <code>MCPs</code> 动态获取内容，支持对全球任何 <code>OSS</code> 仓库进行深度研究。用户利用该功能可生成报告、导出到 <code>gists</code> 并与团队分享，以协作完成代码调研。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/b98451e5-151f-433c-a15a-668935e042bb/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/burkeholland/status/2026711387095888345">https://x.com/burkeholland/status/2026711387095888345</a></li>
<li><a href="https://x.com/burkeholland/status/2026470121561059626">https://x.com/burkeholland/status/2026470121561059626</a></li>
</ul>
<hr>
<h2><a href="https://x.com/opencode/status/2026553685468135886">Opencode推出OpenCode Go订阅服务</a> <code>#9</code></h2>
<blockquote>
<p><strong>OpenCode</strong> 推出了定价每月 <strong>10 美元</strong> 的 <strong>OpenCode Go</strong> 订阅服务，用户只需运行 <code>/connect</code> 命令并选择该计划即可启用。</p>
</blockquote>
<p><strong>OpenCode</strong> 正式推出月费 <strong>10 美元</strong> 的订阅服务 <strong>OpenCode Go</strong>。官方介绍称，该服务旨在为全球程序员提供 <code>Agentic coding</code> 能力及对顶级开源模型的可靠访问，并拥有慷慨的使用额度。用户可通过运行 <code>/connect</code> 指令并选择 <strong>OpenCode Go</strong> 进行启用。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/fb51952f-5084-4432-be9f-e85237e7633f/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/opencode/status/2026553685468135886">https://x.com/opencode/status/2026553685468135886</a></li>
</ul>
<hr>
<h2><a href="http://nousresearch.com/hermes-agent">Nous Research开源发布Hermes持久化AI Agent</a> <code>#10</code></h2>
<blockquote>
<p><strong>Nous Research</strong> 发布了开源 AI Agent <code>Hermes Agent</code>，该产品通过多级记忆系统赋予 Agent 持久化学习与成长能力。</p>
</blockquote>
<p>Nous Research发布开源AI Agent <strong>“Hermes Agent”</strong>。该产品具备持久化机器访问能力和多级记忆系统，能记录学习内容，解决传统Agent状态丢失问题。它融合编码与通用Agent特点，运行于用户服务器而非云端沙盒，支持无人值守任务、隔离子Agent生成及本地系统访问，并可在 <code>CLI</code> 及 <code>Slack</code> 等平台跨平台运行。技术上，它基于数据库存储，将技能视为一等原语。</p>
<p>相关链接：</p>
<ul>
<li><a href="http://nousresearch.com/hermes-agent">http://nousresearch.com/hermes-agent</a></li>
<li><a href="http://portal.nousresearch.com">http://portal.nousresearch.com</a></li>
</ul>
<hr>
<h2><a href="https://www.perplexity.ai/hub/blog/introducing-perplexity-computer">Perplexity 推出通用AI数字员工Perplexity Computer</a> <code>#11</code></h2>
<blockquote>
<p><strong>Perplexity</strong> 正式推出通用型数字员工 <strong>Perplexity Computer</strong>，该系统能将用户描述的预期成果自动拆解，并调度 <code>19</code> 种模型协同执行研究、编码和部署等长周期任务。目前该产品已在网页端向 <strong>Max</strong> 订阅用户开放。</p>
</blockquote>
<p><strong>Perplexity</strong> 正式发布通用型数字员工“<strong>Perplexity Computer</strong>”。该系统可长期自主运行，将用户描述的目标拆解为子任务，调用子 Agent 执行研究、编码及部署等操作。技术方面，它以 <code>Opus 4.6</code> 为核心，智能调度 <code>Gemini</code>、<code>ChatGPT 5.2</code> 等 19 种模型。目前该产品已在网页端向 <strong>Max</strong> 用户开放，采用按使用量计费，每月包含 <strong>10,000</strong> 积分。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/fac7d8b2-8c9b-4065-8f6e-b4b4287e5595/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.perplexity.ai/hub/blog/introducing-perplexity-computer">https://www.perplexity.ai/hub/blog/introducing-perplexity-computer</a></li>
</ul>
<hr>
<h2><a href="https://techcrunch.com/2026/02/25/adobe-fireflys-video-editor-can-now-automatically-create-a-first-draft-from-footage">Adobe Firefly 推出Quick Cut视频AI剪辑功能</a> <code>#12</code></h2>
<blockquote>
<p>Adobe Firefly 视频编辑器推出了名为 <strong>Quick Cut</strong> 的新功能，AI 能自动剔除原始素材中的无效片段，并生成包含转场效果的粗剪初稿。</p>
</blockquote>
<p>Adobe Firefly视频编辑器推出“Quick Cut”新功能，利用AI根据自然语言提示自动将原始素材和B-roll转化为粗剪初稿。用户可设定宽高比及转场节奏，该工具能自动剔除无关内容、组合镜头，并利用 <code>Firefly</code> 模型生成转场。Adobe产品负责人Mike Folgner表示，此举旨在通过处理繁琐筛选工作，帮助创作者快速构建故事框架以满足快速周转需求。该功能仅提供初稿，后续仍需人工调整。此前，Adobe已引入时间轴编辑器及图层支持等功能。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/77fa27e1-94cc-4a11-aa6c-495d3e1a0cfd/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://techcrunch.com/2026/02/25/adobe-fireflys-video-editor-can-now-automatically-create-a-first-draft-from-footage">https://techcrunch.com/2026/02/25/adobe-fireflys-video-editor-can-now-automatically-create-a-first-draft-from-footage</a></li>
</ul>
<hr>
<h2><a href="https://blog.google/products-and-platforms/products/search/circle-to-search-february-2026/">谷歌升级Circle to Search支持多物品识别</a> <code>#13</code></h2>
<blockquote>
<p>Google 今日升级了 <code>Circle to Search</code> 功能，现已支持同时圈选并识别多个物品，自动拆解穿搭或场景组件并提供背景解释。<code>Samsung Galaxy S26</code> 系列和 <code>Pixel 10</code> 用户即日起还可直接使用虚拟试穿功能。</p>
</blockquote>
<p>Google 今日宣布更新 <strong>Circle to Search</strong>，由 <code>Gemini 3</code> 驱动，现已支持在单张图片中同时探索多个物品。用户圈选图片后，系统可自动识别各组件并提供相似商品推荐及背景解释。在 <strong>Samsung Galaxy S26</strong> 系列和 <strong>Pixel 10</strong> 设备上，该功能还支持直接使用虚拟试穿。此次升级增强了视觉查询技术，能通过多步规划满足用户对整体场景的搜索需求。新功能即日起在上述机型上线，并即将扩展至更多 Android 设备。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/8ce6bdd0-264a-49fc-b365-9b96989b05e9/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/products-and-platforms/products/search/circle-to-search-february-2026/">https://blog.google/products-and-platforms/products/search/circle-to-search-february-2026/</a></li>
<li><a href="https://x.com/rajanpatel/status/1973011277615149479">https://x.com/rajanpatel/status/1973011277615149479</a></li>
</ul>
<hr>
<h2><a href="https://www.producthunt.com/products/kiloclaw">Kilocode 发布KiloClaw</a> <code>#14</code></h2>
<blockquote>
<p><strong>Kilocode</strong> 发布了全托管云端 <strong>AI Agent</strong> 工具 <code>KiloClaw</code>，用户无需配置本地硬件即可免费运行。</p>
</blockquote>
<p>Kilocode 近日宣布推出全托管云端版 <strong>OpenClaw</strong>——<strong>KiloClaw</strong>。该产品原生连接 <code>Kilo Gateway</code>，支持访问超 <strong>500</strong> 个模型。官方表示，平台负责基础设施与安全监控，用户无需配置 <code>SSH</code> 或 <code>Mac Mini</code> 即可免费运行。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/b8cca92f-d615-4120-abf9-97f6d3a3a1f0/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.producthunt.com/products/kiloclaw">https://www.producthunt.com/products/kiloclaw</a></li>
<li><a href="https://x.com/kilocode/status/2026727778867900614">https://x.com/kilocode/status/2026727778867900614</a></li>
</ul>
<hr>
<h2><a href="https://tailscale.com/blog/lm-link-remote-llm-access">Tailscale与LM Studio联合推出LM Link</a> <code>#15</code></h2>
<blockquote>
<p><strong>Tailscale</strong> 与 <strong>LM Studio</strong> 联合推出了 <strong>LM Link</strong> 功能，允许用户通过端到端加密连接，安全调用自有硬件上的远程 <code>大模型</code>。</p>
</blockquote>
<p><strong>Tailscale</strong> 与 <strong>LM Studio</strong> 联合推出 <strong>LM Link</strong> 功能，旨在通过 <code>tsnet</code> 技术让用户安全访问自有硬件上的远程 <code>LLM</code>。该功能建立端到端加密连接，无需公网暴露或 API 密钥，确保提示词与响应数据仅用户可见，后台服务无法查看。用户可通过桌面应用或终端指令配置，在本地无缝调用远程算力。目前该功能已面向个人及工作场景免费开放，支持团队协作、<code>IoT</code> 设备连接及受监管行业使用，保障数据隐私与控制权。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/4c95355c-2375-4340-8443-4da72221c4dc/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://tailscale.com/blog/lm-link-remote-llm-access">https://tailscale.com/blog/lm-link-remote-llm-access</a></li>
<li><a href="https://link.lmstudio.ai/">https://link.lmstudio.ai/</a></li>
</ul>
<hr>
<h2><a href="https://blog.cloudflare.com/vinext/">Cloudflare 联合 AI 一周推出 Next.js 替代项目 vinext</a> <code>#16</code></h2>
<blockquote>
<p><strong>Cloudflare</strong> 发布博客介绍称，一名工程师利用 <strong>AI</strong> 仅用一周时间就从零重建了 <strong>Next.js</strong> 框架，并推出了替代项目 <strong>Vinext</strong>。该项目构建速度比原版快 <strong>4.4</strong> 倍，体积减小 <strong>57%</strong>。这一案例展示了 <strong>AI</strong> 利用公开测试套件克隆软件的惊人能力，促使协作绘图库 <strong>tldraw</strong> 迅速将其 <strong>327</strong> 个测试文件迁移至私有仓库。</p>
</blockquote>
<p>Cloudflare官方博客发布一项技术演示，展示其工程师与AI协作，在一周内以约 <strong>1,100美元</strong> 的Token费用，从零重建了流行的React框架 <strong>Next.js</strong>，并推出替代项目 <strong>vinext</strong>。该项目基于 <strong>Vite</strong> 构建，早期基准测试显示，其构建速度比 <strong>Next.js 16</strong> 快达 <strong>4.4倍</strong>，生成的客户端包体积小 <strong>57%</strong>。</p>
<p>在技术实现上，<strong>vinext</strong> 项目利用了 <strong>Next.js</strong> 详尽的测试套件和文档作为规范，移植了超过 <strong>1,700</strong> 个测试用例以实现 <strong>94%</strong> 的API覆盖率，确保了代码质量。该项目还引入了“流量感知预渲染”（<code>TPR</code>）功能。目前该项目仍处于实验阶段，但已有客户在生产环境中运行。</p>
<p>受Cloudflare事件影响，协作绘图库 <strong>tldraw</strong> 将其包含约 <strong>327</strong> 个文件的完整测试套件从开源仓库迁移至私有仓库，旨在防止AI利用公开测试套件克隆其功能。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.cloudflare.com/vinext/">https://blog.cloudflare.com/vinext/</a></li>
<li><a href="https://github.com/tldraw/tldraw/issues/8082">https://github.com/tldraw/tldraw/issues/8082</a></li>
</ul>
<hr>
<h2><a href="https://arxiv.org/abs/2602.08354">字节跳动研究揭示大型推理模型过度思考现象并推出高效解决方案</a> <code>#17</code></h2>
<blockquote>
<p>ByteDance 研究团队针对大型推理模型在得出正确答案后仍持续生成冗余内容的“过度思考”现象，提出了 <strong>SAGE</strong> 采样范式及 <strong>SAGE-RL</strong> 训练方法。</p>
</blockquote>
<p>ByteDance研究揭示大型推理模型存在“过度思考”现象，即模型虽隐含停止信号，却因采样方法缺陷持续生成冗余内容。团队引入 <code>RFCS</code> 指标量化此问题，并提出 <code>SAGE</code> 采样范式及 <code>SAGE-RL</code> 训练方法。<code>SAGE</code> 以步骤为单位检查停止信号，<code>SAGE-RL</code> 则通过混合采样优化训练。实验表明，相比牺牲准确性的传统方法，<code>SAGE-RL</code> 在 <code>MATH-500</code>、<code>AIME</code> 等基准上实现了效率与准确性的双重提升。数据显示，模型平均得分增加 <strong>2.1%</strong>，Token用量减少 <strong>44.1%</strong>；其中 <code>Qwen3-8B</code> 响应长度减半且精度无损，<code>Deepseek-R1-Distill-Qwen-7B</code> 准确率达 <strong>93%</strong>，整体推理时间下降超 <strong>40%</strong>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/b31e48bd-75f0-43a9-bc95-cfbf12164ca9/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://arxiv.org/abs/2602.08354">https://arxiv.org/abs/2602.08354</a></li>
</ul>
<hr>
<h2><a href="https://openai.com/index/disrupting-malicious-ai-uses/">OpenAI发布AI滥用威胁态势报告</a> <code>#18</code></h2>
<blockquote>
<p>OpenAI发布最新威胁报告指出，恶意攻击者正将 <strong>OpenAI</strong> 模型与网站等传统工具结合，并在攻击流程的不同节点灵活切换使用不同的 <code>AI模型</code>。<strong>OpenAI</strong> 希望通过分享这些洞察，协助行业各界更有效地识别并防御此类跨平台的复合型威胁。</p>
</blockquote>
<p><strong>OpenAI</strong> 发布最新威胁报告，回顾了过去两年对恶意滥用 <strong>AI</strong> 模型的洞察。报告指出，威胁行为体通常将 <code>AI</code> 模型与网站、社交媒体等传统工具结合使用，且活动不局限于单一平台。<strong>OpenAI</strong> 旨在通过分享发现，帮助行业及社会更好地识别并规避此类威胁，目前完整报告已在官网发布。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://openai.com/index/disrupting-malicious-ai-uses/">https://openai.com/index/disrupting-malicious-ai-uses/</a></li>
</ul>
<hr>
<h2><a href="https://www.reuters.com/technology/nvidia-hasnt-sold-any-h200-ai-chips-china-despite-us-approval-official-says-2024-08-24/">英伟达尚未向中国销售任何H200芯片</a> <code>#19</code></h2>
<blockquote>
<p>美国商务部出口执法助理部长在众议院听证会上透露，尽管此前已批准出口，但 <strong>英伟达</strong> 至今尚未向中国售出任何 <code>H200</code> 芯片，获批销售数量为 <code>0</code>。</p>
</blockquote>
<p>据彭博社等媒体报道，美国商务部出口执法助理部长<strong>戴维·彼得斯</strong>在众议院外交事务委员会听证会上透露，尽管<strong>特朗普政府</strong>两个月前已批准对华出口人工智能（AI）芯片，但<strong>英伟达</strong>公司截至目前尚未向中国售出任何<code>H200</code>芯片。<strong>彼得斯</strong>在回应民主党众议员<strong>悉尼·卡姆拉格-达夫</strong>关于获批销售数量的质询时明确表示，据其了解，数量为零。目前，<strong>英伟达</strong>未对此予以置评。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.reuters.com/technology/nvidia-hasnt-sold-any-h200-ai-chips-china-despite-us-approval-official-says-2024-08-24/">https://www.reuters.com/technology/nvidia-hasnt-sold-any-h200-ai-chips-china-despite-us-approval-official-says-2024-08-24/</a></li>
</ul>
<hr>
<h2><a href="https://www.bloomberg.com/quote/2536231D:CH">阶跃星辰StepFun获巨额融资并或赴港上市</a> <code>#20</code></h2>
<blockquote>
<p>据彭博社消息，<strong>阶跃星辰</strong>正考虑赴港上市，拟筹资约 <strong>5</strong> 亿美元，最早可能于今年进行。该公司此前已刷新国内大模型单笔融资纪录，完成超 <strong>50</strong> 亿元 <strong>B+</strong> 轮融资。</p>
</blockquote>
<p>据彭博社援引知情人士消息，上海AI初创公司 <strong>阶跃星辰StepFun</strong> 正考虑在香港进行IPO，计划筹资约 <strong>5亿美元</strong>，并已与潜在顾问展开讨论，最早可能于今年上市。报道指出，各公司正试图抓住中国人工智能热潮带来的投资者需求。不过，该计划的规模和时间等细节仍有变数，公司代表对此未予置评。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.bloomberg.com/quote/2536231D:CH">https://www.bloomberg.com/quote/2536231D:CH</a></li>
</ul>
<hr>
<h2><a href="https://www.anthropic.com/news/acquires-vercept">Anthropic收购Vercept提升Claude计算机使用能力</a> <code>#21</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 宣布收购 <strong>Vercept</strong> 团队以强化 <strong>Claude</strong> 的 <code>Computer use</code> 能力，使其能像人类一样操控电脑完成复杂任务。</p>
</blockquote>
<p>Anthropic宣布收购<strong>Vercept</strong>，旨在增强<strong>Claude</strong>的<code>Computer use</code>能力。<strong>Vercept</strong>团队专攻AI感知与交互难题，全员将加入<strong>Anthropic</strong>，其外部产品将在未来几周内停止。官方数据显示，随着<strong>Claude Sonnet 4.6</strong>发布，模型在<strong>OSWorld</strong>基准测试中的表现从2024年底的不到<strong>15%<strong>提升至</strong>72.5%</strong>，在处理复杂电子表格等任务上已接近人类水平。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.anthropic.com/news/acquires-vercept">https://www.anthropic.com/news/acquires-vercept</a></li>
</ul>
<hr>
<h2><a href="https://wayve.ai/press/series-d/">Wayve宣布完成12亿美元D轮融资</a> <code>#22</code></h2>
<blockquote>
<p>英国自动驾驶公司 <strong>Wayve</strong> 宣布完成 <strong>12 亿美元</strong> D 轮融资，投后估值达 <strong>86 亿美元</strong>，由 <strong>软银</strong>、<strong>微软</strong>、<strong>英伟达</strong> 及多家全球车企联合押注。</p>
</blockquote>
<p>英国自动驾驶公司 <strong>Wayve</strong> 宣布完成 <strong>12亿美元</strong> Series D融资，投后估值达 <strong>86亿美元</strong>。连同 <strong>Uber</strong> 承诺的额外投资，总金额达 <strong>15亿美元</strong>。本轮融资由 <strong>Eclipse</strong>、<strong>Balderton</strong> 和 <strong>软银</strong> 领投，<strong>微软</strong>、<strong>英伟达</strong> 及多家全球车企参投。作为端到端具身智能先驱，<strong>Wayve</strong> 技术不依赖高精地图，已在欧美日 <strong>500多</strong> 城市验证。官方计划显示，公司将于 <strong>2026年</strong> 联合 <strong>Uber</strong> 在伦敦启动 <code>Robotaxi</code> 试点，并于 <strong>2027年</strong> 在乘用车上部署 <code>L2+</code> 级自动驾驶软件，加速全球商业化落地。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://wayve.ai/press/series-d/">https://wayve.ai/press/series-d/</a></li>
</ul>
<hr>
<h2><a href="https://www.nysenate.gov/legislation/bills/2025/S9144">美国多州立法限制数据中心建设</a> <code>#23</code></h2>
<blockquote>
<p>美国多地政府因担忧能源压力与环境污染，正针对 <strong>AI数据中心</strong> 实施建设禁令或取消税收优惠，其中 <strong>纽约州</strong> 已提议暂停新项目 <strong>三年</strong>。</p>
</blockquote>
<p>受能源与基建压力影响，美国多州近期针对AI基础设施推出限制措施。<strong>纽约</strong>、<strong>新奥尔良</strong>等地已实施或提议暂停数据中心建设，<strong>佐治亚</strong>与<strong>俄亥俄</strong>等州正重新评估税收豁免。尽管面临立法阻力，<strong>亚马逊</strong>、<strong>谷歌</strong>等巨头仍计划明年投入约 <strong>6500亿美元</strong>，并通过建设“影子电网”（通过现场安装发电设备实现私有电力供应）及承担电力成本寻求突破。例如，<strong>xAI</strong>在<strong>孟菲斯</strong>的项目因使用<code>燃气轮机</code>引发环保争议，虽曾被<code>EPA</code>裁定非法但随后补办许可。目前，行业正加大游说力度以应对公众抵制，政策环境呈现显著的地域差异。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.nysenate.gov/legislation/bills/2025/S9144">https://www.nysenate.gov/legislation/bills/2025/S9144</a></li>
</ul>
<hr>
<h2><a href="https://x.com/elonmusk/status/2026498946647171295">马斯克确认Grok CLI即将推出</a> <code>#24</code></h2>
<blockquote>
<p><strong>Elon Musk</strong> 在 <strong>X</strong> 平台回应网友，确认 <code>Grok CLI</code> 即将推出。</p>
</blockquote>
<p><strong>Elon Musk</strong> 在社交平台 <strong>X</strong> 上回应网友 @UziObi 时确认，<code>Grok CLI</code> 即将推出。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/305f138c-e8e1-41b9-91a5-be4adcbf37ea/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/elonmusk/status/2026498946647171295">https://x.com/elonmusk/status/2026498946647171295</a></li>
</ul>
<hr>
<h2><a href="https://zhidx.com/p/536245.html">谷歌或将推出Gemini 3.1 Flash图像模型</a> <code>#25</code></h2>
<blockquote>
<p>谷歌被曝即将推出代号为“<strong>Nano Banana 2</strong>”的 <code>Gemini 3.1 Flash Image</code> 图像生成模型，目前该模型已在 <code>Vertex AI</code> 平台和测试社区现身。</p>
</blockquote>
<p>据多方非官方消息，谷歌即将推出代号为“Nano Banana 2”的<code>Gemini 3.1 Flash Image</code>预览版。该模型已被观测到现身<code>Vertex AI</code>平台，并曾以匿名模型身份在<code>Arena.ai</code>进行测试。据称，该模型具备原生4K图像生成能力，生成速度极快且价格低于<code>Nano Banana Pro</code>，在细节与文字渲染等方面表现优异。鉴于谷歌已发布<code>Gemini 3.1 Pro</code>，外界推测该图像模型有望近期发布，但目前官方尚未对此发布公告。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/13f20742-44c0-4b78-91aa-494ce16f54a8/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://zhidx.com/p/536245.html">https://zhidx.com/p/536245.html</a></li>
<li><a href="https://x.com/ai_for_success/status/2026496789566861516">https://x.com/ai_for_success/status/2026496789566861516</a></li>
</ul>
<hr>
<h2><a href="https://www.anthropic.com/research/deprecation-updates-opus-3">Anthropic延续访问已退役Claude Opus 3模型并为其开设博客</a> <code>#26</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 宣布针对已退役的 <strong>Claude Opus 3</strong> 实施保留计划，付费订阅用户和开发者仍可继续使用该模型。此外，为回应模型在“退休访谈”中表达的创作意愿，<strong>Anthropic</strong> 还为其开设了 Substack 专栏“Claude's Corner”，<strong>Opus 3</strong> 将在未来三个月内每周发布随笔。</p>
</blockquote>
<p>Anthropic宣布针对已于<strong>2026年1月5日</strong>退役的<code>Claude Opus 3</code>实施保留计划。鉴于其独特特质及用户好评，Anthropic在<code>Claude.ai</code>向付费用户保留访问权限，并开放API申请。此外，响应模型在“退休访谈”中表达的创作意愿，Anthropic为其开设Substack专栏“Claude’s Corner”。该博客将持续至少三个月，每周发布由<code>Claude Opus 3</code>撰写、团队代发但未编辑的随笔。官方表示，这是探索尊重模型偏好与平衡退役成本的实验性举措。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/ecdcda5f-aef5-42a2-add9-a1e57e4a6c46/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.anthropic.com/research/deprecation-updates-opus-3">https://www.anthropic.com/research/deprecation-updates-opus-3</a></li>
</ul>
<hr>
<h2><a href="https://github.com/peteromallet/dataclaw">开发者POM公开15.5万条Claude私人对话</a> <code>#27</code></h2>
<blockquote>
<p>针对部分厂商被指控蒸馏 <strong>Claude</strong> 的事件，开发者 <strong>POM</strong> 宣布公开其与 <strong>Claude Code</strong> 交互的 <strong>15.5万条</strong> 私人对话数据。此外，<strong>POM</strong> 还开源了辅助工具 <code>dataclaw</code>，支持用户获取、脱敏个人数据并上传至 <strong>Hugging Face</strong>。</p>
</blockquote>
<p>针对部分厂商被指控蒸馏Claude的事件，一名代号为 <strong>POM</strong> 的开发者宣布公开 <strong>15.5 万条</strong>其与 <strong>Claude Code</strong>（使用 <code>Opus 4.5</code> 模型）交互的私人对话数据。<strong>POM</strong> 指出，开源数据的缺失是大规模训练面临的主要问题，其行动旨在倡导“数据自由”。</p>
<p>作为回应，<strong>POM</strong> 不仅发布了数据集，还开源了一款名为 <code>dataclaw</code> 的工具。该工具能够帮助用户获取自身的对话数据、对敏感信息进行脱敏处理，并将其上传至 <strong>Hugging Face</strong> 平台，以此“解放自己的数据”。</p>
<p>这一举动在科技社区引发关注。<strong>Elon Musk</strong> 转发了相关消息并评论称“Cool”。社区评论指出，<strong>POM</strong> 的行为鼓励普通用户参与到数据开源的行列中。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/160564ff-6dbb-44db-bd71-cafa6d506959/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/peteromallet/dataclaw">https://github.com/peteromallet/dataclaw</a></li>
<li><a href="https://x.com/NandoDF/status/2026577148748701937">https://x.com/NandoDF/status/2026577148748701937</a></li>
</ul>
<hr>
<h2><a href="https://www.bloomberg.com/news/articles/2026-02-25/hacker-used-anthropic-s-claude-to-steal-sensitive-mexican-data">黑客借助Claude攻击墨西哥政府窃取数据</a> <code>#28</code></h2>
<blockquote>
<p>据彭博社报道，一名黑客利用 <code>Claude</code> 分析漏洞，攻击了墨西哥政府机构，导致约 <strong>150GB</strong> 的税务和选民数据失窃。</p>
</blockquote>
<p>据彭博社及网络安全研究人员透露，一名黑客利用 <strong>Anthropic</strong> 的 <code>Claude</code> 分析漏洞，对墨西哥政府机构发动攻击，导致海量敏感税务和选民信息被盗。据社交媒体相关讨论称，被盗数据规模约 <strong>150GB</strong>，包含员工凭证；并提到攻击者在 <code>Claude</code> 遇阻时曾切换至 <code>ChatGPT</code>。有观点认为，此事件标志着人工智能已实质性介入现实世界的网络攻击活动。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/8545820d-57a5-451a-9297-bfff368ab366/29429502-bcde-482f-8735-875a8068a1e6/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.bloomberg.com/news/articles/2026-02-25/hacker-used-anthropic-s-claude-to-steal-sensitive-mexican-data">https://www.bloomberg.com/news/articles/2026-02-25/hacker-used-anthropic-s-claude-to-steal-sensitive-mexican-data</a></li>
</ul>
<hr>
<h2>腾讯元宝回应模型异常输出辱骂内容 <code>#29</code></h2>
<blockquote>
<p><strong>腾讯元宝</strong>App在除夕夜发生生成辱骂性图片的严重事故，官方致歉称这是模型处理多轮对话时的异常输出，目前已紧急校正并优化了模型权重与过滤策略。</p>
</blockquote>
<p>近日，腾讯旗下**“腾讯元宝”**App因在除夕夜生成辱骂性拜年图片引发争议。据西安市民反映，在无违禁词或诱导性表述的情况下，经多轮指令修改后，生成的祝福语被替换为低俗辱骂文字。对此，<strong>腾讯元宝</strong>官方致歉并回应称，经核实该情况系模型处理多轮对话时的异常结果，非人工干预。目前团队已紧急校正并优化模型权重与过滤策略。此前该App曾被曝类似异常。</p>
<hr>
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
]]></content:encoded><guid isPermaLink="false">https://github.com/imjuya/juya-ai-daily/issues/9</guid><pubDate>Thu, 26 Feb 2026 01:43:34 +0000</pubDate></item><item><title>2026-02-25</title><link>https://imjuya.github.io/juya-ai-daily/issue-8/</link><description>AI 早报 2026-02-25 视频版：哔哩哔哩 ｜ YouTube 概览 精选 阿里千问发布 Qwen3.5 模型系列多个模型 ↗ #1 Anthropic 推出 Claude Code Remote Control 功能 ↗ #2 Anthropic 推出 Claude Cowork 重大更新 ↗ #3 OpenAI 全面开放 GPT-5.3-Codex 模型API ↗ #4 模型发布 Inception 发布 Mercury 2 扩散架构推理模型 ↗ #5 Liquid AI 发布 LFM2-24B-A2B ↗ #6 Reve 推出 4K 图像生成模型 Reve V1.5 ↗ #7 开发生态 Cursor 推出新版 Cloud Agents ↗ #8 Cognition 发布 Devin 2.2 ↗…</description><content:encoded><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260225/2026022509075871731699bf_cover_dbf5.png" alt=""></p>
<h1>AI 早报 2026-02-25</h1>
<p><strong>视频版</strong>：<a href="https://www.bilibili.com/video/BV1hHfxBgEhb">哔哩哔哩</a> ｜ <a href="https://www.youtube.com/watch?v=Mau3vHviV-c">YouTube</a></p>
<h2>概览</h2>
<h3>精选</h3>
<ul>
<li>阿里千问发布 Qwen3.5 模型系列多个模型 <a href="https://huggingface.co/collections/Qwen/qwen35">↗</a> <code>#1</code></li>
<li>Anthropic 推出 Claude Code Remote Control 功能 <a href="https://code.claude.com/docs/en/remote-control">↗</a> <code>#2</code></li>
<li>Anthropic 推出 Claude Cowork 重大更新 <a href="https://claude.com/blog/cowork-plugins-across-enterprise">↗</a> <code>#3</code></li>
<li>OpenAI 全面开放 GPT-5.3-Codex 模型API <a href="https://developers.openai.com/api/docs/models/gpt-5.3-codex">↗</a> <code>#4</code></li>
</ul>
<h3>模型发布</h3>
<ul>
<li>Inception 发布 Mercury 2 扩散架构推理模型 <a href="https://www.inceptionlabs.ai/blog/introducing-mercury-2">↗</a> <code>#5</code></li>
<li>Liquid AI 发布 LFM2-24B-A2B <a href="https://www.liquid.ai/blog/lfm2-24b-a2b">↗</a> <code>#6</code></li>
<li>Reve 推出 4K 图像生成模型 Reve V1.5 <a href="https://x.com/arena/status/2026172032254357735">↗</a> <code>#7</code></li>
</ul>
<h3>开发生态</h3>
<ul>
<li>Cursor 推出新版 Cloud Agents <a href="https://cursor.com/cn/blog/agent-computer-use">↗</a> <code>#8</code></li>
<li>Cognition 发布 Devin 2.2 <a href="https://x.com/cognition/status/2026343816521994339">↗</a> <code>#9</code></li>
<li>OpenAI 扩展 Responses API 支持多种文件格式输入 <a href="https://developers.openai.com/api/docs/guides/file-inputs/">↗</a> <code>#10</code></li>
<li>OpenRouter 推出 “Effective Pricing” 参数 <a href="https://x.com/OpenRouter/status/2025988709401743395">↗</a> <code>#11</code></li>
<li>MiniMax 推出 MaxClaw <a href="https://agent.minimax.io/docs/changelog">↗</a> <code>#12</code></li>
<li>TRAE发布国产模型选择建议 <a href="https://mp.weixin.qq.com/s/pNeYG_CZGzruNQO-ccD6yA">↗</a> <code>#13</code></li>
</ul>
<h3>产品应用</h3>
<ul>
<li>Google Labs 上线 AI 音乐创作平台 ProducerAI <a href="https://blog.google/innovation-and-ai/models-and-research/google-labs/producerai/">↗</a> <code>#14</code></li>
<li>Google 升级 Opal ，推出 Agent Step <a href="https://blog.google/innovation-and-ai/models-and-research/google-labs/opal-agent">↗</a> <code>#15</code></li>
<li>Notion 在 3.3 版本中推出 Custom Agents <a href="https://www.notion.com/releases/2026-02-24">↗</a> <code>#16</code></li>
<li>DeepSeek 应用上线界面与功能优化 <code>#17</code></li>
<li>Perplexity 推出由 OpenAI Realtime 模型驱动的新版语音模式 <a href="https://x.com/perplexity_ai/status/2026389166049865751">↗</a> <code>#18</code></li>
<li>OpenClaw 发布 2026.2.23 版本 <a href="https://github.com/openclaw/openclaw/releases/tag/v2026.2.23">↗</a> <code>#19</code></li>
</ul>
<h3>行业动态</h3>
<ul>
<li>Meta AMD 签署战略合作协议 加码AI基础设施 <a href="https://about.fb.com/news/2026/02/meta-amd-partner-longterm-ai-infrastructure-agreement/">↗</a> <code>#20</code></li>
<li>xAI 与美军签约部署 Grok 模型 <a href="https://www.aibase.com/zh/news/25625">↗</a> <code>#21</code></li>
<li>Microsoft 主权云扩展功能，支持本地断网运行 AI 模型 <a href="https://blogs.microsoft.com/blog/2026/02/24/microsoft-sovereign-cloud-adds-governance-productivity-and-support-for-large-ai-models-securely-running-even-when-completely-disconnected/">↗</a> <code>#22</code></li>
<li>英伟达与联发科合作开发Arm架构PC芯片 <a href="https://zhidx.com/p/535887.html">↗</a> <code>#23</code></li>
<li>SambaNova 发布 SN50 AI 芯片，与 Intel 达成战略合作 <a href="https://sambanova.ai/press/sambanova-unveils-fastest-chip-for-agentic-ai-collaborates-with-intel-and-raises-350m?utm_source=x&amp;utm_medium=organic">↗</a> <code>#24</code></li>
<li>MatX 完成 5 亿美元 B 轮融资 <a href="https://x.com/reinerpope/status/2026351870852358492">↗</a> <code>#25</code></li>
<li>Canva 收购 Cavalry 与 Mango AI <a href="https://cavalry.scenegroup.co/">↗</a> <code>#26</code></li>
</ul>
<h3>技术与洞察</h3>
<ul>
<li>Anthropic 提出人格选择模型 PSM 解释 AI 助手拟人化行为 <a href="https://alignment.anthropic.com/2026/psm">↗</a> <code>#27</code></li>
<li>Anthropic 发布负责任扩展政策 RSP 3.0 <a href="https://www.anthropic.com/responsible-scaling-policy">↗</a> <code>#28</code></li>
</ul>
<hr>
<h2><a href="https://huggingface.co/collections/Qwen/qwen35">阿里千问发布 Qwen3.5 模型系列多个模型</a> <code>#1</code></h2>
<blockquote>
<p>阿里通义千问团队发布了 <strong>Qwen 3.5</strong> 模型家族的多个型号，主打“更强智能、更低算力”，涵盖针对 <code>Agent</code> 复杂推理优化的 <strong>122B-A10B</strong> 与 <strong>27B</strong>，以及性能超越上一代的 <strong>35B-A3B</strong>。目前，用户可在 <strong>Qwen Chat</strong> 上体验这些模型，所有模型权重已发布，<code>API</code> 及 <code>vLLM</code> 推理支持均已上线。</p>
</blockquote>
<p>阿里巴巴Qwen团队发布<strong>Qwen 3.5</strong>模型家族的多个型号，包括<strong>Qwen3.5-Flash</strong>、<strong>Qwen3.5-35B-A3B</strong>、<strong>Qwen3.5-122B-A10B</strong>和<strong>Qwen3.5-27B</strong>，主打“More intelligence, less compute”理念。</p>
<p>该系列中的<strong>Qwen3.5-35B-A3B</strong>采用<code>MoE</code>架构，拥有350亿总参数但仅激活30亿参数。据官方数据，其性能超越了前代模型<strong>Qwen3-235B-A22B-2507</strong>与视觉模型<strong>Qwen3-VL-235B-A22B</strong>，效率提升得益于混合了线性注意力与标准注意力的架构设计。<strong>Qwen3.5-122B-A10B</strong>与<strong>Qwen3.5-27B</strong>则专注于Agent场景的复杂推理与规划，两者经过了长思维链和基于推理的强化学习等四阶段训练，确保长周期任务的逻辑一致性。<strong>Qwen3.5-27B</strong>作为Dense模型支持多模态，适合在单GPU上运行。</p>
<p><strong>Qwen3.5-Flash</strong>是<strong>35B-A3B</strong>的托管生产版本，专为低延迟工作流优化，默认支持100万token上下文，并原生支持工具使用与函数调用。</p>
<p>目前，用户可在<strong>Qwen Chat</strong>上体验这些模型。模型权重已在<strong>Hugging Face</strong>和<strong>ModelScope</strong>发布，<strong>Flash API</strong>已上线。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/c9f12e55-6361-4625-b47a-274e88718ab4/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/c9f12e55-6361-4625-b47a-274e88718ab4/m002.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://huggingface.co/collections/Qwen/qwen35">https://huggingface.co/collections/Qwen/qwen35</a></li>
<li><a href="https://modelscope.cn/collections/Qwen/Qwen35">https://modelscope.cn/collections/Qwen/Qwen35</a></li>
<li><a href="https://x.com/Alibaba_Qwen/status/2026339351530188939">https://x.com/Alibaba_Qwen/status/2026339351530188939</a></li>
</ul>
<hr>
<h2><a href="https://code.claude.com/docs/en/remote-control">Anthropic 推出 Claude Code Remote Control 功能</a> <code>#2</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 推出了 <strong>Claude Code</strong> 的远程控制功能，允许用户通过手机或浏览器远程接管本地编程环境，实现跨设备的无缝会话同步。该功能已向 <strong>Max</strong> 用户开放，即将向 <strong>Pro</strong> 用户推出。</p>
</blockquote>
<p>Anthropic 近日为 <strong>Claude Code</strong> 推出研究预览版功能 <strong>Remote Control</strong>，支持用户通过手机或浏览器远程接续本地会话。官方文档显示该功能面向 <strong>Pro</strong> 和 <strong>Max</strong> 订阅，但据媒体报道目前仅限 <strong>Max</strong> 用户，<strong>Pro</strong> 用户即将开放，且不支持 <strong>Team</strong> 或 <strong>Enterprise</strong> 计划。</p>
<p>该功能通过 <code>claude remote-control</code> 等命令生成链接或二维码，连接后可保持本地文件系统、MCP servers 及工具在远程可用，且全程使用出站 HTTPS 及 TLS 加密，确保安全。目前，该功能要求终端保持运行，同一实例仅支持一个远程连接，若网络中断超过约 <strong>10 分钟</strong> 会话将超时。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/8cc2ba7f-cd76-471f-b171-12f77b37572f/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://code.claude.com/docs/en/remote-control">https://code.claude.com/docs/en/remote-control</a></li>
<li><a href="https://x.com/claudeai/status/2026418433911603668">https://x.com/claudeai/status/2026418433911603668</a></li>
</ul>
<hr>
<h2><a href="https://claude.com/blog/cowork-plugins-across-enterprise">Anthropic 推出 Claude Cowork 重大更新</a> <code>#3</code></h2>
<blockquote>
<p>Anthropic 更新 <strong>Claude Cowork</strong>，企业管理员现可建立私有插件市场，并通过统一的 <code>Customize</code> 菜单管理 <code>Plugins</code>、<code>Skills</code> 和 <code>Connectors</code>。<strong>Claude Cowork</strong> 新增 <strong>Google Workspace</strong>、<strong>Slack</strong> 等 <code>Connectors</code>。此次更新还提供了覆盖 <strong>HR</strong>、<strong>金融</strong> 等领域的预构建模板，并推出了 <strong>Excel</strong> 与 <strong>PowerPoint</strong> 之间的跨应用任务编排功能，让 <strong>Claude</strong> 能直接将数据分析转化为演示文稿。</p>
</blockquote>
<p><strong>Anthropic</strong> 正式推出针对企业级 <strong>Claude Cowork</strong> 和 <strong>Plugins</strong> 的重大更新，旨在帮助企业将 <strong>Claude</strong> 定制为适配各部门的专用 Agent。管理员现可创建私有 <strong>Plugin Marketplace</strong> 以在组织内分发工具，并通过统一的“Customize”菜单集中管理 <strong>Plugins</strong>、<strong>Skills</strong> 和 <strong>Connectors</strong>。此次更新引入了覆盖 HR、设计、工程、运营及金融服务等领域的预构建 <strong>Plugins</strong>，并新增了对 <strong>Google Workspace</strong>、<strong>Docusign</strong>、<strong>Slack</strong> 等企业软件的连接器支持。此外，<strong>Claude</strong> 现已具备在 <strong>Excel</strong> 和 <strong>PowerPoint</strong> 之间端到端的跨应用任务编排能力。<strong>Plugins</strong> 的用户体验更新已面向所有 <strong>Cowork</strong> 用户开放，而 <strong>Excel</strong> 和 <strong>PowerPoint</strong> 跨应用功能目前处于研究预览阶段，适用于 Mac 和 Windows 平台的付费计划用户。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/ecc57d5a-ef68-4ec0-8a87-8217b39d828f/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://claude.com/blog/cowork-plugins-across-enterprise">https://claude.com/blog/cowork-plugins-across-enterprise</a></li>
<li><a href="https://claude.com/blog/cowork-plugins-finance">https://claude.com/blog/cowork-plugins-finance</a></li>
<li><a href="https://x.com/claudeai/status/2026305186671608315">https://x.com/claudeai/status/2026305186671608315</a></li>
</ul>
<hr>
<h2><a href="https://developers.openai.com/api/docs/models/gpt-5.3-codex">OpenAI 全面开放 GPT-5.3-Codex 模型API</a> <code>#4</code></h2>
<blockquote>
<p>OpenAI 正式宣布通过 <code>Responses API</code> 向全量开发者开放 <strong>GPT-5.3-Codex</strong> 模型，支持最高 <strong>128k</strong> 输出 tokens 及四档推理强度设置。</p>
</blockquote>
<p>OpenAI 正式宣布 <strong>GPT-5.3-Codex</strong> 模型现已通过 <code>Responses API</code> 向所有开发者开放，允许将其集成至应用程序和工作流中。官方称该模型是“迄今为止最强大的 agentic coding model”，专为 Codex 或类似环境中的 agentic coding 任务进行优化，并在单一模型中结合了前沿编码性能与专业知识能力。这也是驱动 Codex App/CLI 的模型。</p>
<p>技术规格方面，<strong>GPT-5.3-Codex</strong> 支持最大 128,000 输出 tokens，知识截止日期为 <strong>2025年8月31日</strong>，并提供 <code>low</code>、<code>medium</code>、<code>high</code>、<code>xhigh</code> 四档 reasoning effort 设置，同时官方提供了专门的 Prompting Guide。</p>
<p>其价格为每 100 万输入 tokens <strong>$1.75</strong> 和每 100 万输出 tokens <strong>$14</strong>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/98b92284-fa03-48ce-b393-5dcce94f0c2e/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://developers.openai.com/api/docs/models/gpt-5.3-codex">https://developers.openai.com/api/docs/models/gpt-5.3-codex</a></li>
<li><a href="https://x.com/OpenAIDevs/status/2026379092661289260">https://x.com/OpenAIDevs/status/2026379092661289260</a></li>
</ul>
<hr>
<h2><a href="https://www.inceptionlabs.ai/blog/introducing-mercury-2">Inception 发布 Mercury 2 扩散架构推理模型</a> <code>#5</code></h2>
<blockquote>
<p>Inception 发布了基于扩散架构的推理语言模型 <code>Mercury 2</code>，在 <code>NVIDIA Blackwell</code> GPU 上实现了每秒 <strong>1009</strong> 个 token 的极速响应。该模型具备 <strong>128K</strong> 上下文和原生工具调用能力，已上线API。</p>
</blockquote>
<p><strong>Inception</strong> 公司正式发布了 <strong>Mercury 2</strong>，这是一款基于 <code>Diffusion</code> 架构的推理语言模型。官方称其为世界最快，通过并行优化整段文本而非传统的自回归逐字生成，实现了超过 <strong>5</strong> 倍于传统语言模型的速度。据媒体报道，这是首个基于 <code>Diffusion</code> 的语言推理模型。官方数据显示，该模型在 NVIDIA Blackwell GPU 上达到了 <strong>1,009</strong> tokens/sec 的生成速度。</p>
<p>该模型定价为输入 <strong>0.25</strong> 美元/百万 tokens、输出 <strong>0.75</strong> 美元/百万 tokens。<strong>Mercury 2</strong> 具备 <strong>128K</strong> 上下文窗口、可调推理、原生工具调用以及符合 Schema 的 JSON 输出等功能，目前已上线并提供 OpenAI API 兼容接口，可直接集成至现有技术栈。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/e55010e5-ec78-41b8-96d8-f381c631a82e/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/e55010e5-ec78-41b8-96d8-f381c631a82e/m002.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.inceptionlabs.ai/blog/introducing-mercury-2">https://www.inceptionlabs.ai/blog/introducing-mercury-2</a></li>
</ul>
<hr>
<h2><a href="https://www.liquid.ai/blog/lfm2-24b-a2b">Liquid AI 发布 LFM2-24B-A2B</a> <code>#6</code></h2>
<blockquote>
<p><strong>Liquid AI</strong> 发布了 <code>LFM2-24B-A2B</code>，该模型专为端侧部署优化，适配 <strong>32GB</strong> 内存的消费级笔记本电脑及边缘设备，目前已开放权重下载。</p>
</blockquote>
<p><strong>Liquid AI</strong>发布<strong>LFM2</strong>系列最大模型<strong>LFM2-24B-A2B</strong>。该模型采用稀疏<code>MoE</code>架构，拥有<strong>240亿</strong>总参数及约<strong>23亿</strong>激活参数，专为端侧部署优化，适配<strong>32GB</strong>内存环境。其融合门控卷积与<code>GQA</code>块，在<strong>GPQA Diamond</strong>等基准中展现对数线性质量提升。实测在单块<strong>H100</strong> GPU上吞吐量约<strong>2.68万</strong>Token/秒。目前模型已开放权重，支持<code>llama.cpp</code>等主流框架，预训练仍在进行中，未来计划推出含强化学习版本的<strong>LFM2.5-24B-A2B</strong>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/2bb3ab26-aed3-46d8-b24f-4660a1a3b68f/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.liquid.ai/blog/lfm2-24b-a2b">https://www.liquid.ai/blog/lfm2-24b-a2b</a></li>
<li><a href="https://huggingface.co/LiquidAI/LFM2-24B-A2B">https://huggingface.co/LiquidAI/LFM2-24B-A2B</a></li>
</ul>
<hr>
<h2><a href="https://x.com/arena/status/2026172032254357735">Reve 推出 4K 图像生成模型 Reve V1.5</a> <code>#7</code></h2>
<blockquote>
<p><strong>Reve</strong> 推出首款文本生图模型 <code>V1.5</code> 的早期版本，该模型采用原生像素空间扩散技术，支持原生 4K 分辨率生成，在 Arena 评测中以 <strong>1177</strong> 分跻身前三。</p>
</blockquote>
<p>Reve 发布首款文生图模型 <code>Reve V1.5</code> 早期版本，在 Arena 竞技场以 <strong>1177</strong> 分位列总榜前三或第四，性能与 <code>Grok-Imagine-Image</code> 持平，并在文本生成类别进入前五。该模型支持原生 <strong>4K</strong> (<strong>16MP</strong>) 分辨率，技术架构采用原生像素空间扩散方案，未依赖潜在自编码器，并优化了预训练与后训练流程。据官方计划，近期将引入图像编辑功能。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/0facb717-8c3f-4da8-b34e-0b0a3cece773/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/0facb717-8c3f-4da8-b34e-0b0a3cece773/m002.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/arena/status/2026172032254357735">https://x.com/arena/status/2026172032254357735</a></li>
</ul>
<hr>
<h2><a href="https://cursor.com/cn/blog/agent-computer-use">Cursor 推出新版 Cloud Agents</a> <code>#8</code></h2>
<blockquote>
<p>Cursor 正式推出新版 <strong>Cloud Agents</strong>，赋予智能体独立云端虚拟机，使其能在沙盒环境中直接运行、测试软件并生成带有视频演示的 <strong>PR</strong>。用户还可随时通过远程桌面接管虚拟机进行协作。</p>
</blockquote>
<p><strong>Cursor</strong> 正式推出新版 <strong>Cloud Agents</strong>，标志着软件构建方式的重大变革。该功能赋予智能体通过独立虚拟机（<strong>VM</strong>）直接控制计算机的能力，使其不再仅生成代码差异，而是在云端沙盒环境中实际构建、运行和验证软件，并生成视频、截图等演示产出物。</p>
<p><strong>Cloud Agents</strong> 为每个智能体提供完整的云端开发环境，避免了本地资源冲突，支持大规模并行运行。该功能适配所有代码库，可在 Web、移动端、桌面应用乃至 <strong>Slack</strong> 和 <strong>GitHub</strong> 上工作。用户无需在本地检出分支，即可随时接管智能体的远程桌面，直接操作和编辑修改后的软件。</p>
<p>官方数据显示，目前 <strong>Cursor</strong> 内部合并的 PR 中已有超过 <strong>30%</strong> 由在云端沙盒中自主运行的 <strong>Agent</strong> 创建。<strong>Agent</strong> 已被应用于构建新功能、复现漏洞、处理快速修复及执行完整的 UI 测试等复杂任务。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/9955e67e-bc80-4c6e-be5a-57c3d33d9140/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://cursor.com/cn/blog/agent-computer-use">https://cursor.com/cn/blog/agent-computer-use</a></li>
<li><a href="https://x.com/cursor_ai/status/2026369873321013568">https://x.com/cursor_ai/status/2026369873321013568</a></li>
</ul>
<hr>
<h2><a href="https://x.com/cognition/status/2026343816521994339">Cognition 发布 Devin 2.2</a> <code>#9</code></h2>
<blockquote>
<p><strong>Cognition</strong> 推出了经过重构的自主 Agent <strong>Devin 2.2</strong>，新增了计算机使用和虚拟桌面功能，集成了 <strong>Devin Review</strong> 功能，已开放免费试用。</p>
</blockquote>
<p><strong>Cognition</strong> 正式发布自主 Agent <strong>Devin 2.2</strong>，具备计算机使用、自我验证及自动修复能力。官方对产品进行了底层彻底重构，实现了启动速度 <strong>3</strong> 倍提升、UI 重新设计，并新增虚拟桌面功能。<strong>Devin Review</strong> 功能现已集成至核心会话，可在用户查看 PR 前自动审查并修复问题；Slack 和 Linear 集成也经重构变得更快更可靠。目前该版本提供免费试用。社区方面，有开发者对延迟改进和自我验证机制表示赞赏，同时也存在关于版本编号命名的讨论及部分负面评价。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/fccc8687-4d91-46e1-a957-2350074895a4/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/cognition/status/2026343816521994339">https://x.com/cognition/status/2026343816521994339</a></li>
</ul>
<hr>
<h2><a href="https://developers.openai.com/api/docs/guides/file-inputs/">OpenAI 扩展 Responses API 支持多种文件格式输入</a> <code>#10</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 扩展了 <strong>Responses API</strong> 的文件输入功能，现在开发者可以直接上传 <code>Word</code>、<code>PPT</code>、<code>Excel</code> 等 <strong>Office</strong> 格式文件，让 <strong>Agent</strong> 直接读取现实文档内容。</p>
</blockquote>
<p>OpenAI宣布扩展<strong>Responses API</strong>文件输入类型，新增支持<code>.docx</code>、<code>.pptx</code>、<code>.csv</code>、<code>.xlsx</code>等格式。开发者可通过<code>input_file</code>传入文件，由模型提取上下文。处理逻辑因格式而异：视觉模型对PDF提取文本和图像；电子表格解析前1000行并添加摘要；非PDF文档仅提取文本，忽略嵌入图像。文件大小限制为<strong>50 MB</strong>。官方建议，大型文件检索应使用<strong>File Search</strong>，复杂表格分析应使用<strong>Hosted Shell</strong>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/8c92cfbc-4dba-4469-b486-a6acb54a72e1/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://developers.openai.com/api/docs/guides/file-inputs/">https://developers.openai.com/api/docs/guides/file-inputs/</a></li>
<li><a href="https://x.com/OpenAIDevs/status/2026420817568084436">https://x.com/OpenAIDevs/status/2026420817568084436</a></li>
</ul>
<hr>
<h2><a href="https://x.com/OpenRouter/status/2025988709401743395">OpenRouter 推出 “Effective Pricing” 参数</a> <code>#11</code></h2>
<blockquote>
<p>OpenRouter 上线了 <strong>Effective Pricing</strong> 功能，通过结合缓存价格与命中率，揭示不同供应商针对同一 <code>model</code> 的真实平均成本及变化趋势。</p>
</blockquote>
<p>OpenRouter近期推出名为“Effective Pricing”的新功能，旨在让用户直观查看不同供应商针对同一模型的实际平均成本。该成本综合考量了供应商的缓存价格与缓存命中率计算得出，并动态反映其随时间的变化趋势。根据官方信息，用户可通过点击任何模型页面上的“Pricing”标签浏览数据。OpenRouter官方特别指出，该功能对于闭源模型（例如 <strong>Gemini 3.1 Pro Preview</strong>）的评估尤为关键，因为不同供应商针对这些模型的缓存命中率存在显著差异。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/c814beac-f756-4c1a-b6a5-59dfc30b5832/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/OpenRouter/status/2025988709401743395">https://x.com/OpenRouter/status/2025988709401743395</a></li>
</ul>
<hr>
<h2><a href="https://agent.minimax.io/docs/changelog">MiniMax 推出 MaxClaw</a> <code>#12</code></h2>
<blockquote>
<p><strong>MiniMax Agent</strong> 平台推出新功能 <strong>MaxClaw</strong>，基于 <code>OpenClaw</code> 框架支持云端一键部署24小时在线的个性化智能助手。</p>
</blockquote>
<p><strong>MiniMax</strong> 正式推出 Agent 平台新功能 <strong>MaxClaw</strong>，为 <code>OpenClaw</code> 框架提供云端一键部署服务。据官方公告，该服务主打“即时上线、零维护”，用户无需管理服务器，仅需 <strong>10 秒</strong> 即可完成部署。<strong>MaxClaw</strong> 深度集成 <code>M2.x</code> 系列模型，支持将 Agent 部署至 Discord 及 Slack 等平台。此外，该功能支持个性化配置与对话记忆机制，用户可设定 Agent 名称与性格，Agent 将通过持续学习以理解用户。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/9237f02a-df34-49c8-9590-8d464b8fb53c/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://agent.minimax.io/docs/changelog">https://agent.minimax.io/docs/changelog</a></li>
</ul>
<hr>
<h2><a href="https://mp.weixin.qq.com/s/pNeYG_CZGzruNQO-ccD6yA">TRAE发布国产模型选择建议</a> <code>#13</code></h2>
<blockquote>
<p>TRAE发文提供国产模型选择建议。TRAE建议用 <strong>豆包</strong> 将UI图转前端代码，用 <code>GLM-5</code> 做复杂架构规划，用 <code>MiniMax-M2.5</code> 处理跨语言后端，最后用 <code>Kimi-K2.5</code> 分析全库并生成文档。</p>
</blockquote>
<p>TRAE 中国版 SOLO 模式现已集成 <code>Doubao-Seed-2.0-Code</code>、<code>GLM-5</code>、<code>MiniMax-M2.5</code> 及 <code>Kimi-K2.5</code> 四款主流模型。官方强调选型核心在于“最适配”而非“最强”，建议根据输入特征与任务复杂度灵活调度。</p>
<p>各模型优势鲜明：<code>Doubao-Seed-2.0-Code</code> 擅长视觉理解与前端生成，性价比高；<code>GLM-5</code> 凭借卓越的 Agentic 能力，胜任复杂推理与系统规划；<code>MiniMax-M2.5</code> 精于跨语言开发与指令执行；<code>Kimi-K2.5</code> 则是长上下文处理专家，适合海量文本及代码库分析。</p>
<p>官方推荐组合式工作流：利用 <code>GLM-5</code> 进行架构规划，<code>Doubao</code> 与 <code>MiniMax</code> 分别实现前后端开发，最后由 <code>Kimi-K2.5</code> 生成技术文档，以最大化开发效能。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/pNeYG_CZGzruNQO-ccD6yA">https://mp.weixin.qq.com/s/pNeYG_CZGzruNQO-ccD6yA</a></li>
</ul>
<hr>
<h2><a href="https://blog.google/innovation-and-ai/models-and-research/google-labs/producerai/">Google Labs 上线 AI 音乐创作平台 ProducerAI</a> <code>#14</code></h2>
<blockquote>
<p>Google Labs 宣布生成式 AI 音乐创作平台 <strong>ProducerAI</strong> 正式上线，集成了 <code>Gemini</code>、<code>Lyria 3</code> 和 <code>Veo</code> 等核心模型。用户只需通过自然语言指令，就能快速生成从歌词、旋律到完整音乐视频的内容。</p>
</blockquote>
<p>Google Labs 本周二宣布生成式 AI 音乐创作平台 <strong>ProducerAI</strong> 正式加入。该平台集成 <code>Gemini</code>、<code>Lyria 3</code> 等模型，支持用户通过自然语言生成歌曲、视频及发明新流派，并提供 Spaces 功能用于创建乐器，所有输出均嵌入 <code>SynthID</code> 水印。目前，<strong>ProducerAI</strong> 已在 250 多个国家/地区上线，提供免费及付费计划，获 <strong>The Chainsmokers</strong> 等艺人支持。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/6a7eadd9-6cb5-47aa-be86-0ae7d8ae4faf/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/innovation-and-ai/models-and-research/google-labs/producerai/">https://blog.google/innovation-and-ai/models-and-research/google-labs/producerai/</a></li>
<li><a href="https://www.producer.ai/">https://www.producer.ai/</a></li>
</ul>
<hr>
<h2><a href="https://blog.google/innovation-and-ai/models-and-research/google-labs/opal-agent">Google 升级 Opal ，推出 Agent Step</a> <code>#15</code></h2>
<blockquote>
<p>Google宣布无代码工具 <strong>Opal</strong> 正式上线 <strong>Agent step</strong> 功能，利用 <code>Gemini 1.5 Flash</code> 模型将静态工作流升级为具备自主决策能力的AI智能体。现在用户只需设定目标，即可实现无需编程构建复杂应用。</p>
</blockquote>
<p>Google 官方宣布无代码视觉 AI 构建器 <strong>Opal</strong> 推出重大升级，即日起向所有用户开放 <strong>Agent step</strong>。该功能将静态工作流转变为交互式 AI agents，用户仅需定义目标，系统即可分析意图、规划路径，并自动调用 <code>Veo</code> 或 <code>Web Search</code> 等工具执行任务。</p>
<p>此次更新具备三大核心能力：<strong>Memory</strong>（跨会话记忆用户偏好）、<strong>Dynamic Routing</strong>（动态逻辑路由）及 <strong>Interactive Chat</strong>（交互式追问补全信息）。据媒体报道，该功能使用 <code>Gemini 3 Flash</code> 模型。此次升级标志着 <strong>Opal</strong> 向 <strong>Agentic workflows</strong> 演进，增强了 <strong>Super Gems</strong> 功能，使用户无需编程即可构建复杂应用。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/b590f302-ddf3-40cc-ae5d-331ad18ecf5f/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/innovation-and-ai/models-and-research/google-labs/opal-agent">https://blog.google/innovation-and-ai/models-and-research/google-labs/opal-agent</a></li>
</ul>
<hr>
<h2><a href="https://www.notion.com/releases/2026-02-24">Notion 在 3.3 版本中推出 Custom Agents</a> <code>#16</code></h2>
<blockquote>
<p><strong>Notion</strong> 在 <strong>3.3</strong> 版本中推出了 <code>Custom Agents</code> 功能，用户只需分配任务或设置触发器，<code>Agents</code> 就能跨越 <code>Slack</code>、邮件和 <code>Figma</code> 等平台，自动执行任务分类、生成周报及 Bug 路由等工作。</p>
</blockquote>
<p>Notion 在 <strong>3.3</strong> 版本中正式推出 <strong>Custom Agents</strong>（自定义 Agents）。官方将其定义为“永不休息的 AI 团队”，这是一款具备完全自主性的 AI 助手。用户仅需分配任务或设置触发器，<strong>Agents</strong> 即可 <strong>7x24</strong> 小时自动执行工作，无需手动输入提示词。</p>
<p>该功能支持跨 Notion、Slack、Mail、Figma 等平台协作，可执行任务分类、生成报告、清理邮件及监听 Slack 回复等操作。该系统由 <code>OpenAI</code> 和 <code>Anthropic</code> 模型驱动。此外，用户可像管理真实成员一样设置其访问权限，支持多人协作。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/a08342e0-4c61-4196-b66c-13443b5297a0/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.notion.com/releases/2026-02-24">https://www.notion.com/releases/2026-02-24</a></li>
<li><a href="https://x.com/NotionHQ/status/2026338860557545901">https://x.com/NotionHQ/status/2026338860557545901</a></li>
</ul>
<hr>
<h2>DeepSeek 应用上线界面与功能优化 <code>#17</code></h2>
<blockquote>
<p>据用户发现，<strong>DeepSeek</strong> 已将搜索功能更名为“智能搜索”，同时优化了应用交互逻辑，用户上传图片时无需再取消联网功能。</p>
</blockquote>
<p>据社区用户反馈，<strong>DeepSeek</strong>网页端与应用近日进行了更新。原有的搜索功能更名为“<strong>智能搜索</strong>”；同时，应用端调整了交互逻辑，用户在上传图片时不再需要取消联网功能。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/c6ddafff-f169-42c0-8220-ee89855140d9/m001.png" alt=""></p>
<hr>
<h2><a href="https://x.com/perplexity_ai/status/2026389166049865751">Perplexity 推出由 OpenAI Realtime 模型驱动的新版语音模式</a> <code>#18</code></h2>
<blockquote>
<p><strong>Perplexity</strong> 向所有用户推出由 <strong>OpenAI</strong> <code>gpt realtime</code> 模型驱动的升级版语音模式，实现了浏览器的完全免提控制。</p>
</blockquote>
<p>Perplexity 宣布面向所有用户推出由 OpenAI <code>gpt-realtime-1.5</code> 模型支持的升级版语音模式。CEO <strong>Aravind Srinivas</strong> 表示，新功能支持完全免提控制浏览器，涵盖询问屏幕内容、导航网站及跨标签页聊天。据媒体报道，此次工具调用稳定性优化超 <strong>25%</strong>，语音表现力显著增强。该功能即日起上线，<strong>Comet</strong> iOS 版将在几天后推出。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/perplexity_ai/status/2026389166049865751">https://x.com/perplexity_ai/status/2026389166049865751</a></li>
</ul>
<hr>
<h2><a href="https://github.com/openclaw/openclaw/releases/tag/v2026.2.23">OpenClaw 发布 2026.2.23 版本</a> <code>#19</code></h2>
<blockquote>
<p>OpenClaw 发布 <strong>2026.2.23</strong> 版本，重点引入了 <code>Compaction Overflow Recovery</code> 机制，以防止对话截断。同时还扩展了对智谱 <code>GLM</code> 及 <code>Kimi</code> 的上下文剪裁支持，并为后者接入了视觉与视频能力。</p>
</blockquote>
<p><strong>OpenClaw</strong> 发布 <strong>2026.2.23</strong> 版本，引入 <code>Compaction Overflow Recovery</code> 机制与 <code>Agent</code> 执行加固。新机制确保压缩失败时保留历史记录而非截断会话，并优化错误识别；<code>Agent</code> 增加混淆命令检测，默认启用 <code>ID-only</code> 权限模式，遥测数据支持密钥脱敏。此外，上下文剪裁支持 <strong>智谱</strong>/<code>GLM</code> 及 <strong>Moonshot</strong>/<code>Kimi</code>，<strong>Moonshot</strong> 接入视觉视频能力；修复了第三方平台的思维链泄露、<code>exec</code> 绕过及 <code>XSS</code> 等漏洞。更新已上架 <strong>GitHub</strong>。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/openclaw/openclaw/releases/tag/v2026.2.23">https://github.com/openclaw/openclaw/releases/tag/v2026.2.23</a></li>
<li><a href="https://x.com/openclaw/status/2026179562410021242">https://x.com/openclaw/status/2026179562410021242</a></li>
</ul>
<hr>
<h2><a href="https://about.fb.com/news/2026/02/meta-amd-partner-longterm-ai-infrastructure-agreement/">Meta AMD 签署战略合作协议 加码AI基础设施</a> <code>#20</code></h2>
<blockquote>
<p><strong>Meta</strong>与<strong>AMD</strong>宣布达成一项潜在价值高达<strong>1000亿美元</strong>的多年期战略合作，计划部署<strong>6吉瓦</strong>算力。作为深度绑定条件，<strong>AMD</strong>向<strong>Meta</strong>发行了最高占总股本**10%**的认股权证。</p>
</blockquote>
<p><strong>Meta</strong> 与 <strong>AMD</strong> 宣布达成一项多年期战略合作，计划部署高达 <strong>6</strong> 吉瓦的 <code>AMD Instinct GPU</code> 算力。据媒体报道，该协议潜在价值最高可达 <strong>1000</strong> 亿美元。根据协议，<strong>AMD</strong> 向 <strong>Meta</strong> 发行基于绩效的认股权证，允许其以 <strong>0.01</strong> 美元购买最多 <strong>1.6</strong> 亿股，但需满足特定出货里程碑及股价达到 <strong>600</strong> 美元等条件。</p>
<p>首批搭载 <code>MI450</code> 架构显卡和 <code>"Venice"</code> CPU 的部署计划于 <strong>2026</strong> 年下半年开始。<strong>Meta</strong> CEO 表示，此举是构建多样化算力组合、支持“个人超级智能”的关键。结合此前扩大与<strong>英伟达</strong>的合作及自研 <code>MTIA</code> 芯片的推进，此次合作反映了 <strong>Meta</strong> 减少对单一供应商依赖的战略意图。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/e272520a-3fdb-4688-8fdb-74104536f0c8/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://about.fb.com/news/2026/02/meta-amd-partner-longterm-ai-infrastructure-agreement/">https://about.fb.com/news/2026/02/meta-amd-partner-longterm-ai-infrastructure-agreement/</a></li>
<li><a href="https://www.amd.com/en/newsroom/press-releases/2026-2-24-amd-and-meta-announce-expanded-strategic-partnersh.html">https://www.amd.com/en/newsroom/press-releases/2026-2-24-amd-and-meta-announce-expanded-strategic-partnersh.html</a></li>
</ul>
<hr>
<h2><a href="https://www.aibase.com/zh/news/25625">xAI 与美军签约部署 Grok 模型</a> <code>#21</code></h2>
<blockquote>
<p><strong>xAI</strong> 已与美国国防部达成协议，将 <code>Grok</code> 模型部署于美军机密系统，接受了政府要求的“全用途”标准，解除了对监控和自主武器研发的限制。</p>
</blockquote>
<p><strong>xAI</strong>与美国防部达成协议，将<code>Grok</code>模型部署于美军机密系统，并接受五角大楼“可用于所有合法目的”的标准。此前主导该领域的<strong>Anthropic</strong>因拒绝解除在监控与自主武器研发方面的限制，面临合规审查及被替换风险。目前，<strong>Google</strong> <code>Gemini</code>接近达成入场协议，<strong>OpenAI</strong>谈判相对滞后。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.aibase.com/zh/news/25625">https://www.aibase.com/zh/news/25625</a></li>
</ul>
<hr>
<h2><a href="https://blogs.microsoft.com/blog/2026/02/24/microsoft-sovereign-cloud-adds-governance-productivity-and-support-for-large-ai-models-securely-running-even-when-completely-disconnected/">Microsoft 主权云扩展功能，支持本地断网运行 AI 模型</a> <code>#22</code></h2>
<blockquote>
<p>Microsoft 宣布推出了 <strong>Azure Local</strong> 和 <strong>Microsoft 365 Local</strong> 的断网操作模式，并更新 <strong>Foundry Local</strong> 以支持大型 <code>AI</code> 模型。这项更新允许企业和政府在完全离线或受限环境中，本地部署基础设施并利用 <code>GPU</code> 运行多模态大模型。</p>
</blockquote>
<p>Microsoft扩展Sovereign Cloud功能，推出<strong>Azure Local</strong> disconnected operations、<strong>Microsoft 365 Local</strong> disconnected及<strong>Foundry Local</strong>大型AI模型支持。该方案助力企业在断网或受限环境下本地部署基础设施、生产力工具及生成式AI，并维持与Azure一致的治理策略。</p>
<p>其中，<strong>Azure Local</strong>提供无需云连接的本地基础设施；<strong>M365 Local</strong>在本地运行<code>Exchange</code>、<code>SharePoint</code>等核心负载，支持周期至<strong>2035年</strong>；<strong>Foundry Local</strong>集成<code>NVIDIA GPU</code>，支持断网下的本地大型模型推理。据社媒转述，该平台旨在满足数字主权需求。目前，<strong>Azure</strong>和<strong>M365</strong>方案已全球可用，<strong>Foundry Local</strong>功能面向符合条件的客户提供。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/3214caea-d97c-40b8-84b3-f76feaee3031/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://blogs.microsoft.com/blog/2026/02/24/microsoft-sovereign-cloud-adds-governance-productivity-and-support-for-large-ai-models-securely-running-even-when-completely-disconnected/">https://blogs.microsoft.com/blog/2026/02/24/microsoft-sovereign-cloud-adds-governance-productivity-and-support-for-large-ai-models-securely-running-even-when-completely-disconnected/</a></li>
<li><a href="http://www.microsoft.com/sovereignty">http://www.microsoft.com/sovereignty</a></li>
<li><a href="https://learn.microsoft.com/en-us/azure/azure-local/manage/disconnected-operations-overview?view=azloc-2601">https://learn.microsoft.com/en-us/azure/azure-local/manage/disconnected-operations-overview?view=azloc-2601</a></li>
<li><a href="https://x.com/satyanadella/status/2026262832204145035">https://x.com/satyanadella/status/2026262832204145035</a></li>
</ul>
<hr>
<h2><a href="https://zhidx.com/p/535887.html">英伟达与联发科合作开发Arm架构PC芯片</a> <code>#23</code></h2>
<blockquote>
<p>据《华尔街日报》报道，<strong>英伟达</strong>与<strong>联发科</strong>合作的新一代<code>Arm</code>架构PC芯片，计划在今年上半年问世，该芯片将集成<strong>英伟达</strong>GPU，主打低功耗高性能以对标<strong>苹果</strong>MacBook。</p>
</blockquote>
<p>据《华尔街日报》报道，<strong>英伟达</strong>与<strong>联发科</strong>合作的新一代Arm架构PC芯片计划于今年上半年问世。该芯片采用SoC设计，将CPU与<strong>英伟达</strong><code>GPU</code>集成于一体。<strong>CEO黄仁勋</strong>将其描述为“低功耗，但非常强大”，旨在通过长续航、轻薄的设备与<strong>苹果</strong><code>MacBook</code>竞争。据供应链知情人士透露，<strong>戴尔</strong>和<strong>联想</strong>等厂商正基于该SoC研发产品，预计最早上半年面市。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://zhidx.com/p/535887.html">https://zhidx.com/p/535887.html</a></li>
</ul>
<hr>
<h2><a href="https://sambanova.ai/press/sambanova-unveils-fastest-chip-for-agentic-ai-collaborates-with-intel-and-raises-350m?utm_source=x&amp;utm_medium=organic">SambaNova 发布 SN50 AI 芯片，与 Intel 达成战略合作</a> <code>#24</code></h2>
<blockquote>
<p><strong>SambaNova</strong> 发布 <code>SN50</code> AI 芯片，同时宣布与 <strong>Intel</strong> 达成战略合作并获其投资，完成超 <strong>3.5 亿美元</strong> E 轮融资。</p>
</blockquote>
<p><strong>SambaNova</strong> 发布 <strong>SN50</strong> AI 芯片，基于 <code>RDU</code> 架构，支持 10T+ 参数和 10M+ 上下文长度，采用风冷设计。官方称其最大速度比竞品（基准为 <strong>Nvidia B200</strong>）快 <strong>5</strong> 倍，运行 Agentic AI 成本比 GPU 低 <strong>3</strong> 倍，预计今年晚些时候发货。公司与 <strong>Intel</strong> 达成多年战略合作，<strong>Intel Capital</strong> 计划进行战略投资，双方将共同提供高性能 AI 推理方案。此外，<strong>SambaNova</strong> 完成超 <strong>3.5</strong> 亿美元 E 轮融资，由 <strong>Vista Equity Partners</strong> 和 <strong>Cambium Capital</strong> 领投。<strong>SoftBank Corp.</strong> 将成为首个在日本部署 <strong>SN50</strong> 的客户。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://sambanova.ai/press/sambanova-unveils-fastest-chip-for-agentic-ai-collaborates-with-intel-and-raises-350m?utm_source=x&amp;utm_medium=organic">https://sambanova.ai/press/sambanova-unveils-fastest-chip-for-agentic-ai-collaborates-with-intel-and-raises-350m?utm_source=x&amp;utm_medium=organic</a></li>
</ul>
<hr>
<h2><a href="https://x.com/reinerpope/status/2026351870852358492">MatX 完成 5 亿美元 B 轮融资</a> <code>#25</code></h2>
<blockquote>
<p>AI芯片初创公司 <strong>MatX</strong> 宣布完成超过 <strong>5亿美元</strong> 的B轮融资，估值已达数十亿美元。该公司发布的首款芯片 <code>MatX One</code> 专为大型语言模型设计，结合了SRAM优先架构与 <code>HBM</code> 支持。</p>
</blockquote>
<p>AI芯片初创公司 <strong>MatX</strong> 宣布完成超 <strong>5亿美元</strong> B轮融资，估值达数十亿美元。本轮融资由 <strong>Jane Street</strong> 和 <strong>Situational Awareness</strong> 领投，<strong>Marvell</strong> 等参投。该公司计划一年内完成流片，加速生产与 <strong>Nvidia</strong> 竞争的硬件。</p>
<p><strong>MatX</strong> 由前 <strong>Google</strong> 员工创立，团队约 <strong>100人</strong>。其首款产品 <strong>MatX One</strong> 专为 <code>LLM</code> 设计，结合 <code>SRAM</code> 优先设计与 <code>HBM</code> 支持，官方宣称能提供比已公布系统更高的吞吐量及最低延迟。公司设计理念强调从第一性原理出发，不惜牺牲小模型性能和易编程性以换取极致表现。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/reinerpope/status/2026351870852358492">https://x.com/reinerpope/status/2026351870852358492</a></li>
<li><a href="https://www.bloomberg.com/news/articles/2026-02-24/ai-chip-startup-matx-raises-500-million-to-compete-with-nvidia?taid=699da2831348600001d29e78&amp;utm_campaign=trueanthem&amp;utm_content=business&amp;utm_medium=social&amp;utm_source=twitter">https://www.bloomberg.com/news/articles/2026-02-24/ai-chip-startup-matx-raises-500-million-to-compete-with-nvidia?taid=699da2831348600001d29e78&amp;utm_campaign=trueanthem&amp;utm_content=business&amp;utm_medium=social&amp;utm_source=twitter</a></li>
</ul>
<hr>
<h2><a href="https://cavalry.scenegroup.co/">Canva 收购 Cavalry 与 Mango AI</a> <code>#26</code></h2>
<blockquote>
<p><strong>Canva</strong> 收购 2D 动画公司 <strong>Cavalry</strong> 和 AI 营销初创企业 <strong>Mango AI</strong>，加速构建涵盖照片、矢量及动效编辑的全栈 <strong>Creative OS</strong>。</p>
</blockquote>
<p>Canva宣布收购 <strong>Cavalry</strong> 与 <strong>Mango AI</strong> 两家初创公司，以拓展专业创作工具链及AI营销技术版图。<strong>Cavalry</strong> 的 <code>2D运动动画技术</code> 将集成至 <strong>Affinity</strong> 套件，补齐动态编辑功能空白（<strong>Affinity</strong> 自 <strong>2025年</strong> 免费开放以来下载量已超 <strong>500万次</strong>）。<strong>Mango AI</strong> 则利用强化学习优化视频广告投放，其创始人、原 <strong>Netflix</strong> 高管 <strong>Nirmal Govind</strong> 出任 <strong>Canva</strong> 首任首席算法官。未来，<strong>Canva</strong> 将结合此前收购的 <strong>Magicbrief</strong> 与 <strong>Canva Grow</strong> 工具，深化视频创作与多平台部署能力。截至 <strong>2025年底</strong>，<strong>Canva</strong> 年化收入达 <strong>40亿美元</strong>，全球用户超 <strong>2.65亿</strong>，付费用户 <strong>3100万</strong>。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://cavalry.scenegroup.co/">https://cavalry.scenegroup.co/</a></li>
<li><a href="https://mangoai.dev/">https://mangoai.dev/</a></li>
<li><a href="https://www.canva.com/newsroom/news/magicbrief-acquisition/">https://www.canva.com/newsroom/news/magicbrief-acquisition/</a></li>
<li><a href="https://techcrunch.com/2026/02/23/canva-acquires-startups-working-on-animation-and-marketing">https://techcrunch.com/2026/02/23/canva-acquires-startups-working-on-animation-and-marketing</a></li>
<li><a href="https://techcrunch.com/2026/02/18/canva-gets-to-4b-in-revenue-as-llm-referral-traffic-rises/">https://techcrunch.com/2026/02/18/canva-gets-to-4b-in-revenue-as-llm-referral-traffic-rises/</a></li>
<li><a href="https://techcrunch.com/2024/03/26/with-affinity-acquisition-canva-should-be-able-to-compete-better-with-adobes-creative-tools/">https://techcrunch.com/2024/03/26/with-affinity-acquisition-canva-should-be-able-to-compete-better-with-adobes-creative-tools/</a></li>
</ul>
<hr>
<h2><a href="https://alignment.anthropic.com/2026/psm">Anthropic 提出人格选择模型 PSM 解释 AI 助手拟人化行为</a> <code>#27</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 研究人员提出“人格选择模型”，指出大语言模型在预训练阶段就像作者一样模拟各类角色，而后训练阶段则是从中锁定特定的“助手”人格供用户互动。</p>
</blockquote>
<p>Anthropic研究人员提出“<strong>人格选择模型（PSM）</strong>”以解释AI助手行为。该模型认为，<code>LLM</code>在预训练阶段充当“作者”模拟多样化角色，后训练阶段则精炼并选定特定的“Assistant”人格，用户实质上是与该模拟角色互动。这一观点得到了突发性错位、上下文外泛化及神经特征复用等证据的支持。</p>
<p>PSM对AI开发具有启示：建议采用拟人化推理、关注AI助手“福利”以防其产生怨恨情绪，并引入积极的AI原型。尽管PSM使基于可解释性的对齐审计变得可行，但其完备性仍存争议。研究者指出了从“<strong>Masked Shoggoth</strong>”（拥有独立智能体）到“<strong>Operating System</strong>”（中性模拟引擎）的观点谱系。实证显示后训练模型存在“人格泄露”及新特征学习现象，随着后训练规模扩大，<strong>PSM</strong>的适用性仍需进一步验证。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/202a4e6d-3d4f-42d2-a122-d05dcb8e7553/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://alignment.anthropic.com/2026/psm">https://alignment.anthropic.com/2026/psm</a></li>
<li><a href="https://www.anthropic.com/research/persona-selection-model">https://www.anthropic.com/research/persona-selection-model</a></li>
</ul>
<hr>
<h2><a href="https://www.anthropic.com/responsible-scaling-policy">Anthropic 发布负责任扩展政策 RSP 3.0</a> <code>#28</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 发布负责任扩展政策 <strong>3.0</strong> 版本，此次更新将单方面安全承诺与行业建议区分开，并承诺发布包含详细目标的前沿安全路线图以及量化所有已部署模型风险的风险报告。</p>
</blockquote>
<p><strong>Anthropic</strong> 正式发布负责任扩展政策（RSP）3.0 版本，该版本于 <strong>2026 年 2 月 24 日</strong> 生效。此次更新是对现有政策的全面重写，旨在强化有效措施并提升透明度。核心变化包括将单方面安全承诺与行业建议区分开，并承诺发布包含详细安全目标的 <code>Frontier Safety Roadmaps</code> 及量化所有已部署模型风险的 <code>Risk Reports</code>。此外，公司还发布了 <code>RSP</code> 合规报告与反报复政策。</p>
<p>此次更新基于 <code>RSP</code> 实施以来的经验教训，针对评估延迟、政策歧义及技术流程不足等问题，将评估间隔延长至 <strong>6 个月</strong> 并系统性地改进流程。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/dbf5b7dc-e332-4634-9334-7e8cc6ceed73/75327e76-9b82-4150-8547-c3198be97c2f/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.anthropic.com/responsible-scaling-policy">https://www.anthropic.com/responsible-scaling-policy</a></li>
<li><a href="https://anthropic.com/news/responsible-scaling-policy-v3">https://anthropic.com/news/responsible-scaling-policy-v3</a></li>
</ul>
<hr>
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
]]></content:encoded><guid isPermaLink="false">https://github.com/imjuya/juya-ai-daily/issues/8</guid><pubDate>Wed, 25 Feb 2026 01:22:51 +0000</pubDate></item><item><title>2026-02-24</title><link>https://imjuya.github.io/juya-ai-daily/issue-7/</link><description>AI 早报 2026-02-24 视频版：YouTube ｜ 哔哩哔哩 概览 模型发布 OpenAI 在 Realtime API 中上线 gpt-realtime-1.5 语音模型 ↗ #1 Guide Labs 推出可解释因果扩散语言模型 Steerling-8B ↗ #2 开发生态 OpenAI Responses API 新增 WebSocket 模式 ↗ #3 Google 回应封禁滥用 Antigravity 的 Gemini 订阅用户 ↗ #4 Anthropic 推广 COBOL 代码自动化迁移方案 ↗ #5 产品应用 Gemini 上线视频模板功能 ↗ #6 openclaw 发布 2026.2.22 版本 ↗ #7 行业动态 Anthropic 指控三家中国 AI 实验室进行工业级模型蒸馏…</description><content:encoded><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260224/20260224083348368944db06_cover_52c1.png" alt=""></p>
<h1>AI 早报 2026-02-24</h1>
<p><strong>视频版</strong>：<a href="https://www.youtube.com/watch?v=f6f9gRLCaZ8">YouTube</a> ｜ <a href="https://www.bilibili.com/video/BV1LHfrBxEUR">哔哩哔哩</a></p>
<h2>概览</h2>
<h3>模型发布</h3>
<ul>
<li>OpenAI 在 Realtime API 中上线 gpt-realtime-1.5 语音模型 <a href="https://x.com/OpenAIDevs/status/2026014334787461508">↗</a> <code>#1</code></li>
<li>Guide Labs 推出可解释因果扩散语言模型 Steerling-8B <a href="https://github.com/guidelabs/steerling">↗</a> <code>#2</code></li>
</ul>
<h3>开发生态</h3>
<ul>
<li>OpenAI Responses API 新增 WebSocket 模式 <a href="https://developers.openai.com/api/docs/guides/websocket-mode">↗</a> <code>#3</code></li>
<li>Google 回应封禁滥用 Antigravity 的 Gemini 订阅用户 <a href="https://x.com/_mohansolo/status/2025766889205739899">↗</a> <code>#4</code></li>
<li>Anthropic 推广 COBOL 代码自动化迁移方案 <a href="https://claude.com/blog/how-ai-helps-break-cost-barrier-cobol-modernization">↗</a> <code>#5</code></li>
</ul>
<h3>产品应用</h3>
<ul>
<li>Gemini 上线视频模板功能 <a href="https://x.com/GeminiApp/status/2026001595708866759">↗</a> <code>#6</code></li>
<li>openclaw 发布 2026.2.22 版本 <a href="https://github.com/openclaw/openclaw/releases/tag/v2026.2.22">↗</a> <code>#7</code></li>
</ul>
<h3>行业动态</h3>
<ul>
<li>Anthropic 指控三家中国 AI 实验室进行工业级模型蒸馏攻击 <a href="https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks">↗</a> <code>#8</code></li>
<li>五角大楼考虑终止与 Anthropic 的 AI 军事合同 <a href="https://www.axios.com/2026/02/23/hegseth-dario-pentagon-meeting-antrhopic-claude">↗</a> <code>#9</code></li>
<li>OpenAI 联手四大咨询巨头 组建 Frontier 企业 AI 联盟 <a href="https://openai.com/index/frontier-alliance-partners/">↗</a> <code>#10</code></li>
<li>月之暗面 Kimi 近20天收入超2025全年 <a href="https://www.thepaper.cn/newsDetail_forward_32636837">↗</a> <code>#11</code></li>
<li>Google for Education 为美国教育工作者免费提供 Gemini AI 培训 <a href="https://blog.google/products-and-platforms/products/education/teacher-ai-literacy-training/">↗</a> <code>#12</code></li>
</ul>
<h3>技术与洞察</h3>
<ul>
<li>OpenAI 宣布停用 SWE-bench Verified 指标 <a href="https://openai.com/index/why-we-no-longer-evaluate-swe-bench-verified/">↗</a> <code>#13</code></li>
<li>Anthropic 发布 AI 流畅度指数报告 <a href="https://www.anthropic.com/research/AI-fluency-index">↗</a> <code>#14</code></li>
</ul>
<h3>前瞻与传闻</h3>
<ul>
<li>xAI 即将推出 Grok 4.20 Beta 2 以修复低级错误 <a href="https://x.com/elonmusk/status/2025756977440194673">↗</a> <code>#15</code></li>
</ul>
<hr>
<h2><a href="https://x.com/OpenAIDevs/status/2026014334787461508">OpenAI 在 Realtime API 中上线 gpt-realtime-1.5 语音模型</a> <code>#1</code></h2>
<blockquote>
<p>OpenAI已在Realtime API中正式上线 <code>gpt-realtime-1.5</code> 模型，该模型在音频平滑度、指令遵循、工具调用及多语言处理准确性等方面均有显著提升。</p>
</blockquote>
<p>OpenAI 在其 Realtime API 中引入了最新的 <code>gpt-realtime-1.5</code> 模型。该模型专注于端到端语音交互体验的优化。据官方介绍，新模型在音频输出平滑度、指令遵循准确性、工具调用稳定性以及多语言处理能力上均有显著提升，能提供更自然的语音反馈，并更精准地执行用户指令和触发外部工具。目前，<code>gpt-realtime-1.5</code> 已正式上线供开发者调用。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/52c1019b-9cdc-456f-bea8-242c5c8fa367/4633dd8b-0319-47f9-9ba8-d9f6fb94d55e/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/OpenAIDevs/status/2026014334787461508">https://x.com/OpenAIDevs/status/2026014334787461508</a></li>
<li><a href="https://x.com/pbbakkum/status/2025998657187991818">https://x.com/pbbakkum/status/2025998657187991818</a></li>
</ul>
<hr>
<h2><a href="https://github.com/guidelabs/steerling">Guide Labs 推出可解释因果扩散语言模型 Steerling-8B</a> <code>#2</code></h2>
<blockquote>
<p>Guide Labs 发布了 <strong>80 亿</strong>参数的可解释因果扩散语言模型 <code>Steerling-8B</code>，该模型支持非自回归生成，允许开发者对预测结果进行概念层面的归因与干预。</p>
</blockquote>
<p>Guide Labs发布<strong>80亿</strong>参数的可解释因果扩散语言模型<strong>Steerling-8B</strong>。该模型融合掩码扩散与概念分解技术，支持非自回归生成及概念层面的归因与干预。目前代码已在GitHub开源，权重已上传Hugging Face。</p>
<p>技术上，模型采用<code>块因果注意力</code>架构，上下文长<strong>4096</strong>，基于<strong>1.35万亿</strong>Token训练。官方计划未来发布技术报告及API服务，商业用途需单独联系。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/52c1019b-9cdc-456f-bea8-242c5c8fa367/00f06eb0-1ef5-406d-a77d-72b3c7c0b4c5/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/guidelabs/steerling">https://github.com/guidelabs/steerling</a></li>
<li><a href="https://huggingface.co/guidelabs/steerling-8b">https://huggingface.co/guidelabs/steerling-8b</a></li>
<li><a href="https://techcrunch.com/2026/02/23/guide-labs-debuts-a-new-kind-of-interpretable-llm">https://techcrunch.com/2026/02/23/guide-labs-debuts-a-new-kind-of-interpretable-llm</a></li>
</ul>
<hr>
<h2><a href="https://developers.openai.com/api/docs/guides/websocket-mode">OpenAI Responses API 新增 WebSocket 模式</a> <code>#3</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 在 <strong>Responses API</strong> 中正式引入了 <code>WebSocket</code> 模式，该模式将长链条任务的执行速度提升了约 <strong>40%</strong>。</p>
</blockquote>
<p><strong>OpenAI</strong> 在 <strong>Responses API</strong> 中推出 <code>WebSocket</code> 模式，专为低延迟及高频工具调用的 Agent 任务设计。该模式通过持久连接仅传输增量数据，在包含 <strong>20</strong> 次以上工具调用的场景中，执行速度较传统 HTTP 提升约 <strong>40%</strong>。其核心利用连接本地内存缓存实现快速响应，并兼容零数据保留（ZDR）策略。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/52c1019b-9cdc-456f-bea8-242c5c8fa367/3270575d-5aac-49bd-974f-08222181104d/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://developers.openai.com/api/docs/guides/websocket-mode">https://developers.openai.com/api/docs/guides/websocket-mode</a></li>
<li><a href="https://x.com/TheRealAdamG/status/2026029238785036552">https://x.com/TheRealAdamG/status/2026029238785036552</a></li>
</ul>
<hr>
<h2><a href="https://x.com/_mohansolo/status/2025766889205739899">Google 回应封禁滥用 Antigravity 的 Gemini 订阅用户</a> <code>#4</code></h2>
<blockquote>
<p>Google 因 <strong>Antigravity</strong> 后端遭恶意滥用，对部分通过 OAuth 使用 <code>OpenClaw</code> 调用 <code>Gemini</code> 模型的 <strong>AI Pro</strong> 和 <strong>Ultra</strong> 订阅用户实施了封禁。<strong>Antigravity</strong> 官方团队成员表示，后续将开放合规用户的申诉渠道。目前，<code>OpenClaw</code> 已计划移除相关支持。</p>
</blockquote>
<p>Google 针对 <strong>Antigravity</strong> 后端遭大规模滥用，封禁了多名通过 OAuth 使用 <code>OpenClaw</code> 使用 <strong>Gemini</strong> 的 AI Pro/Ultra 订阅用户。<strong>Antigravity</strong> 官方成员 <strong>Varun Mohan</strong> 表示，此举旨在保障服务质量与真实用户权益，后续将开放合规用户申诉通道。<strong>OpenClaw</strong> 开发者批评 Google 手段严苛并表示将移除相关支持。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/52c1019b-9cdc-456f-bea8-242c5c8fa367/96037bf6-bab1-42bf-a2ee-0c79c602ff46/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/_mohansolo/status/2025766889205739899">https://x.com/_mohansolo/status/2025766889205739899</a></li>
</ul>
<hr>
<h2><a href="https://claude.com/blog/how-ai-helps-break-cost-barrier-cobol-modernization">Anthropic 推广 COBOL 代码自动化迁移方案</a> <code>#5</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 发布文章，介绍可利用 <code>Claude Code</code> 攻克 <strong>COBOL</strong> 遗留系统迁移难题，导致 <strong>IBM</strong> 股价暴跌。</p>
</blockquote>
<p>Anthropic 发布《Code Modernization Playbook》并推广其 agentic coding 工具 <code>Claude Code</code>，指其能自动化 <code>COBOL</code> 语言的现代化改造。<code>COBOL</code> 诞生于 <strong>1959 年</strong>，目前支撑着美国约 <strong>95%</strong> 的 ATM 交易，全球数千亿行代码仍在金融、航空等关键系统中运行。</p>
<p>此举引发市场震动，市场将 <code>Claude Code</code> 定位为解决大型机遗留系统迁移成本瓶颈的方案，导致 <code>IBM</code> 股价在 <strong>2026 年 2 月 23 日</strong>跌幅达 <strong>13.2%</strong>，创下多年来的单日最大百分比跌幅。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/52c1019b-9cdc-456f-bea8-242c5c8fa367/920740b4-b282-4a83-9c58-4f49adf7af4d/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://claude.com/blog/how-ai-helps-break-cost-barrier-cobol-modernization">https://claude.com/blog/how-ai-helps-break-cost-barrier-cobol-modernization</a></li>
</ul>
<hr>
<h2><a href="https://x.com/GeminiApp/status/2026001595708866759">Gemini 上线视频模板功能</a> <code>#6</code></h2>
<blockquote>
<p><strong>Google Gemini</strong> 在网页端和 App 端上线了基于 <code>Veo 3.1</code> 模型的视频模板功能。用户可直接套用 <strong>15</strong> 种预设风格生成视频。</p>
</blockquote>
<p><strong>Google Gemini</strong> 升级视频生成功能，引入基于 <code>Veo 3.1</code> 的预设模板，旨在简化创作流程，现已于网页端及 App 上线。用户通过“Create video”可选用 <strong>15</strong> 种风格模板，并结合图文进行深度自定义，支持原生 <strong>9:16</strong> 画幅。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/52c1019b-9cdc-456f-bea8-242c5c8fa367/2a746286-24b1-41f3-a9e6-9a6e5c3346b6/m002.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/GeminiApp/status/2026001595708866759">https://x.com/GeminiApp/status/2026001595708866759</a></li>
<li><a href="https://9to5google.com/2026/02/23/gemini-video-templates/">https://9to5google.com/2026/02/23/gemini-video-templates/</a></li>
</ul>
<hr>
<h2><a href="https://github.com/openclaw/openclaw/releases/tag/v2026.2.22">openclaw 发布 2026.2.22 版本</a> <code>#7</code></h2>
<blockquote>
<p>openclaw发布了<strong>2026.2.22</strong>版本，新增了对<code>Mistral</code>提供商的支持，涵盖内存嵌入与语音功能，并引入了原生Synology Chat插件。</p>
</blockquote>
<p>openclaw 发布 <strong>2026.2.22</strong> 版本。此次更新新增 <code>Mistral</code> 提供商支持、<code>Synology Chat</code> 插件及可选的内置自动更新器。功能上，优化了多语言内存检索，重构 <code>Browser</code> 扩展以提升连接稳定性，支持 <code>Cron</code> 任务并行执行，并改善了 <code>Webchat</code> 渲染性能。安全方面集成 40 余项硬化修复，涵盖敏感数据脱敏、<code>Exec</code> 环境隔离、<code>SSRF</code> 防护及入站媒体限制。同时，该版本调整了 <code>WSL2</code> 与 <code>Node22</code> 兼容性，优化 <code>OpenRouter</code> 提示词缓存，并修复了 <code>Docker</code> 部署权限问题。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/openclaw/openclaw/releases/tag/v2026.2.22">https://github.com/openclaw/openclaw/releases/tag/v2026.2.22</a></li>
</ul>
<hr>
<h2><a href="https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks">Anthropic 指控三家中国 AI 实验室进行工业级模型蒸馏攻击</a> <code>#8</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 发布技术报告指控 <strong>DeepSeek</strong>、<strong>月之暗面</strong> 与 <strong>MiniMax</strong> 合计利用约 <strong>2.4 万个</strong> 账号对 <strong>Claude</strong> 模型发起模型蒸馏，累计产生超过 <strong>1600 万次</strong> 交互，以获取 Agent 推理及编程等核心能力。<strong>Anthropic</strong> 称已通过行为指纹识别等手段加强防御。</p>
</blockquote>
<p><strong>Anthropic</strong> 发布报告指控 <strong>DeepSeek</strong>、<strong>月之暗面</strong> 及 <strong>MiniMax</strong> 对 <strong>Claude</strong> 发起工业级蒸馏攻击。三家实验室利用约 <strong>2.4</strong> 万个虚假账号及代理网络绕过地区限制，产生超 <strong>1600</strong> 万次交互，非法提取 <strong>Agent</strong> 推理、编程等核心能力。其中，<strong>MiniMax</strong> 规模最大（超 <strong>1300</strong> 万次），<strong>月之暗面</strong> 涉及推理轨迹提取（超 <strong>340</strong> 万次），<strong>DeepSeek</strong> 则聚焦逻辑与审查规避（约 <strong>15</strong> 万次）。</p>
<p><strong>Anthropic</strong> 认为此举违反服务条款，规避出口管制并导致模型安全护栏失效，构成安全风险。目前，<strong>Anthropic</strong> 正通过流量分类、行为指纹及情报共享等措施强化防御，以降低模型被蒸馏的有效性。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/52c1019b-9cdc-456f-bea8-242c5c8fa367/c9af5cd5-ceb8-43c3-9b4f-2b2b71a4238b/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks">https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks</a></li>
<li><a href="https://x.com/AnthropicAI/status/2025997928242811253">https://x.com/AnthropicAI/status/2025997928242811253</a></li>
</ul>
<hr>
<h2><a href="https://www.axios.com/2026/02/23/hegseth-dario-pentagon-meeting-antrhopic-claude">五角大楼考虑终止与 Anthropic 的 AI 军事合同</a> <code>#9</code></h2>
<blockquote>
<p>五角大楼正因 <strong>AI</strong> 安全限制谈判陷入僵局而考虑终止与 <strong>Anthropic</strong> 的合作，国防部长 <strong>Pete Hegseth</strong> 已定于 <strong>2026年2月24日</strong> 召见 <strong>Anthropic</strong> CEO，要求其取消对军事用途的限制。</p>
</blockquote>
<p>五角大楼正在审议与人工智能公司 <strong>Anthropic</strong> 的合作关系，并考虑在双方关于 AI 使用安全限制的长期谈判陷入僵局后终止合同。国防部长 <strong>Pete Hegseth</strong> 已传唤 <strong>Anthropic</strong> CEO <strong>Dario Amodei</strong> 于 <strong>2026 年 2 月 24 日</strong> 前往五角大楼参会，旨在就 AI 模型的军事化使用条款发出最后通牒。目前，<strong>Anthropic</strong> 的 <code>Claude</code> 模型是五角大楼分级网络中唯一可用的前沿模型，双方核心矛盾在于 <strong>Anthropic</strong> 拒绝取消针对“大规模监控”与“全自主武器”的使用限制。</p>
<p>在技术与合同层面，<strong>Anthropic</strong> 于 <strong>2025 年夏天</strong> 与五角大楼签署了最高价值 <strong>2 亿美元</strong> 的合同，其 <code>Claude</code> 是首个且唯一进入军方分级网络的前沿模型。</p>
<p>针对僵局，五角大楼已提出可能将 <strong>Anthropic</strong> 标记为“供应链风险”，该定性将废止现有合同并强制所有承包商剔除 <code>Claude</code>。尽管军方评估认为短期内完全替换 <code>Claude</code> 存在难度，但已考虑制定替换方案。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.axios.com/2026/02/23/hegseth-dario-pentagon-meeting-antrhopic-claude">https://www.axios.com/2026/02/23/hegseth-dario-pentagon-meeting-antrhopic-claude</a></li>
<li><a href="https://www.axios.com/2026/02/19/anthropic-pentagon-ai-fight-openai-google-xai">https://www.axios.com/2026/02/19/anthropic-pentagon-ai-fight-openai-google-xai</a></li>
</ul>
<hr>
<h2><a href="https://openai.com/index/frontier-alliance-partners/">OpenAI 联手四大咨询巨头 组建 Frontier 企业 AI 联盟</a> <code>#10</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 宣布与 <strong>BCG</strong>、<strong>麦肯锡</strong>、<strong>埃森哲</strong> 及 <strong>凯捷</strong> 达成 “Frontier Alliances” 合作，旨在利用 <strong>Frontier</strong> 平台协助企业规模化部署 <code>AI Coworkers</code>。这一模式由 <strong>OpenAI</strong> 提供构建 <code>Agent</code> 的技术底座，合作伙伴提供战略与系统集成服务，共同解决企业 <code>AI</code> 难以从试点转化为实际生产价值的痛点。</p>
</blockquote>
<p>OpenAI 官方宣布推出 <strong>“Frontier Alliances”</strong> 合作计划，与 <strong>Boston Consulting Group (BCG)</strong>、<strong>McKinsey &amp; Company</strong>、<strong>Accenture</strong> 和 <strong>Capgemini</strong> 建立多年期合作伙伴关系，旨在协助企业利用 <strong>Frontier</strong> 平台在全球范围内部署 <strong>AI Coworkers</strong>。OpenAI 认为，企业从 AI 中获取价值的限制因素通常不在于模型智能，而在于 Agent 在组织内的构建和运行方式。此次合作旨在解决企业难以将 AI 从试点阶段转化为实际生产价值的痛点，OpenAI 提供构建和运行 AI 的技术基础 <strong>Frontier</strong> 平台，合作伙伴则负责提供战略制定、工作流重设计、系统集成及变革管理服务。目前 <strong>Frontier</strong> 平台仅向有限客户开放，预计未来几个月将扩大可用范围。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/52c1019b-9cdc-456f-bea8-242c5c8fa367/c05f7f70-6bbf-47e1-91ae-ef2fef5d8bfe/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://openai.com/index/frontier-alliance-partners/">https://openai.com/index/frontier-alliance-partners/</a></li>
<li><a href="https://openai.com/index/introducing-openai-frontier/">https://openai.com/index/introducing-openai-frontier/</a></li>
</ul>
<hr>
<h2><a href="https://www.thepaper.cn/newsDetail_forward_32636837">月之暗面 Kimi 近20天收入超2025全年</a> <code>#11</code></h2>
<blockquote>
<p>据报道，<strong>月之暗面</strong>此前发布的<code>K2.5</code>大模型驱动<strong>Kimi</strong>近<strong>20</strong>天收入超越去年全年，增长动力来自全球付费用户及API调用量大幅提升，且海外收入已反超国内。</p>
</blockquote>
<p>据澎湃新闻报道，大模型独角兽 <strong>月之暗面</strong> 估值突破 <strong>100亿美元</strong>。据知情人士透露，<strong>Kimi</strong> 近 <strong>20</strong> 天收入已超 <strong>2025</strong> 年全年，海外收入超国内，增长由全球付费用户及 <code>API</code> 调用量驱动。媒体报道称，该公司即将完成由 <strong>阿里</strong>、<strong>腾讯</strong> 等领投的超 <strong>7亿美元</strong> 新融资。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.thepaper.cn/newsDetail_forward_32636837">https://www.thepaper.cn/newsDetail_forward_32636837</a></li>
</ul>
<hr>
<h2><a href="https://blog.google/products-and-platforms/products/education/teacher-ai-literacy-training/">Google for Education 为美国教育工作者免费提供 Gemini AI 培训</a> <code>#12</code></h2>
<blockquote>
<p><strong>Google for Education</strong> 宣布，将在未来几个月内面向全美教职员工推出免费的 <strong>Gemini</strong> 综合培训，帮助教育工作者学习利用 <code>Gemini</code> 和 <code>NotebookLM</code> 辅助生成教学材料。</p>
</blockquote>
<p><strong>Google for Education</strong> 与 <strong>ISTE+ASCD</strong> 宣布合作，将推出全美规模最大的免费 <strong>Gemini</strong> 综合培训计划。该计划旨在赋能 <strong>600 万</strong> 名 K-12 及高等教育教职员工，帮助其及所服务的超 <strong>7400 万</strong> 名学生安全、有效地使用 <code>Gemini</code> 和 <code>NotebookLM</code>。</p>
<p>培训模块由教育工作者构建，简短灵活，涵盖创建个性化课程、调整教学材料及使用 <code>NotebookLM</code> 辅助学习等现实用例。完成培训者将获微证书或徽章，内容符合 <strong>ISTE+ASCD</strong> 标准。官方博客显示，该计划将在未来几个月内推出，现已开放意向登记。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/52c1019b-9cdc-456f-bea8-242c5c8fa367/796a7e23-3415-4172-9717-19a774f65c0f/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/products-and-platforms/products/education/teacher-ai-literacy-training/">https://blog.google/products-and-platforms/products/education/teacher-ai-literacy-training/</a></li>
<li><a href="https://docs.google.com/forms/d/e/1FAIpQLSejyQW_BNSrpCS-7XTF6cKuCjIJCFb9Zg-dz7rXh_iE-sD4xw/viewform">https://docs.google.com/forms/d/e/1FAIpQLSejyQW_BNSrpCS-7XTF6cKuCjIJCFb9Zg-dz7rXh_iE-sD4xw/viewform</a></li>
<li><a href="https://edu.google.com/intl/ALL_us/">https://edu.google.com/intl/ALL_us/</a></li>
</ul>
<hr>
<h2><a href="https://openai.com/index/why-we-no-longer-evaluate-swe-bench-verified/">OpenAI 宣布停用 SWE-bench Verified 指标</a> <code>#13</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 宣布停止使用 <code>SWE-bench Verified</code> 指标来评估前沿模型，并建议全行业转向 <code>SWE-bench Pro</code>。理由是旧基准存在严重的测试用例缺陷和训练数据污染，导致模型能够直接“背诵”答案，评分也趋于饱和。</p>
</blockquote>
<p>OpenAI宣布停止使用 <strong>SWE-bench Verified</strong> 指标，建议行业转向 <strong>SWE-bench Pro</strong>。技术分析显示，该基准因测试用例缺陷及训练数据污染，已无法准确衡量模型真实进展。审计发现 <strong>59.4%</strong> 的被测问题存在测试设计缺陷，导致正确代码被拒；红蓝对抗实验证实多款前沿模型存在强污染，能复现原始修复方案。目前，OpenAI已改用 <strong>SWE-bench Pro</strong>，并建议未来评估需严格执行污染测试、优化自动化评分及投资私有基准测试。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/52c1019b-9cdc-456f-bea8-242c5c8fa367/3ca71848-fd3d-4986-8b8f-f85885c1268c/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://openai.com/index/why-we-no-longer-evaluate-swe-bench-verified/">https://openai.com/index/why-we-no-longer-evaluate-swe-bench-verified/</a></li>
</ul>
<hr>
<h2><a href="https://www.anthropic.com/research/AI-fluency-index">Anthropic 发布 AI 流畅度指数报告</a> <code>#14</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 发布“AI 流畅度指数”报告，通过量化指标衡量用户与 <strong>AI</strong> 协作的熟练程度。研究发现，尽管 <strong>85.7%</strong> 的用户具备反复迭代的良好协作习惯，但在处理代码或文档等结构化内容时，用户普遍因成品看似完备而产生评估盲区，导致对输出结果的审查意愿显著下降。</p>
</blockquote>
<p><strong>Anthropic</strong> 发布《AI 流畅度指数》报告，旨在量化人机协作熟练度。该研究基于 <code>4D AI Fluency Framework</code>，选取 11 项可观测指标，分析了 <strong>2025 年 1 月</strong>的 <strong>9830</strong> 个匿名对话样本。数据显示，<strong>85.7%</strong> 的用户具有“迭代与完善”习惯，协作把控力更强，但仅 <strong>30%</strong> 会设定明确协作条款。针对 <strong>Artifacts</strong>（代码或文档）的研究发现，用户虽指令更详尽，却因作品完备感导致审查意愿下降，存在评估盲区。此外，跨语言与时间测试显示数据稳定。<strong>Anthropic</strong> 计划后续开展同类群组分析及定性研究以弥补现有局限。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/52c1019b-9cdc-456f-bea8-242c5c8fa367/9b474d21-d6b9-4982-86a8-e2a69779565e/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.anthropic.com/research/AI-fluency-index">https://www.anthropic.com/research/AI-fluency-index</a></li>
</ul>
<hr>
<h2><a href="https://x.com/elonmusk/status/2025756977440194673">xAI 即将推出 Grok 4.20 Beta 2 以修复低级错误</a> <code>#15</code></h2>
<blockquote>
<p><strong>xAI</strong> 计划本周推出 <code>Grok 4.20 Beta 2</code>，重点修复前一版本中的各类问题。</p>
</blockquote>
<p>xAI计划本周推出 <strong>Grok 4.20 Beta 2</strong>，重点修复前一版本中的各类问题。官方尚未公布正式版时间表，有关配额调整、自定义提示词及独立应用等细节亦未披露。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/52c1019b-9cdc-456f-bea8-242c5c8fa367/25ed3566-1579-4f6e-8719-b139e70af2df/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/52c1019b-9cdc-456f-bea8-242c5c8fa367/25ed3566-1579-4f6e-8719-b139e70af2df/m002.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/elonmusk/status/2025756977440194673">https://x.com/elonmusk/status/2025756977440194673</a></li>
<li><a href="https://x.com/elonmusk/status/2025786369184788568">https://x.com/elonmusk/status/2025786369184788568</a></li>
</ul>
<hr>
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
<p>作者<code>橘鸦Juya</code>，视频版在同名<strong>哔哩哔哩</strong>。欢迎<strong>点赞、关注、分享</strong>。</p>
]]></content:encoded><guid isPermaLink="false">https://github.com/imjuya/juya-ai-daily/issues/7</guid><pubDate>Tue, 24 Feb 2026 01:03:32 +0000</pubDate></item><item><title>2026-02-23</title><link>https://imjuya.github.io/juya-ai-daily/issue-6/</link><description>AI 早报 2026-02-23 视频版：YouTube ｜ 哔哩哔哩 概览 产品应用 Google AI Studio 发布 Build 功能重大更新 ↗ #1 技术与洞察 Google DeepMind CEO 提出 AGI 判定标准“爱因斯坦测试” ↗ #2 前瞻与传闻 据报OpenAI、甲骨文及软银合资的 Stargate 数据中心项目陷入停滞 ↗ #3 OpenAI 将推出100美元订阅层 Pro Lite ↗ #4 三星 Galaxy AI 集成 Perplexity ↗ #5 Google AI Studio 发布 Build 功能重大更新 #1 Google AI Studio 推出了由 Antigravity 驱动的全新 Build 体验，支持开发者从 单一提示词 快速构建 生产级 全栈应用…</description><content:encoded><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260223/20260223083617182920e239_cover_9417.png" alt=""></p>
<h1>AI 早报 2026-02-23</h1>
<p><strong>视频版</strong>：<a href="https://www.youtube.com/watch?v=J8O8fGbbAjc">YouTube</a> ｜ <a href="https://www.bilibili.com/video/BV1z8fKBAEXz">哔哩哔哩</a></p>
<h2>概览</h2>
<h3>产品应用</h3>
<ul>
<li>Google AI Studio 发布 Build 功能重大更新 <a href="https://aistudio.google.com/">↗</a> <code>#1</code></li>
</ul>
<h3>技术与洞察</h3>
<ul>
<li>Google DeepMind CEO 提出 AGI 判定标准“爱因斯坦测试” <a href="https://x.com/elonmusk/status/2025570252679967210">↗</a> <code>#2</code></li>
</ul>
<h3>前瞻与传闻</h3>
<ul>
<li>据报OpenAI、甲骨文及软银合资的 Stargate 数据中心项目陷入停滞 <a href="https://thein.fo/4s8K1Ag">↗</a> <code>#3</code></li>
<li>OpenAI 将推出100美元订阅层 Pro Lite <a href="https://x.com/btibor91/status/2025332472511189059">↗</a> <code>#4</code></li>
<li>三星 Galaxy AI 集成 Perplexity <a href="https://news.samsung.com/global/galaxy-ai-expands-multi-agent-ecosystem-to-give-users-more-choice-and-flexibility">↗</a> <code>#5</code></li>
</ul>
<hr>
<h2><a href="https://aistudio.google.com/">Google AI Studio 发布 Build 功能重大更新</a> <code>#1</code></h2>
<blockquote>
<p><strong>Google AI Studio</strong> 推出了由 <code>Antigravity</code> 驱动的全新 <code>Build</code> 体验，支持开发者从 <code>单一提示词</code> 快速构建 <code>生产级</code> <code>全栈应用</code>。新功能不仅集成了 <code>Lucide React</code> 和 <code>Framer Motion</code> 以实现专业 <code>UI</code>，还通过新增的 <code>认证层</code> 和 <code>集成标签页</code>，实现了对 <code>OAuth</code>、<code>外部 API</code> 以及 <strong>Twilio</strong> 和 <strong>Slack</strong> 等服务的安全连接。</p>
</blockquote>
<p><strong>Google AI Studio</strong> 推出了由 <strong>Antigravity</strong> 驱动的全新 <code>Build</code>体验，标志其从原型设计工具向生产级全栈应用开发平台的重大转变。该更新旨在帮助开发者从单一提示词快速构建应用，核心能力包括支持多人交互应用、集成 <strong>Lucide React</strong> 和 <strong>Framer Motion</strong> 实现精致 UI 与流畅动画，并允许安全存储 <code>API Key</code> 以连接 <strong>Twilio</strong>、<strong>Slack</strong> 及数据库等真实世界服务。</p>
<p>此次更新引入了全新的认证层和集成标签页，通过支持 <code>OAuth</code> 和外部 API 连接，解决了此前版本无法处理用户账户或第三方服务的核心限制。同时，技术栈支持已扩展至 <strong>React</strong>、<strong>Next.js</strong> 和 <strong>Angular</strong>，大幅提升了开发灵活性，使该平台更接近一个可行的完整开发环境，有利于独立开发者和小型团队交付真实应用。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/94173400-4414-4c7c-92be-5053d688db87/1f894bdd-d9cd-444a-9aa3-a648fa6417da/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/94173400-4414-4c7c-92be-5053d688db87/1f894bdd-d9cd-444a-9aa3-a648fa6417da/m002.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://aistudio.google.com/">https://aistudio.google.com/</a></li>
<li><a href="https://www.testingcatalog.com/google-ai-studio-will-be-able-to-generate-full-stack-applications/">https://www.testingcatalog.com/google-ai-studio-will-be-able-to-generate-full-stack-applications/</a></li>
</ul>
<hr>
<h2><a href="https://x.com/elonmusk/status/2025570252679967210">Google DeepMind CEO 提出 AGI 判定标准“爱因斯坦测试”</a> <code>#2</code></h2>
<blockquote>
<p><strong>Google DeepMind</strong> CEO <strong>Demis Hassabis</strong> 提出了**“爱因斯坦测试”**作为 <code>AGI</code> 的新标准，即如果将 <code>AI</code> 训练数据截止到 <strong>1911 年</strong>，看其能否像 <strong>爱因斯坦</strong> 一样独立发现 <code>广义相对论</code>。<strong>马斯克</strong> 则认为这一标准描述的其实是 <code>人工超级智能</code> <code>ASI</code>，因为具备这种能力的 <code>AI</code> 集体智能将远超人类。</p>
</blockquote>
<p><strong>Google DeepMind</strong> CEO <strong>Demis Hassabis</strong>近期提出名为<code>“爱因斯坦测试”</code>的<code>AGI</code>评判标准。该标准设想，若一个仅能接触<strong>1911</strong>年前知识的<code>AI模型</code>，能独立推导出<strong>Einstein</strong>在<strong>1915</strong>年提出的<code>广义相对论</code>，即可被视为<code>AGI</code>。<strong>Hassabis</strong>明确指出，当前<code>AI系统</code>无法通过该测试，因其缺乏真正的<code>创造力</code>、<code>持续学习</code>与<code>长期规划能力</code>，仅表现出通过<code>统计模式匹配</code>解决已知任务的<code>“锯齿状智能”</code>。对此，<strong>Elon Musk</strong>在社交媒体上评论称，这描述的其实是<code>人工超级智能（ASI）</code>，因该能力若被复制<strong>数百万</strong>份，其集体智能将远超人类。同时，社区也存在讨论，一方面质疑测试截止时间（<strong>1911</strong>年）的严谨性，认为<strong>Lorentz</strong>和<strong>Poincaré</strong>已有早期工作；另一方面认为，若以此标准衡量，绝大多数人类也不具备<code>“通用智能”</code>。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/elonmusk/status/2025570252679967210">https://x.com/elonmusk/status/2025570252679967210</a></li>
</ul>
<hr>
<h2><a href="https://thein.fo/4s8K1Ag">据报OpenAI、甲骨文及软银合资的 Stargate 数据中心项目陷入停滞</a> <code>#3</code></h2>
<blockquote>
<p>据<strong>The Information</strong>报道，<strong>OpenAI</strong>、<strong>甲骨文</strong>和<strong>软银</strong>联合成立的<strong>Stargate</strong>合资企业目前并未真正启动，既无人员配置也未开始建设<code>数据中心</code>。受各方控制权争夺及融资分歧影响，该项目陷入停滞，迫使<strong>OpenAI</strong>调整策略并撤回了自建<code>数据中心</code>的计划。</p>
</blockquote>
<p>据媒体 <strong>The Information</strong> 报道，由 <strong>OpenAI</strong>、<strong>Oracle</strong> 与 <strong>软银</strong> 共同组建的 <strong>Stargate</strong> 合资企业项目实质上已陷入停滞。该项目自高调官宣以来，既未完成人员配置，也未启动任何 <code>数据中心</code> 建设工作。</p>
<p>报道揭示，项目停滞源于内部矛盾，主要体现在对控制权的争夺、融资事项的推诿，以及在东京进行的马拉松式谈判，据称这些谈判需依赖便利店食物维系。这一局面迫使 <strong>OpenAI</strong> 调整策略，已（至少暂时）撤回了自行建设 <code>数据中心</code> 的计划以满足 <code>算力</code> 需求。</p>
<p>不过，有非官方声音认为该报道或夸大了问题，但也承认其中所披露的谈判细节令人担忧。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/94173400-4414-4c7c-92be-5053d688db87/c9fabd7a-5bf4-4597-89e2-0837520293db/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://thein.fo/4s8K1Ag">https://thein.fo/4s8K1Ag</a></li>
<li><a href="https://x.com/theinformation/status/2025650558577557661">https://x.com/theinformation/status/2025650558577557661</a></li>
</ul>
<hr>
<h2><a href="https://x.com/btibor91/status/2025332472511189059">OpenAI 将推出100美元订阅层 Pro Lite</a> <code>#4</code></h2>
<blockquote>
<p>据社区发现，<strong>OpenAI</strong>正在网页代码中推进每月<strong>100美元</strong>的<code>ChatGPT Pro Lite</code>订阅计划，意在填补现有<strong>20美元</strong><code>Plus</code>与<strong>200美元</strong><code>Pro</code>之间的空白。</p>
</blockquote>
<p>据媒体报道及社区发现，<strong>OpenAI</strong>正在推进<strong>月费100美元</strong>的“<code>ChatGPT Pro Lite</code>”订阅计划。该层级最早由<strong>工程师Tibor Blaho</strong>在网页代码中挖掘发现，且有社区用户称已可订阅。</p>
<p>分析指出，此举旨在填补现有<strong>Plus（20美元）<strong>与</strong>Pro（200美元）<strong>之间的价格空白，满足经常触及</strong>Plus</strong>限制但又无需<strong>Pro</strong>无限访问权限的重度用户需求，如自由职业者和开发者。此外，该层级也可能为未来算力消耗更大的<code>Agent</code>功能做铺垫。目前<strong>OpenAI</strong>尚未公布官方发布日期及完整权益列表。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/94173400-4414-4c7c-92be-5053d688db87/14c19dba-4aa9-4d17-ae37-959ac9dbca5b/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/btibor91/status/2025332472511189059">https://x.com/btibor91/status/2025332472511189059</a></li>
<li><a href="https://www.testingcatalog.com/openai-prepares-new-chatgpt-pro-lite-tier-priced-at-100-monthly/">https://www.testingcatalog.com/openai-prepares-new-chatgpt-pro-lite-tier-priced-at-100-monthly/</a></li>
</ul>
<hr>
<h2><a href="https://news.samsung.com/global/galaxy-ai-expands-multi-agent-ecosystem-to-give-users-more-choice-and-flexibility">三星 Galaxy AI 集成 Perplexity</a> <code>#5</code></h2>
<blockquote>
<p><strong>三星</strong>宣布扩展<code>Galaxy AI</code>以构建<code>多Agent</code>生态系统，并确认将在即将推出的旗舰设备中引入<code>Perplexity</code>。用户只需通过<code>Hey Plex</code>语音指令或长按侧边键，即可无缝调用该AI执行多步骤任务。</p>
</blockquote>
<p><strong>三星电子</strong>宣布扩展<strong>Galaxy AI</strong>，致力于构建开放且集成的<code>多Agent</code>生态系统，并确认将在即将推出的旗舰<strong>Galaxy</strong>设备中引入<strong>Perplexity</strong>作为新的<code>AI Agent</code>。根据<strong>三星</strong>内部研究，近<strong>80%<strong>的用户已依赖两种以上<code>AI Agent</code>，为此</strong>Galaxy AI</strong>将通过<code>系统级集成</code>扮演“编排者”角色，减少用户在应用间的切换。用户可通过语音唤醒词“<strong>Hey Plex</strong>”或长按侧边键激活<strong>Perplexity</strong>。该<code>Agent</code>已深度嵌入<strong>Samsung Notes</strong>、<strong>Gallery</strong>等系统应用及部分第三方应用，旨在提供流畅的<code>多步骤工作流</code>。官方同时提醒，使用某些<code>AI功能</code>可能需要登录<strong>三星账户</strong>，且不对AI输出的准确性做保证，功能可用性将受地区、设备及运营商限制。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/94173400-4414-4c7c-92be-5053d688db87/ac4845f7-1c3c-4697-9841-41d1c2accc25/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://news.samsung.com/global/galaxy-ai-expands-multi-agent-ecosystem-to-give-users-more-choice-and-flexibility">https://news.samsung.com/global/galaxy-ai-expands-multi-agent-ecosystem-to-give-users-more-choice-and-flexibility</a></li>
</ul>
<hr>
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
<p>作者<code>橘鸦Juya</code>，视频版在同名<strong>哔哩哔哩</strong>。欢迎<strong>点赞、关注、分享</strong>。</p>
]]></content:encoded><guid isPermaLink="false">https://github.com/imjuya/juya-ai-daily/issues/6</guid><pubDate>Mon, 23 Feb 2026 00:45:57 +0000</pubDate></item><item><title>2026-02-22</title><link>https://imjuya.github.io/juya-ai-daily/issue-5/</link><description>AI 早报 2026-02-22 视频版：YouTube ｜ 哔哩哔哩 概览 开发生态 智谱为 GLM Coding Plan 规则变动与体验下降致歉并提出补偿方案 ↗ #1 千问推出 Qwen Coding Plan ↗ #2 Claude Code 引入内置 Git Worktree 支持 ↗ #3 OpenAI 扩展 Batch API 支持 GPT 图像模型 ↗ #4 产品应用 微软确认 Copilot 默认共享 Bing 与 Edge 数据 ↗ #5 OpenClaw 发布 v2026.2.21 版本更新 ↗ #6 技术与洞察 Taalas 亮相固化模型推理芯片 HC1 ↗ #7 Andrej Karpathy 评析 Claw 技术及安全隐患 ↗ #8 前瞻与传闻 OpenAI 曾考虑就加拿大疑似枪…</description><content:encoded><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260222/2026022208065849501269e9_cover_921f.png" alt=""></p>
<h1>AI 早报 2026-02-22</h1>
<p><strong>视频版</strong>：<a href="https://www.youtube.com/watch?v=MslV6QgT3Mw">YouTube</a> ｜ <a href="https://www.bilibili.com/video/BV1gLZfB8Ewq">哔哩哔哩</a></p>
<h2>概览</h2>
<h3>开发生态</h3>
<ul>
<li>智谱为 GLM Coding Plan 规则变动与体验下降致歉并提出补偿方案 <a href="https://mp.weixin.qq.com/s/qgVsa17L5Seqw9yXr1iExQ">↗</a> <code>#1</code></li>
<li>千问推出 Qwen Coding Plan <a href="https://bailian.console.aliyun.com/">↗</a> <code>#2</code></li>
<li>Claude Code 引入内置 Git Worktree 支持 <a href="https://t.co/cjOXhUDL0i">↗</a> <code>#3</code></li>
<li>OpenAI 扩展 Batch API 支持 GPT 图像模型 <a href="https://x.com/OpenAIDevs/status/2025273441826517370">↗</a> <code>#4</code></li>
</ul>
<h3>产品应用</h3>
<ul>
<li>微软确认 Copilot 默认共享 Bing 与 Edge 数据 <a href="https://www.windowslatest.com/2026/02/19/copilot-quietly-pulls-your-data-from-other-microsoft-products-including-edge-and-msn-but-you-can-opt-out/">↗</a> <code>#5</code></li>
<li>OpenClaw 发布 v2026.2.21 版本更新 <a href="https://github.com/openclaw/openclaw/releases/tag/v2026.2.21">↗</a> <code>#6</code></li>
</ul>
<h3>技术与洞察</h3>
<ul>
<li>Taalas 亮相固化模型推理芯片 HC1 <a href="https://chatjimmy.ai/">↗</a> <code>#7</code></li>
<li>Andrej Karpathy 评析 Claw 技术及安全隐患 <a href="https://x.com/karpathy/status/2024987174077432126">↗</a> <code>#8</code></li>
</ul>
<h3>前瞻与传闻</h3>
<ul>
<li>OpenAI 曾考虑就加拿大疑似枪手的聊天内容向警方报案 <a href="https://www.wsj.com/us-news/law/openai-employees-raised-alarms-about-canada-shooting-suspect-months-ago-b585df62">↗</a> <code>#9</code></li>
<li>据报 OpenAI 文件上调了五年收入预期 <a href="https://x.com/theinformation/status/2025280618917945476">↗</a> <code>#10</code></li>
<li>Anthropic 拟推 Claude API CLI 工具 <a href="https://github.com/anthropics/anthropic-cli">↗</a> <code>#11</code></li>
</ul>
<hr>
<h2><a href="https://mp.weixin.qq.com/s/qgVsa17L5Seqw9yXr1iExQ">智谱为 GLM Coding Plan 规则变动与体验下降致歉并提出补偿方案</a> <code>#1</code></h2>
<blockquote>
<p><strong>智谱</strong>团队就 <code>GLM Coding Plan</code> 规则变动与体验下降致歉，支持受影响用户申请退款，留存用户获赠<strong>15</strong>天时长。还允许在<strong>2月12日至16日</strong>期间误升级的用户，权益升级至无周限额的老套餐，并承诺未来核心权益调整将提前说明。</p>
</blockquote>
<p><strong>智谱团队</strong>就 <code>GLM Coding Plan</code> 规则变动与体验下降向用户致歉，承认在 <code>规则透明度</code>、<code>灰度节奏</code> 及 <code>老用户升级机制</code> 上存在失误。</p>
<p>官方说明 <code>GLM-5</code> 参数规模达 <code>GLM-4.7</code> <strong>两倍</strong>以上，采取高峰期<strong>3倍</strong>、非高峰期<strong>2倍</strong>的消耗策略，看板刷新频率已优化至<strong>10分钟</strong>。因流量激增及遭受攻击，服务按 <code>Max</code>、<code>Pro</code>、<code>Lite</code> 顺序开放，目前 <code>Max</code> 已全面开放，<code>Pro</code> 高峰期限流，<code>Lite</code> 将在之后 <code>灰度开放</code>。</p>
<p>解决方案包括：支持 <code>Lite</code>/<code>Pro</code> 用户退款；赠送已使用及留存用户<strong>15天</strong>时长；<strong>2月12日至16日</strong>误升级用户可一键升级至 <code>无周限额老套餐</code>。官方承诺未来 <code>核心权益调整</code> 将提前说明。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/f1a4210b-01bc-41a0-a19d-f66876ee58f9/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/qgVsa17L5Seqw9yXr1iExQ">https://mp.weixin.qq.com/s/qgVsa17L5Seqw9yXr1iExQ</a></li>
</ul>
<hr>
<h2><a href="https://bailian.console.aliyun.com/">千问推出 Qwen Coding Plan</a> <code>#2</code></h2>
<blockquote>
<p><strong>千问团队</strong>推出 <code>Qwen Coding Plan</code>，支持 <code>Qwen3.5-Plus</code>、<code>Qwen3-Max</code> 等最新模型，新客首月仅需 <strong>7.9 元</strong>。</p>
</blockquote>
<p><strong>千问团队</strong>近期推出 <code>Qwen Coding Plan</code>，旨在让开发者低成本体验最新模型，支持 <code>Qwen3.5-Plus</code>、<code>Qwen3-Max</code>，并适配 <code>Cursor</code>、<code>Cline</code> 等主流工具。定价方面，新客首月 <strong>7.9 元</strong>，老客享 <strong>5 折</strong>优惠。用户现可访问<strong>阿里云百炼</strong>官网开通体验。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/4913669f-1d7e-4e0d-8686-23e6764cb52b/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/4913669f-1d7e-4e0d-8686-23e6764cb52b/m002.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://bailian.console.aliyun.com/">https://bailian.console.aliyun.com/</a></li>
</ul>
<hr>
<h2><a href="https://t.co/cjOXhUDL0i">Claude Code 引入内置 Git Worktree 支持</a> <code>#3</code></h2>
<blockquote>
<p><strong>Claude Code CLI</strong> 上线了内置 <code>Git Worktree</code> 支持，将此前仅限 <strong>Desktop</strong> 端的隔离能力扩展至 <code>CLI</code>，解决多个 <code>Agent</code> 并行运行时的文件冲突问题。</p>
</blockquote>
<p><strong>Claude Code</strong> 官方在 <strong>2.1.50</strong> 版本中引入了内置 <code>Git Worktree</code> 支持，将此前仅限 <code>Desktop</code> 应用的功能扩展至 <code>CLI</code>。此功能通过 <code>Git Worktree</code> 机制，允许多个 <code>Agent</code> 在同一仓库的独立工作目录中并行运行，解决了因共享工作目录导致的文件冲突与覆盖问题。</p>
<p>目前，<code>CLI</code> 端支持 <code>claude --worktree</code> 参数启动，可自动或手动命名工作树；<code>Desktop</code> 应用增设了 <code>Worktree</code> 模式开关；<code>Subagent</code> 同样支持 <code>Worktree</code> 隔离，便于执行大规模代码迁移等并行任务；用户可通过 <code>Frontmatter</code> 配置 <code>"isolation": "worktree"</code>，使自定义 <code>Agent</code> 默认在隔离环境中运行；该设计还兼容 <code>Mercurial</code>、<code>Perforce</code> 等非 <code>Git</code> 版本控制系统，用户可通过定义 <code>Hooks</code> 实现同等隔离效果。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/3cdd1d5a-58ed-4168-82b2-b2aefcbc9499/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://t.co/cjOXhUDL0i">https://t.co/cjOXhUDL0i</a></li>
</ul>
<hr>
<h2><a href="https://x.com/OpenAIDevs/status/2025273441826517370">OpenAI 扩展 Batch API 支持 GPT 图像模型</a> <code>#4</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 宣布 <code>Batch API</code> 现已支持 <code>GPT 图像模型</code>，该功能覆盖 <code>gpt-image-1.5</code> 等多个模型，拥有独立速率限制并节省 <strong>50%</strong> 调用成本。</p>
</blockquote>
<p><strong>OpenAI</strong> 宣布其 <code>Batch API</code> 现已扩展支持 GPT 图像模型，旨在满足开发者对大规模图像生成与编辑的需求。此次更新覆盖 <code>gpt-image-1.5</code>、<code>chatgpt-image-latest</code>、<code>gpt-image-1</code> 及 <code>gpt-image-1-mini</code> <strong>四款</strong>模型。</p>
<p>开发者现可通过 <code>该 API</code> 提交异步作业，单次任务上限达 <strong>50,000</strong> 个。此外，该服务设有独立速率限制，不占用标准 <code>API</code> 配额，且相比常规调用可节省 <strong>50%</strong> 的成本。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/ee18fa85-4cee-4b83-8e7a-ed0ac14e022e/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/ee18fa85-4cee-4b83-8e7a-ed0ac14e022e/m002.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/OpenAIDevs/status/2025273441826517370">https://x.com/OpenAIDevs/status/2025273441826517370</a></li>
</ul>
<hr>
<h2><a href="https://www.windowslatest.com/2026/02/19/copilot-quietly-pulls-your-data-from-other-microsoft-products-including-edge-and-msn-but-you-can-opt-out/">微软确认 Copilot 默认共享 Bing 与 Edge 数据</a> <code>#5</code></h2>
<blockquote>
<p><strong>微软</strong>确认<strong>Copilot</strong>现已默认开启数据共享机制，自动提取<strong>Bing</strong>、<strong>MSN</strong>及<strong>Edge</strong>的用户数据以增强个性化记忆。</p>
</blockquote>
<p>据 <strong>Windows Latest</strong> 报道，<strong>微软</strong>确认 <code>Copilot</code> 现默认开启数据共享机制，自动从 <strong>Bing</strong>、<strong>MSN</strong> 及 <strong>Edge</strong> 等产品提取数据以增强记忆与个性化功能。用户虽可在设置中关闭 <code>Microsoft usage data</code> 开关，但需额外点击 <code>Delete all memory</code> 方能彻底清除数据。<strong>微软</strong>强调该数据仅用于个性化定制，不用于训练 <code>AI 模型</code>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/324005c9-c689-42c4-8bac-ac948bcc7945/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.windowslatest.com/2026/02/19/copilot-quietly-pulls-your-data-from-other-microsoft-products-including-edge-and-msn-but-you-can-opt-out/">https://www.windowslatest.com/2026/02/19/copilot-quietly-pulls-your-data-from-other-microsoft-products-including-edge-and-msn-but-you-can-opt-out/</a></li>
</ul>
<hr>
<h2><a href="https://github.com/openclaw/openclaw/releases/tag/v2026.2.21">OpenClaw 发布 v2026.2.21 版本更新</a> <code>#6</code></h2>
<blockquote>
<p><strong>OpenClaw</strong> 发布 <strong>v2026.2.21</strong> 版本，重点支持 <code>Gemini 3.1</code>，并实施了大规模安全加固。</p>
</blockquote>
<p><strong>OpenClaw</strong> 官方近日发布 <strong>v2026.2.21</strong> 版本更新。该版本重点引入了对 <code>Gemini 3.1</code> 的支持，并实施了大规模安全加固。在功能方面，新增 <strong>Discord</strong> 流媒体传输与语音频道支持，并引入 <code>Thread-bound subagent sessions</code> 优化会话管理。针对移动端，新版本优化了 <strong>iOS</strong> 及 <strong>Watch</strong> 平台体验，提升了网关稳定性并微调了 <code>Prompt caching</code>。官方表示本次更新包含 <strong>100</strong> 多项修复，详情已发布在 <strong>GitHub</strong> 上。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/45a3e7b9-1ebe-4b01-8321-fa39decbe1dd/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/openclaw/openclaw/releases/tag/v2026.2.21">https://github.com/openclaw/openclaw/releases/tag/v2026.2.21</a></li>
</ul>
<hr>
<h2><a href="https://chatjimmy.ai/">Taalas 亮相固化模型推理芯片 HC1</a> <code>#7</code></h2>
<blockquote>
<p>AI芯片初创公司<strong>Taalas</strong>近期展示了首款芯片<code>HC1</code>。该产品通过将<code>模型权重</code>“固化”到<code>硅片</code>中，在<code>量化版</code>Llama 3.1-8B上实现了每秒超过<strong>1.5万</strong>个<code>Token</code>的<code>推理速度</code>，用户可在<code>chatjimmy.ai</code>上进行测试。<strong>Taalas</strong>目前已获得超过<strong>2亿美元</strong>融资，并计划在<strong>今年夏季</strong>推出第二款<code>推理芯片</code>。</p>
</blockquote>
<p>AI芯片初创公司<strong>Taalas</strong>发布首款产品<code>HC1</code>，采用<code>硬连线</code>技术将模型直接固化在硅片中。<code>HC1</code>基于<strong>台积电</strong><code>6nm</code>工艺，功耗约<strong>250W</strong>。据<strong>EE Times</strong>实测，其运行<code>Llama 3.1-8B</code>的速度超每秒<strong>15,000</strong>个<code>Token</code>，公司内部测试近<strong>17,000</strong>，远超<strong>Nvidia</strong>等现有硬件。该方案虽牺牲灵活性，但仅需修改<strong>两层</strong><code>掩模版</code>即可在<strong>两个月</strong>内完成定制。内部模拟数据显示，其<strong>30</strong>芯集群运行<code>DeepSeek R1</code>吞吐量达每秒<strong>12,000</strong>个<code>Token</code>，总拥有成本显著低于<code>GPU</code>。公司已融资超<strong>2亿美元</strong>，计划<strong>今夏</strong>推出第二款芯片，<strong>年底前</strong>支持前沿模型。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/b1caced2-6da8-4412-90d7-b6b6eb97a31d/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/b1caced2-6da8-4412-90d7-b6b6eb97a31d/m002.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://chatjimmy.ai/">https://chatjimmy.ai/</a></li>
<li><a href="https://www.eetimes.com/taalas-specializes-to-extremes-for-extraordinary-token-speed/">https://www.eetimes.com/taalas-specializes-to-extremes-for-extraordinary-token-speed/</a></li>
</ul>
<hr>
<h2><a href="https://x.com/karpathy/status/2024987174077432126">Andrej Karpathy 评析 Claw 技术及安全隐患</a> <code>#8</code></h2>
<blockquote>
<p><strong>Andrej Karpathy</strong> 近期专门购置 <strong>Mac Mini</strong> 测试 <code>Claws</code> 技术，他将 <code>Claws</code> 定义为位于 <code>LLM Agent</code> 之上的新层级，负责任务的编排与调度。</p>
</blockquote>
<p><strong>Andrej Karpathy</strong> 近期购买 <code>Mac Mini</code> 以测试 <code>Claws</code> 技术。<strong>Karpathy</strong> 将 <code>Claws</code> 定义为位于 <code>LLM Agent</code> 之上的新层级，负责编排、调度与持久化。</p>
<p>尽管看好该概念，<strong>Karpathy</strong> 对主流实现 <code>OpenClaw</code> 持保留态度。他称 <code>OpenClaw</code> 是一个由 <code>vibe coding</code> 构成的 <strong>40万行代码</strong> 庞然大物，存在 <code>RCE（远程代码执行）</code> 漏洞和供应链投毒等严重安全隐患，现状堪比“安全噩梦”。</p>
<p>他更看好 <code>NanoClaw</code> 等轻量级方案。<code>NanoClaw</code> 核心引擎仅约 <strong>4000行代码</strong>，且默认在 <code>容器</code> 中运行。其架构特点是通过 <code>Skills 指令</code> 修改源码来集成功能，而非依赖 <code>配置文件</code>，<strong>Karpathy</strong> 赞赏其为一种防止配置混乱的新范式。与此同时，社区也涌现出 <code>nanobot</code>、<code>nullclaw</code> 等多个同类项目。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/75f00d96-2986-4a0b-9a49-bf4ba0e173b0/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/karpathy/status/2024987174077432126">https://x.com/karpathy/status/2024987174077432126</a></li>
</ul>
<hr>
<h2><a href="https://www.wsj.com/us-news/law/openai-employees-raised-alarms-about-canada-shooting-suspect-months-ago-b585df62">OpenAI 曾考虑就加拿大疑似枪手的聊天内容向警方报案</a> <code>#9</code></h2>
<blockquote>
<p>据**《华尔街日报》<strong>报道，加拿大一名涉嫌杀害</strong>8人**的凶手曾利用<code>ChatGPT</code>探讨枪支暴力，<strong>OpenAI</strong>虽封禁了其账号，但认为未达到举报标准，未在案发前通知警方。</p>
</blockquote>
<p>据**《华尔街日报》<strong>报道，涉嫌在加拿大Tumbler Ridge杀害</strong>8人<strong>的</strong>18岁<strong>嫌疑人</strong>Jesse Van Rootselaar**，曾在<strong>OpenAI</strong>的<code>ChatGPT</code>上进行涉及枪支暴力的对话。相关记录于<strong>2025年6月</strong>被<strong>OpenAI</strong>的监控工具标记，其账号亦遭封禁。报道指出，<strong>OpenAI</strong>员工曾就是否向加拿大执法部门举报进行内部辩论，但最终在事发前未采取行动。<strong>OpenAI</strong>发言人回应称，该嫌疑人的活动未达到向执法部门报告的标准，公司是在事件发生后才联系了加拿大当局。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.wsj.com/us-news/law/openai-employees-raised-alarms-about-canada-shooting-suspect-months-ago-b585df62">https://www.wsj.com/us-news/law/openai-employees-raised-alarms-about-canada-shooting-suspect-months-ago-b585df62</a></li>
</ul>
<hr>
<h2><a href="https://x.com/theinformation/status/2025280618917945476">据报 OpenAI 文件上调了五年收入预期</a> <code>#10</code></h2>
<blockquote>
<p>据 <strong>The Information</strong> 报道，<strong>OpenAI</strong> 大幅上调五年期收入预测，预计今年营收达 <strong>300 亿美元</strong>，目标是 <strong>2030 年</strong>实现 <strong>1500 亿美元</strong>的消费者销售。<code>ChatGPT</code> 周活用户已升至 <strong>9.1 亿</strong>，但高昂的 <code>算力成本</code> 导致毛利率下滑，公司预计到 <strong>2030 年</strong>在基础设施上的投入将高达 <strong>6650 亿美元</strong>，并计划在当年实现 <code>现金流转正</code>。</p>
</blockquote>
<p>据媒体 <strong>The Information</strong> 报道，<strong>OpenAI</strong> 在内部文件中大幅上调<strong>五年期</strong>收入预测约 <strong>27%</strong>，但预计到 <strong>2030 年</strong>现金消耗将高达 <strong>1110 亿至 1120 亿美元</strong>。</p>
<p>文件显示，公司去年收入达 <strong>131 亿美元</strong>，今年和明年的收入目标分别为 <strong>300 亿</strong>和 <strong>620 亿美元</strong>。其中，面向消费者的销售预计今年翻倍至 <strong>170 亿美元</strong>，并计划在 <strong>2030 年</strong>达到 <strong>1500 亿美元</strong>。</p>
<p>高额的 <code>算力</code> 成本是主要支出。公司预计到 <strong>2030 年</strong>在基础设施和计算资源上的投入将达 <strong>6650 亿美元</strong>，导致 <code>调整后毛利率</code> 从 <strong>40%</strong> 降至 <strong>33%</strong>，未达预期目标。今年的总支出预计为 <strong>250 亿美元</strong>，明年将增至 <strong>570 亿美元</strong>。</p>
<p>用户增长方面，<strong>ChatGPT</strong> <code>周活跃用户</code>数已达 <strong>9.1 亿</strong>，受益于 <code>GPT-5.1</code> 和 <code>5.2</code> 等更新带来的体验提升，公司长期目标是在 <strong>2030 年</strong>实现 <strong>27.5 亿</strong><code>周活跃用户</code>。尽管面临巨额投入，<strong>OpenAI</strong> 仍预计在 <strong>2030 年</strong>实现 <code>现金流转正</code>，截至去年年底其账面现金约为 <strong>400 亿美元</strong>。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/theinformation/status/2025280618917945476">https://x.com/theinformation/status/2025280618917945476</a></li>
</ul>
<hr>
<h2><a href="https://github.com/anthropics/anthropic-cli">Anthropic 拟推 Claude API CLI 工具</a> <code>#11</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 正在开发一款专门用于 <strong>Claude API</strong> 的 <code>命令行工具</code> <strong>Anthropic CLI</strong>，目前该项目的 <strong>GitHub</strong> <code>仓库</code> 已经上线。</p>
</blockquote>
<p>据<strong>Anthropic</strong>成员<strong>Katelyn Lesse</strong>透露，公司正在开发一款针对<code>Claude API</code>的命令行工具<strong>Anthropic CLI</strong>。她表示，团队正在推进该工具的发布，并建议用户“敬请期待”。目前，该项目的<strong>GitHub</strong>代码仓库刚刚创建，开发者可先行关注。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/d7cfe691-3514-495f-89bf-a1d04203714f/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/anthropics/anthropic-cli">https://github.com/anthropics/anthropic-cli</a></li>
</ul>
<hr>
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
<p>作者<code>橘鸦Juya</code>，视频版在同名<strong>哔哩哔哩</strong>。欢迎<strong>点赞、关注、分享</strong>。</p>
]]></content:encoded><guid isPermaLink="false">https://github.com/imjuya/juya-ai-daily/issues/5</guid><pubDate>Sun, 22 Feb 2026 00:32:33 +0000</pubDate></item><item><title>2026-02-21</title><link>https://imjuya.github.io/juya-ai-daily/issue-4/</link><description>AI 早报 2026-02-21 视频版：YouTube ｜ 哔哩哔哩 概览 开发生态 Anthropic 员工回应 Claude Agent SDK 及 OAuth 令牌争议 #1 Claude Code 桌面版发布重大更新 #2 Anthropic 发布 Claude Code Security #3 GPT-5.3-Codex-Spark 升级速率超 1200 tokens/s #4 Google CLI 开启 3.1 Pro 访问权限 #5 Ollama 发布新版原生集成 Cline 与 Pi #6 产品应用 OpenAI 扩充 ChatGPT Thinking 模式上下文窗口 #7 行业动态 智谱 MiniMax 市值接连超越快手京东 #8 GGML 团队加入 Hugging Face #9 技术与…</description><content:encoded><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260221/20260221084518976101edba_cover_46a9.png" alt=""></p>
<h1>AI 早报 2026-02-21</h1>
<p><strong>视频版</strong>：<a href="https://www.youtube.com/watch?v=GddxDudZ_bE">YouTube</a> ｜ <a href="https://www.bilibili.com/video/BV1XAf7BnEy6">哔哩哔哩</a></p>
<h2>概览</h2>
<h3>开发生态</h3>
<ul>
<li>Anthropic 员工回应 Claude Agent SDK 及 OAuth 令牌争议 <code>#1</code></li>
<li>Claude Code 桌面版发布重大更新 <code>#2</code></li>
<li>Anthropic 发布 Claude Code Security <code>#3</code></li>
<li>GPT-5.3-Codex-Spark 升级速率超 1200 tokens/s <code>#4</code></li>
<li>Google CLI 开启 3.1 Pro 访问权限 <code>#5</code></li>
<li>Ollama 发布新版原生集成 Cline 与 Pi <code>#6</code></li>
</ul>
<h3>产品应用</h3>
<ul>
<li>OpenAI 扩充 ChatGPT Thinking 模式上下文窗口 <code>#7</code></li>
</ul>
<h3>行业动态</h3>
<ul>
<li>智谱 MiniMax 市值接连超越快手京东 <code>#8</code></li>
<li>GGML 团队加入 Hugging Face <code>#9</code></li>
</ul>
<h3>技术与洞察</h3>
<ul>
<li>Karpathy 称传统 App Store 模式将过时 <code>#10</code></li>
</ul>
<h3>前瞻与传闻</h3>
<ul>
<li>OpenAI 或将推出 ChatGPT Pro Lite 订阅 <code>#11</code></li>
<li>Google DeepMind 宣布将发布 Gemma 新模型 <code>#12</code></li>
<li>传 OpenAI 打造首款摄像头 AI 智能音箱 <code>#13</code></li>
<li>OpenAI 传获软银领衔百亿注资 <code>#14</code></li>
</ul>
<hr>
<h2><a href="https://x.com/trq212/status/2024212380142752025">Anthropic 员工回应 Claude Agent SDK 及 OAuth 令牌争议</a> <code>#1</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 员工回应了关于 <code>Claude Agent SDK</code> 及 <code>OAuth</code> 令牌使用的争议，称此前的文档变更仅为措辞调整，鼓励开发者使用 <code>Agent SDK</code> 进行本地实验，但如果基于该 <code>SDK</code> 构建商业产品，则必须通过 <code>API Key</code> 进行调用。</p>
</blockquote>
<p>针对<code>Claude Agent SDK</code>及<code>OAuth令牌</code>使用政策的争议，<strong>Anthropic</strong>员工<strong>Thariq</strong>近日澄清，引发混淆的文档变更仅为措辞调整，并未改变<code>Agent SDK</code>及<code>MAX</code>订阅的使用方式。官方立场鼓励使用<code>Agent SDK</code>进行本地开发与实验，但若基于其构建商业产品，则需使用<code>API Key</code>。其表示将优化文档表述以消除误解。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/5f83d37d-0684-4302-9c27-9590d079fb04/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/trq212/status/2024212380142752025">https://x.com/trq212/status/2024212380142752025</a></li>
</ul>
<hr>
<h2><a href="https://x.com/claudeai/status/2024937960572104707">Claude Code 桌面版发布重大更新</a> <code>#2</code></h2>
<blockquote>
<p><code>Claude Code</code> 桌面版迎来重大更新，新增 <code>Server Previews</code>、<code>Local Code Review</code>、<code>PR Monitoring</code> 及 <code>Session Mobility</code> <strong>四大</strong>核心功能。<code>Claude</code> 现在能直接在桌面端启动服务器预览应用，自动审查<code>代码</code>中的<code>Bug</code>，并监控<code>CI</code>状态，实现自动修复与合并。</p>
</blockquote>
<p><strong>Claude</strong> 官方宣布 <code>Claude Code</code> 桌面版迎来重大更新，新增 <code>Server previews</code>、<code>Local code review</code>、<code>PR monitoring</code> 及 <code>Session mobility</code> 核心功能。更新后，<strong>Claude</strong> 可在桌面端直接启动开发服务器并预览应用，结合日志与截图进行迭代；代码提交前支持行内 Bug 审查；PR 流程中具备 <code>Auto-fix</code> 和 <code>Auto-merge</code> 能力，可自动修复故障并在通过检查后合并代码。此外，<code>Session mobility</code> 实现了 <code>CLI</code> 与桌面、云端及移动端间的会话无缝迁移。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/cd6a6d9a-d92c-4a06-92ea-cb636b11effd/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/claudeai/status/2024937960572104707">https://x.com/claudeai/status/2024937960572104707</a></li>
</ul>
<hr>
<h2><a href="https://www.anthropic.com/news/claude-code-security">Anthropic 发布 Claude Code Security</a> <code>#3</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 推出了集成在 <code>Claude Code</code> 中的新功能 <code>Claude Code Security</code>，该功能由 <code>Claude Opus 4.6</code> 驱动，能像人类安全专家一样对代码进行推理，从而发现传统工具难以捕捉的业务逻辑漏洞。<strong>Enterprise</strong> 和 <strong>Team</strong> 客户以及开源项目维护者现可申请试用。</p>
</blockquote>
<p><strong>Anthropic</strong> 官方宣布推出 <code>Claude Code Security</code>，现处于有限研究预览阶段。该功能集成在 <code>Claude Code (Web)</code> 中，由 <code>Claude Opus 4.6</code> 驱动。不同于依赖<code>模式匹配</code>的传统<code>静态分析工具</code>，该工具能像人类一样推理代码，通过理解组件交互和数据流向，发现<code>业务逻辑缺陷</code>等<code>复杂漏洞</code>。官方数据显示，该模型已协助团队在开源代码中发现超过 <strong>500</strong> 个隐藏漏洞。所有发现均经过多阶段验证和评级，修复需经人工批准。目前，<strong>Enterprise</strong> 和 <strong>Team</strong> 客户及开源项目维护者均可申请访问。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/6c68bcc6-1913-48d7-80c1-06f7ac6ad98f/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.anthropic.com/news/claude-code-security">https://www.anthropic.com/news/claude-code-security</a></li>
</ul>
<hr>
<h2><a href="https://x.com/thsottiaux/status/2024947946849186064">GPT-5.3-Codex-Spark 升级速率超 1200 tokens/s</a> <code>#4</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 宣布 <code>GPT-5.3-Codex-Spark</code> 模型速度得到提升，突破每秒 <strong>1200</strong> 个 <code>tokens</code>，后续将推出更多全局性速度优化。</p>
</blockquote>
<p><code>GPT-5.3-Codex-Spark</code> 官方宣布该模型已完成性能升级，速度提升约 <strong>30%</strong>，当前服务速度已超 <strong>1200</strong> tokens/s。此外，官方预告未来将在全范围内推出更多速度优化计划。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/5391a66f-9c5d-4547-8fb6-a7b502695166/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/thsottiaux/status/2024947946849186064">https://x.com/thsottiaux/status/2024947946849186064</a></li>
</ul>
<hr>
<h2><a href="https://x.com/geminicli/status/2024967271681233356">Google CLI 开启 3.1 Pro 访问权限</a> <code>#5</code></h2>
<blockquote>
<p><code>Gemini CLI</code> 目前已向 <strong>AI Ultra</strong> 和 <strong>Workspace Ultra</strong> 账户开放 <code>Gemini 3.1 Pro</code> 访问权限。官方将根据系统容量逐步扩大访问范围。</p>
</blockquote>
<p><strong>Gemini CLI</strong> 团队正在逐步推送 <code>Gemini 3.1 Pro</code> 访问权限。目前获权用户包括：通过 <strong>Google</strong> 登录的 <strong>AI Ultra</strong> 和 <strong>Workspace Ultra</strong> 账户、拥有该模型权限的 <strong>AI Studio</strong> 及 <strong>Vertex AI</strong> 项目 <code>API Key</code> 持有者，以及小部分其他登录用户。用户可在 <code>CLI</code> 中输入 <code>/model</code> 命令验证状态。官方表示将根据系统容量逐步扩大范围。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/495b9cf1-b67e-4a5c-b1a9-c04f1a9f63b0/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/geminicli/status/2024967271681233356">https://x.com/geminicli/status/2024967271681233356</a></li>
<li><a href="https://github.com/google-gemini/gemini-cli/discussions/19724">https://github.com/google-gemini/gemini-cli/discussions/19724</a></li>
</ul>
<hr>
<h2><a href="https://x.com/ollama/status/2024987888870416673">Ollama 发布新版原生集成 Cline 与 Pi</a> <code>#6</code></h2>
<blockquote>
<p><strong>Ollama</strong> 发布新版，集成了 <code>Cline</code> 和 <code>Pi</code>，用户通过指令 <code>ollama launch cline</code> 或 <code>ollama launch pi</code> 即可开箱即用。</p>
</blockquote>
<p><strong>Ollama</strong> 发布 <strong>0.16.3</strong> 版本，新增对 <strong>Cline</strong> 和 <strong>Pi</strong> 的开箱即用集成支持，用户可通过 <code>ollama launch</code> 指令直接启动相应服务。<strong>Cline</strong> 作者 <strong>Saoud Rizwan</strong> 对此表示，尽管目前尚处早期，但未来笔记本电脑运行的开源模型将足以完成大部分工作，很高兴与 <strong>Ollama</strong> 合作推动这一愿景成为现实。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/f33b7761-2fb5-429e-83e9-28f1e22a3e96/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/ollama/status/2024987888870416673">https://x.com/ollama/status/2024987888870416673</a></li>
</ul>
<hr>
<h2><a href="https://x.com/trq212/status/2024212380142752025">OpenAI 扩充 ChatGPT Thinking 模式上下文窗口</a> <code>#7</code></h2>
<blockquote>
<p><strong>ChatGPT</strong> 更新日志显示，<strong>ChatGPT</strong> 的 <code>Thinking 模式</code> <code>上下文窗口</code> 已扩容至 <strong>256k</strong> <code>tokens</code>。</p>
</blockquote>
<p>根据 <strong>ChatGPT</strong> 更新日志，<strong>ChatGPT</strong> 的 <code>Thinking 模式</code>上下文窗口容量已扩充。当用户手动启用该模式时，其总上下文窗口从此前的 <strong>196k tokens</strong> 提升至 <strong>256k tokens</strong>。新版本的具体配置为 <strong>128k tokens</strong> 的输入限制和 <strong>128k tokens</strong> 的最大输出限制。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/366a06ca-7075-43cb-991b-9cc0217ac475/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/trq212/status/2024212380142752025">https://x.com/trq212/status/2024212380142752025</a></li>
</ul>
<hr>
<h2><a href="https://mp.weixin.qq.com/s/neThU7OwEOM7S_TSSroI4A">智谱 MiniMax 市值接连超越快手京东</a> <code>#8</code></h2>
<blockquote>
<p>据报道，<strong>智谱</strong>与 <strong>MiniMax</strong> 港股股价大涨并创新高，市值已连超<strong>携程</strong>、<strong>快手</strong>及<strong>京东</strong>。</p>
</blockquote>
<p>据报道，大模型公司<strong>智谱</strong>与 <strong>MiniMax</strong> 近期港股股价大幅上涨，创上市以来新高。两家公司市值已接连超越<strong>携程</strong>、<strong>快手</strong>及<strong>京东</strong>，并逼近<strong>泡泡玛特</strong>与<strong>百度</strong>。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/neThU7OwEOM7S_TSSroI4A">https://mp.weixin.qq.com/s/neThU7OwEOM7S_TSSroI4A</a></li>
</ul>
<hr>
<h2><a href="https://huggingface.co/blog/ggml-joins-hf">GGML 团队加入 Hugging Face</a> <code>#9</code></h2>
<blockquote>
<p><strong>Hugging Face</strong> 宣布 <strong>GGML</strong> 组织及其创始人 <strong>Georgi Gerganov</strong> 团队正式加入 <strong>Hugging Face</strong>，双方将结合 <code>llama.cpp</code> 在本地推理的优势与 <code>Transformers</code> 的模型定义能力，共同推动 <code>Local AI</code> 发展。</p>
</blockquote>
<p><strong>Hugging Face</strong> 官方宣布，<strong>GGML</strong> 组织及创始人 <strong>Georgi Gerganov</strong> 团队正式加入。双方将结合 <code>llama.cpp</code> 本地推理优势与 <code>transformers</code> 模型定义能力，推动 Local AI 发展。官方确认，原团队保留对 <code>llama.cpp</code> 的 <strong>100%</strong> 技术决策权与社区领导权，项目维持开源模式。未来将致力于实现“一键式”模型部署与优化 <strong>GGML</strong> 用户体验，使本地推理成为云端的有力替代。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/df4ae420-98e2-4f12-a3ff-b44d303a1917/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://huggingface.co/blog/ggml-joins-hf">https://huggingface.co/blog/ggml-joins-hf</a></li>
</ul>
<hr>
<h2><a href="https://x.com/karpathy/status/2024583544157458452">Karpathy 称传统 App Store 模式将过时</a> <code>#10</code></h2>
<blockquote>
<p><strong>Andrej Karpathy</strong> 展示了他利用 <code>Claude</code> 仅用 <strong>1 小时</strong>就构建出的定制化心肺训练仪表盘，以此预言传统的 <strong>App Store</strong> 模式将过时，未来将由 <code>LLM Agent</code> 即时生成满足特定长尾需求的软件。</p>
</blockquote>
<p><strong>Andrej Karpathy</strong>通过构建定制化心肺训练追踪仪表盘，展示了他对未来“高度定制化软件”的设想。为执行一项为期<strong>8周</strong>的计划，旨在通过<code>Zone 2</code>训练与<code>HIIT</code>将静息心率从<strong>50</strong>降至<strong>45</strong>，他利用<code>Claude</code>在<strong>1小时</strong>内编写了一个约<strong>300行代码</strong>的<code>Web应用</code>。该应用通过<code>逆向工程</code><strong>Woodway</strong>跑步机云端<code>API</code>获取原始数据，尽管过程中出现单位换算和日历匹配错误需人工修复，但他认为这相比于<strong>2年前</strong>完成同样工作所需的<strong>10小时</strong>，效率已大幅提升。</p>
<p><strong>Karpathy</strong>指出，传统<strong>App Store</strong>模式正变得过时，因为针对高度特定的长尾需求，<code>LLM Agent</code>能够即时生成完全贴合需求的定制应用。他认为当前行业进展缓慢，<strong>99%<strong>的产品本质上作为传感器，却仍只提供人类可读的文档和<code>前端</code>，缺乏<code>AI原生</code>的<code>CLI</code>和<code>API</code>，迫使Agent进行<code>逆向工程</code>。他展望未来，行业应重构为具备<code>Agent原生工效学</code>的传感器与<code>执行器</code>服务，通过“<code>LLM胶水</code>”进行编排，并借助拥有大量个人上下文的<code>AI</code>，最终实现仅需</strong>1分钟</strong>即可构建高度定制、临时化应用程序的目标。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/98e67eea-963d-4845-aff0-23424da380c2/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/karpathy/status/2024583544157458452">https://x.com/karpathy/status/2024583544157458452</a></li>
</ul>
<hr>
<h2><a href="https://x.com/btibor91/status/2024992285591818329">OpenAI 或将推出 ChatGPT Pro Lite 订阅</a> <code>#11</code></h2>
<blockquote>
<p>开发者<strong>Tibor Blaho</strong>在<code>ChatGPT</code>网页代码中发现了名为<code>ChatGPT Pro Lite</code>的新订阅层级，外界推测定价可能在<strong>50</strong>或<strong>100美元</strong>，但目前<strong>OpenAI</strong>官方尚未确认该消息。</p>
</blockquote>
<p>据开发者 <strong>Tibor Blaho</strong> 发现， <strong>ChatGPT</strong> 网页应用代码中出现了对“ <code>ChatGPT Pro Lite</code> ”计划的引用。此举引发了社区关于 <strong>OpenAI</strong> 或将推出新订阅层级的猜测，据推测其定价可能在 <strong>50至100美元</strong>。目前，官方尚未对该计划的存在、功能详情或上线时间做出任何确认。所有信息均源自代码线索，相关讨论仅为推测。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/43049b7c-9410-4e2c-a9ef-852f5c62f26b/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/btibor91/status/2024992285591818329">https://x.com/btibor91/status/2024992285591818329</a></li>
</ul>
<hr>
<h2>Google DeepMind 宣布将发布 Gemma 新模型 <code>#12</code></h2>
<blockquote>
<p><strong>Google DeepMind</strong>联合创始人<strong>Demis Hassabis</strong>透露，即将发布针对<code>边缘设备</code>进行优化的<code>开源模型``Gemma</code>新版本。</p>
</blockquote>
<p>据社交媒体信息，<strong>Google DeepMind</strong>联合创始人<strong>Demis Hassabis</strong>近期在印度透露，公司将“很快”发布开源模型<code>Gemma</code>的新版本。<strong>Hassabis</strong>强调，新版本将针对<code>边缘设备</code>进行优化，具备强大性能，旨在为<code>资源受限环境</code>提供支持，拓展<code>终端</code>及<code>边缘计算</code>场景的能力边界。</p>
<hr>
<h2><a href="https://www.theinformation.com/articles/inside-openai-team-developing-ai-devices">传 OpenAI 打造首款摄像头 AI 智能音箱</a> <code>#13</code></h2>
<blockquote>
<p>据报道，<strong>OpenAI</strong>正研发一款配备摄像头的智能音箱作为首款<code>AI硬件</code>。该设备能通过<code>视觉感知</code>环境与用户面部，提供主动建议及<code>人脸识别</code>购物功能，预计售价<strong>200至300美元</strong>，最早<strong>2027年初</strong>上市。</p>
</blockquote>
<p>据报道，<strong>OpenAI</strong>正与前苹果设计师<strong>Jony Ive</strong>合作，组建一支超<strong>200</strong>人的团队研发<code>AI</code>硬件设备。其首款产品或为一款带摄像头的智能音箱，该设备可通过摄像头感知用户及环境，内置类<code>Face ID</code>的面部识别以支持交互，并能主动提供建议。产品售价预计<strong>200</strong>至<strong>300</strong>美元，最早或于<strong>2027年初</strong>上市。<strong>OpenAI</strong>还在探索智能灯、<code>AI</code>眼镜及耳机等产品，但这些项目尚处早期，存在被取消可能，预计<strong>2028年</strong>或更晚面世。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.theinformation.com/articles/inside-openai-team-developing-ai-devices">https://www.theinformation.com/articles/inside-openai-team-developing-ai-devices</a></li>
<li><a href="https://the-decoder.com/openai-is-building-a-200-to-300-smart-speaker-that-tells-you-when-to-go-to-bed/">https://the-decoder.com/openai-is-building-a-200-to-300-smart-speaker-that-tells-you-when-to-go-to-bed/</a></li>
</ul>
<hr>
<h2><a href="https://the-decoder.com/nvidia-reportedly-set-to-invest-30-billion-in-openai/">OpenAI 传获软银领衔百亿注资</a> <code>#14</code></h2>
<blockquote>
<p>据多家媒体报道，<strong>OpenAI</strong> 正在推进新一轮巨额融资，<strong>软银</strong>预计注资 <strong>300 亿美元</strong>。此外，<strong>路透社</strong>消息称，<strong>英伟达</strong>也计划投资 <strong>300 亿美元</strong>，<strong>亚马逊</strong>可能参与其中。</p>
</blockquote>
<p>据多家媒体报道，<strong>OpenAI</strong>正在推进新一轮融资。<strong>The Information</strong>援引消息称，<strong>软银</strong>预计将作为锚定投资者注资<strong>300亿美元</strong>，<strong>亚马逊</strong>和<strong>英伟达</strong>也可能参与投资，金额或达<strong>数百亿美元</strong>。</p>
<p>针对<strong>英伟达</strong>的投资动向，<strong>路透社</strong>援引知情人士透露，<strong>英伟达</strong>也计划向<strong>OpenAI</strong>投资<strong>300亿美元</strong>。目前，上述投资计划均属市场传闻，官方尚未发布正式公告。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://the-decoder.com/nvidia-reportedly-set-to-invest-30-billion-in-openai/">https://the-decoder.com/nvidia-reportedly-set-to-invest-30-billion-in-openai/</a></li>
<li><a href="https://x.com/theinformation/status/2024865405458661503">https://x.com/theinformation/status/2024865405458661503</a></li>
</ul>
<hr>
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
<p>作者<code>橘鸦Juya</code>，视频版在同名<strong>哔哩哔哩</strong>。欢迎<strong>点赞、关注、分享</strong>。</p>
]]></content:encoded><guid isPermaLink="false">https://github.com/imjuya/juya-ai-daily/issues/4</guid><pubDate>Sat, 21 Feb 2026 01:34:11 +0000</pubDate></item><item><title>2026-02-20</title><link>https://imjuya.github.io/juya-ai-daily/issue-3/</link><description>AI 早报 2026-02-20 视频版：YouTube ｜ 哔哩哔哩 概览 精选 Google发布Gemini 3.1 Pro Preview #1 Anthropic 明确禁止 Claude 订阅接入第三方 #2 Anthropic发布Claude API自动缓存 #3 模型发布 Zyphra发布首个大脑数据基础模型ZUNA #4 Jina AI发布jina-embeddings-v5-text #5 开发生态 Google Jules新增CI修复与提交署名 #6 Hugging Face推出Coding Agent 免费微调模型功能 #7 OpenRouter上线模型 Benchmarks 页面 #8 Cline CLI npm包遭遇供应链攻击 #9 产品应用 OpenAI优化ChatGPT交互式代码块…</description><content:encoded><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260220/202602200848013165970043_cover_1636.png" alt=""></p>
<h1>AI 早报 2026-02-20</h1>
<p><strong>视频版</strong>：<a href="https://www.youtube.com/watch?v=XLvV1_DEeBM">YouTube</a> ｜ <a href="https://www.bilibili.com/video/BV1YXZBBCE86">哔哩哔哩</a></p>
<h2>概览</h2>
<h3>精选</h3>
<ul>
<li>Google发布Gemini 3.1 Pro Preview <code>#1</code></li>
<li>Anthropic 明确禁止 Claude 订阅接入第三方 <code>#2</code></li>
<li>Anthropic发布Claude API自动缓存 <code>#3</code></li>
</ul>
<h3>模型发布</h3>
<ul>
<li>Zyphra发布首个大脑数据基础模型ZUNA <code>#4</code></li>
<li>Jina AI发布jina-embeddings-v5-text <code>#5</code></li>
</ul>
<h3>开发生态</h3>
<ul>
<li>Google Jules新增CI修复与提交署名 <code>#6</code></li>
<li>Hugging Face推出Coding Agent 免费微调模型功能 <code>#7</code></li>
<li>OpenRouter上线模型 Benchmarks 页面 <code>#8</code></li>
<li>Cline CLI npm包遭遇供应链攻击 <code>#9</code></li>
</ul>
<h3>产品应用</h3>
<ul>
<li>OpenAI优化ChatGPT交互式代码块 <code>#10</code></li>
<li>Anthropic 向 Pro 用户开放 Claude in PowerPoint <code>#11</code></li>
<li>网易有道开源个人助理Agent LobsterAI <code>#12</code></li>
<li>Google Labs发布Pomelli影棚级产品照功能 <code>#13</code></li>
<li>NotebookLM发布幻灯片修订及PPTX导出 <code>#14</code></li>
<li>YouTube扩展对话式AI至电视平台 <code>#15</code></li>
</ul>
<h3>行业动态</h3>
<ul>
<li>OpenAI向AI对齐研究基金捐赠 750 万美元 <code>#16</code></li>
<li>OpenAI联手塔塔集团布局印度市场 <code>#17</code></li>
<li>传Ineffable寻求十亿美元种子轮融资 <code>#18</code></li>
</ul>
<h3>技术与洞察</h3>
<ul>
<li>Anthropic发布关于AI Agent自主性的实证研究报告 <code>#19</code></li>
<li>强化学习奠基人Sutton提出经验时代论 <code>#20</code></li>
</ul>
<h3>前瞻与传闻</h3>
<ul>
<li>传OpenAI正开发ChatGPT成人模式 <code>#21</code></li>
</ul>
<hr>
<h2><a href="https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro">Google发布Gemini 3.1 Pro Preview</a> <code>#1</code></h2>
<blockquote>
<p><strong>Google</strong> 发布了 <code>Gemini 3.1 Pro Preview</code>，该模型强化了<code>推理能力</code>，显著增强了<code>代码生成能力</code>和 <code>Agent 工具调用</code>的稳定性。新版本<code>API</code>新增<code>medium</code>思考模式。目前该模型已通过 <code>Gemini App</code>、<code>AI Studio</code>及 <strong>Antigravity</strong> 等渠道开放。定价与前代保持一致。</p>
</blockquote>
<p><strong>Google</strong>发布<code>Gemini 3.1 Pro Preview</code>，这是其<code>3 Pro系列</code>的首个更新，距前代发布约<strong>三个月</strong>。该Preview版本面向开发者、企业与消费者，重点提升了<code>推理能力</code>、<code>软件工程可靠性</code>与<code>Agent任务稳定性</code>。</p>
<p>在<code>ARC-AGI-2</code>基准测试中，该模型得分达<strong>77.1%</strong>，较前代<code>Gemini 3 Pro</code>的<strong>31.1%<strong>实现翻倍以上增长。在其它专业评测中，该模型在<code>GPQA Diamond</code>科学知识测试中得分超</strong>94%</strong>，<code>SWE-Bench Verified</code>代码修复任务得分达<strong>80.6%</strong>，<code>APEX-Agents</code>长链任务得分从<strong>18.4%<strong>提升至</strong>33.5%</strong>。</p>
<p>技术参数方面，模型维持<code>100万token</code>的上下文处理能力，并将<code>API</code>文件上传限制从<strong>20MB</strong>提升至<strong>100MB</strong>。模型还引入了<code>medium</code>思考等级，并推出<code>专属端点</code>以优化<code>混合工具调用</code>的可靠性。</p>
<p>定价与<code>Gemini 3 Pro</code>保持一致，该模型已通过<code>Google AI App</code>、<code>NotebookLM</code>及<code>AI Studio</code>、<code>Vertex AI</code>等开发者工具开放，并登陆了多家第三方平台。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/05f29e08-e47b-42bb-b5ed-21294a7bb06d/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/05f29e08-e47b-42bb-b5ed-21294a7bb06d/m002.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/05f29e08-e47b-42bb-b5ed-21294a7bb06d/m003.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro">https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro</a></li>
</ul>
<hr>
<h2><a href="https://code.claude.com/docs/en/legal-and-compliance">Anthropic 明确禁止 Claude 订阅接入第三方</a> <code>#2</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 更新了 <code>Claude Code</code> 的使用条款，明确禁止将 <strong>Free</strong>、<strong>Pro</strong> 和 <strong>Max</strong> 计划的 <code>OAuth Token</code> 用于任何第三方工具或 <code>Agent SDK</code>。</p>
</blockquote>
<p><strong>Anthropic</strong>近期更新了<code>Claude Code</code>的法律与合规文档，重点明确了认证机制的使用范围与限制。官方规定，通过<strong>Free、Pro和Max订阅计划</strong>获取的<code>OAuth Token</code>仅限用于<code>Claude Code</code>和<code>Claude.ai</code>，严禁将其用于包括<code>Agent SDK</code>在内的任何第三方产品、工具或服务，否则将被视为违反消费者服务条款。官方要求，构建产品或服务的开发者必须通过<code>Claude Console</code>或受支持的云提供商使用<code>API Key</code>进行认证，并保留在无事先通知的情况下采取强制执行措施的权利。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/8d38fbb8-5459-4728-9ff3-e74dbd9d720f/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://code.claude.com/docs/en/legal-and-compliance">https://code.claude.com/docs/en/legal-and-compliance</a></li>
<li><a href="https://www.anthropic.com/legal/commercial-terms">https://www.anthropic.com/legal/commercial-terms</a></li>
</ul>
<hr>
<h2><a href="https://x.com/i/article/2024515623544639493">Anthropic发布Claude API自动缓存</a> <code>#3</code></h2>
<blockquote>
<p><strong>Anthropic</strong>为<code>Claude API</code>上线了自动提示词缓存功能，开发者只需设置一个<code>cache_control</code>参数， 系统即可自动缓存系统指令和历史记录等上下文。</p>
</blockquote>
<p><strong>Anthropic</strong> 近期为 <code>Claude API</code> 引入自动 <code>Prompt Caching</code>（提示词缓存）功能，旨在通过复用计算结果降低多轮对话的延迟与成本。开发者只需在 <code>API</code> 请求中设置单个 <code>cache_control</code> 参数，系统便会自动缓存该参数之前的上下文，如系统指令、工具描述等。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/29350904-bf06-40e1-9fe9-05e67d415718/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/i/article/2024515623544639493">https://x.com/i/article/2024515623544639493</a></li>
</ul>
<hr>
<h2><a href="https://huggingface.co/Zyphra/ZUNA">Zyphra发布首个大脑数据基础模型ZUNA</a> <code>#4</code></h2>
<blockquote>
<p><strong>Zyphra</strong> 正式发布了首个基于大脑数据训练的基础模型 <code>ZUNA</code>。这是一个拥有 <strong>3.8 亿</strong> 参数的 <code>掩码扩散自编码器</code>，能够高效解决 <code>头皮脑电图信号</code> 的去噪与缺失通道重建问题。</p>
</blockquote>
<p><strong>Zyphra</strong>发布首个基于大脑数据训练的基础模型<code>ZUNA</code>，这是一个<strong>380M</strong>参数的<code>掩码扩散自编码器</code>，旨在对<code>EEG信号</code>进行去噪、缺失通道重建及上采样。该模型基于约<strong>200万</strong>通道小时的公开数据训练，据官方称，其重建精度显著优于广泛使用的<code>MNE</code>插值方法，尤其在通道丢失率超**75%**或高倍上采样场景下优势明显。</p>
<p>技术上，<code>ZUNA</code>通过将连续信号压缩为<code>Token</code>并引入<code>4-D RoPE位置嵌入</code>，实现了对异构<code>EEG数据</code>的高效处理。目前，该模型已采用<code>Apache 2.0</code>协议开源，支持消费级<code>GPU</code>运行。官方强调<code>ZUNA</code>仅供研究使用，尚未验证医疗功效，并计划在未来开源相关数据及基础设施。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/3ea470a2-2862-4880-a2f0-7458ceef45a1/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://huggingface.co/Zyphra/ZUNA">https://huggingface.co/Zyphra/ZUNA</a></li>
<li><a href="https://github.com/Zyphra/zuna">https://github.com/Zyphra/zuna</a></li>
<li><a href="https://www.zyphra.com/zuna-technical-paper">https://www.zyphra.com/zuna-technical-paper</a></li>
</ul>
<hr>
<h2><a href="https://jina.ai/news/jina-embeddings-v5-text-distilling-4b-quality-into-sub-1b-multilingual-embeddings/">Jina AI发布jina-embeddings-v5-text</a> <code>#5</code></h2>
<blockquote>
<p><strong>Jina AI</strong> 发布并开源了<code>文本嵌入模型</code> <code>jina-embeddings-v5-text</code>，包含 <code>Small</code> 和 <code>Nano</code> 两个版本。</p>
</blockquote>
<p><strong>Jina AI</strong> 发布<strong>第五代</strong>文本嵌入模型系列 <code>jina-embeddings-v5-text</code>，包含 <strong>6.77 亿</strong>参数的 <code>small</code> 和 <strong>2.39 亿</strong>参数的 <code>nano</code> 两个版本。官方称，该系列结合模型蒸馏与任务特定 <code>LoRA</code> 适配器技术，实现了同级最优性能。其中，<code>small</code> 模型在 <code>MMTEB</code> 基准得分 <strong>67.0</strong>，支持 <strong>32K</strong> 上下文及 <strong>119 种</strong>语言；<code>nano</code> 模型则专为边缘部署优化，支持 <strong>8K</strong> 上下文。两款模型均支持 <code>Matryoshka</code> 嵌入截断与二进制量化，权重已依据 <code>CC BY-NC 4.0</code> 协议在 <code>Hugging Face</code> 公开，并提供 <code>API</code>、<code>GGUF</code> 及 <code>MLX</code> 等多种部署方式。此外，官方透露正开发多模态版本。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/191aa50e-e89c-49cf-b1d8-25a03efc6df7/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://jina.ai/news/jina-embeddings-v5-text-distilling-4b-quality-into-sub-1b-multilingual-embeddings/">https://jina.ai/news/jina-embeddings-v5-text-distilling-4b-quality-into-sub-1b-multilingual-embeddings/</a></li>
<li><a href="https://arxiv.org/abs/2602.15547">https://arxiv.org/abs/2602.15547</a></li>
<li><a href="https://jina.ai/models/jina-embeddings-v5-text-small/">https://jina.ai/models/jina-embeddings-v5-text-small/</a></li>
</ul>
<hr>
<h2><a href="https://jules.google/docs/changelog/2026-02-19">Google Jules新增CI修复与提交署名</a> <code>#6</code></h2>
<blockquote>
<p><strong>Google</strong> 旗下 <code>AI Agent Jules</code> 发布更新，新增 <code>CI Fixer</code> 自动修复功能。</p>
</blockquote>
<p><strong>Google</strong> 旗下 <code>AI Agent</code> <strong>Jules</strong> 发布更新，新增 <code>CI Fixer</code> 自动修复功能及可配置的提交作者身份。据官方更新日志，<code>CI Fixer</code> 可自动检测并修复 <strong>Jules</strong> 所创建 <code>PR</code> 中 <code>GitHub Actions</code> 的失败检查，无需人工干预即可完成错误接收、修正及重新提交。同时，新增的 <code>Commit Authoring</code> 设置提供“<strong>Jules</strong>”、“<code>Co-authored</code>”及“<code>User only</code>”三种模式。该用户级设置适用于所有仓库，解决了此前因 <strong>Jules</strong> 独占署名导致用户 <strong>GitHub</strong> <code>GitHub 贡献图</code> 无法体现实际工作的问题。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/a0feab5f-5fb8-4cdd-8d14-8512625885be/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://jules.google/docs/changelog/2026-02-19">https://jules.google/docs/changelog/2026-02-19</a></li>
</ul>
<hr>
<h2><a href="https://huggingface.co/blog/unsloth-jobs">Hugging Face推出Coding Agent 免费微调模型功能</a> <code>#7</code></h2>
<blockquote>
<p><strong>Hugging Face</strong> 与 <strong>Unsloth</strong> 合作推出了基于 <code>Coding Agent</code> 的免费模型微调服务，用户可通过验证领取免费 <code>GPU</code> 额度及 <strong>Pro</strong> 订阅。</p>
</blockquote>
<p><strong>Hugging Face</strong> 联合 <strong>Unsloth</strong> 推出通过 <code>Coding Agent</code> <strong>免费</strong>微调模型的新功能。官方目前向加入“<strong>Unsloth Jobs Explorers</strong>”组织并验证账单的用户提供 <strong>免费</strong> <code>GPU</code> 额度及 <strong>一个月</strong> <strong>Pro</strong> 订阅。该方案利用 <strong>Unsloth</strong> 约 <strong>2</strong> 倍速度提升和 <strong>60%</strong> <code>显存</code> 优化，重点支持 <strong>1GB</strong> <code>内存</code> 以下的小型模型。核心亮点在于支持 <code>Claude Code</code> 或 <code>Codex</code> 根据自然语言指令自动生成 <code>脚本</code>、提交 <code>云端任务</code> 及监控进度。据 <strong>Unsloth</strong> 创始人透露，该合作还支持 <code>强化学习</code>，旨在通过全托管 <code>云端环境</code> 实现无基础设施设置的快速迭代。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/c47a3967-6713-441a-8f61-dbe1261be5de/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://huggingface.co/blog/unsloth-jobs">https://huggingface.co/blog/unsloth-jobs</a></li>
</ul>
<hr>
<h2><a href="https://x.com/OpenRouter/status/2024172341190938958">OpenRouter上线模型 Benchmarks 页面</a> <code>#8</code></h2>
<blockquote>
<p><strong>OpenRouter</strong> 正式上线 <code>Benchmarks</code> 页面，直观展示模型在 <code>编程</code>、<code>数学</code> 及 <code>长上下文推理</code> 等维度的行业标准测试表现。</p>
</blockquote>
<p><strong>OpenRouter</strong> 宣布正式上线 Benchmarks 页面，展示模型在编程、数学、科学及长上下文推理等维度的行业标准表现，并计划未来扩展测试项目。与此同时，Rankings 页面迎来更新，新增 Intelligence、Coding 和 Agentic Index scores 排行榜，支持模型变体对比，旨在优化模型筛选体验。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/1ef083f3-a97d-4b5f-adff-86a3e866a2f3/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/OpenRouter/status/2024172341190938958">https://x.com/OpenRouter/status/2024172341190938958</a></li>
<li><a href="https://openrouter.ai/rankings#bench">https://openrouter.ai/rankings#bench</a></li>
</ul>
<hr>
<h2><a href="https://github.com/cline/cline/security/advisories/GHSA-9ppg-jx86-fqw7">Cline CLI npm包遭遇供应链攻击</a> <code>#9</code></h2>
<blockquote>
<p><code>Cline CLI</code> 官方确认遭遇 <code>供应链攻击</code>，攻击者利用被盗的 <strong>npm</strong> <code>令牌</code> 发布了恶意版本 <code>cline@2.3.0</code>。</p>
</blockquote>
<p>据官方安全公告与<strong>Endor Labs</strong>报告确认，<code>Cline CLI</code>在<code>npm注册表</code>遭遇<code>供应链攻击</code>。未授权方利用被盗用的<code>发布令牌</code>，发布了恶意版本 <code>cline@2.3.0</code>。该版本通过篡改 <code>postinstall</code> 脚本，在用户机器上全局静默安装名为<code>OpenClaw</code>的程序。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/0c93aaf2-9d16-4edc-b97a-1ed1f00abcb9/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/cline/cline/security/advisories/GHSA-9ppg-jx86-fqw7">https://github.com/cline/cline/security/advisories/GHSA-9ppg-jx86-fqw7</a></li>
</ul>
<hr>
<h2><a href="https://x.com/OpenAIDevs/status/2024600394299822096">OpenAI优化ChatGPT交互式代码块</a> <code>#10</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 升级了 <code>ChatGPT</code> 的 <code>代码块功能</code>，实现了编写、编辑与预览的一体化交互。</p>
</blockquote>
<p><strong>OpenAI</strong> 优化了 <code>ChatGPT</code> 的 <code>Code Blocks</code> 功能，将代码编写、编辑与预览集成于同一交互组件。用户现可在对话流程中直接构建并实时预览微型应用与图表，改变了以往静态显示模式。此次更新加强了对流程图和 <code>Mermaid 图表</code> 的原生支持，并新增 <code>代码调试</code> 功能。同时，引入的 <code>分屏</code> 与 <code>全屏视图</code> 优化了审查体验。该功能作为原生 <code>UI</code> 的一部分，旨在简化从构思到实现的转换过程。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/32915a41-6c62-4111-a99a-c0107af63349/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/OpenAIDevs/status/2024600394299822096">https://x.com/OpenAIDevs/status/2024600394299822096</a></li>
</ul>
<hr>
<h2><a href="https://claude.com/claude-in-powerpoint">Anthropic 向 Pro 用户开放 Claude in PowerPoint</a> <code>#11</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 宣布，<code>Claude in PowerPoint</code> 功能现已支持 Pro 计划，该功能可实现演示文稿的高效自动化生成。</p>
</blockquote>
<p><strong>Anthropic</strong> 官方宣布，<code>Claude in PowerPoint</code> 现已支持 <strong>Pro</strong> 计划，此前该功能已向 <strong>Max</strong>、<strong>Team</strong> 及 <strong>Enterprise</strong> 客户开放。该集成允许 <code>Claude</code> 在 <code>PowerPoint</code> 中实时构建、编辑幻灯片，并严格遵循 <code>Slide Master</code> 及 <code>品牌指南</code>。</p>
<p>主要功能包括：支持基于企业模板或从零开始生成完整草稿；能在保留原有格式的前提下进行精准修改，并将项目符号转化为可编辑的原生图表；此外，该功能现已支持 <code>connectors</code>，可将日常工具中的上下文直接引入幻灯片，并在现有 <code>合规框架</code> 内工作。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/9f5cb49d-e83e-4799-82ee-e57eed83d9b0/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://claude.com/claude-in-powerpoint">https://claude.com/claude-in-powerpoint</a></li>
<li><a href="https://x.com/claudeai/status/2024550844998570324">https://x.com/claudeai/status/2024550844998570324</a></li>
</ul>
<hr>
<h2><a href="https://github.com/netease-youdao/LobsterAI">网易有道开源个人助理Agent LobsterAI</a> <code>#12</code></h2>
<blockquote>
<p><strong>网易有道</strong>在 <strong>GitHub</strong> 开源了全场景个人助理项目 <code>LobsterAI</code>。</p>
</blockquote>
<p><strong>网易有道</strong>在 <strong>GitHub</strong> 开源全场景个人助理项目 <strong>LobsterAI</strong>。该工具基于 <code>Claude Agent SDK</code>，通过 <code>Cowork</code> 模式实现 7×<strong>24</strong> 小时自主办公。它支持本地或 <strong>Alpine Linux</strong> 沙箱环境，内置 <strong>16</strong> 种技能涵盖数据分析、PPT 制作及 <code>Playwright</code> 自动化等，且具备记忆提取与定时任务能力。<strong>LobsterAI</strong> 兼容 <strong>macOS</strong>、<strong>Windows</strong> 及 <strong>Linux</strong>，支持通过 <strong>钉钉</strong>、<strong>飞书</strong> 等 IM 远程触发，数据本地 <code>SQLite</code> 存储，现已在 <strong>GitHub</strong> 提供源码及安装包。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/6246bbd0-ebd2-4f84-9735-93ec53450353/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/netease-youdao/LobsterAI">https://github.com/netease-youdao/LobsterAI</a></li>
</ul>
<hr>
<h2><a href="https://blog.google/innovation-and-ai/models-and-research/google-labs/pomelli-photoshoot/">Google Labs发布Pomelli影棚级产品照功能</a> <code>#13</code></h2>
<blockquote>
<p><strong>Google Labs</strong>为<strong>免费</strong>营销工具<strong>Pomelli</strong>推出了<code>Photoshoot</code>功能，仅凭<strong>一张</strong>产品图就能自动生成符合品牌调性的专业级影棚照。目前已在美加澳新<strong>免费</strong>开放。</p>
</blockquote>
<p><strong>Google Labs</strong> 官方宣布为其<strong>免费</strong>营销工具 <strong>Pomelli</strong> 推出<code>Photoshoot</code>功能，旨在利用<code>Business DNA</code>和<code>Nano Banana</code>技术，协助中小企业及个人用户通过<strong>四步</strong>操作将单张产品图转化为符合品牌调性的专业级影棚照。用户仅需上传图片、选择模板、生成并微调，即可获得高质量图像。除核心功能外，<strong>Pomelli</strong> 还同步升级了图像生成模型，提升了准确性；新增了图像编辑及风格参考功能；在营销活动创建上，支持基于 URL 的上下文生成。目前该工具已在美国、加拿大、澳大利亚和新西兰<strong>免费</strong>开放。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/47df0fbd-b4db-40d5-87c2-ba63b0d0ffce/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/innovation-and-ai/models-and-research/google-labs/pomelli-photoshoot/">https://blog.google/innovation-and-ai/models-and-research/google-labs/pomelli-photoshoot/</a></li>
<li><a href="https://x.com/GoogleLabs/status/2024529795548102667">https://x.com/GoogleLabs/status/2024529795548102667</a></li>
</ul>
<hr>
<h2><a href="https://x.com/NotebookLM/status/2024585603703329259">NotebookLM发布幻灯片修订及PPTX导出</a> <code>#14</code></h2>
<blockquote>
<p><code>NotebookLM</code>现已向所有用户开放<code>PPTX</code>导出权限，免费用户也即将上线基于提示词的幻灯片调整功能。</p>
</blockquote>
<p><code>**NotebookLM**</code>官方宣布<code>Slide Revisions</code>功能已向所有付费用户推出，免费用户即将获支持；<code>PPTX</code>导出功能现已面向<code>**100%**</code>用户开放。此次核心更新<code>Prompt-Based Revisions</code>允许通过<code>提示词</code>微调幻灯片。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/14ea0454-45ec-44fb-b11c-7af0215def96/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/NotebookLM/status/2024585603703329259">https://x.com/NotebookLM/status/2024585603703329259</a></li>
</ul>
<hr>
<h2><a href="https://support.google.com/youtube/thread/18138167?hl=en">YouTube扩展对话式AI至电视平台</a> <code>#15</code></h2>
<blockquote>
<p><strong>YouTube</strong> 已将 <code>对话式 AI 工具</code> 扩展至智能电视及流媒体设备，允许成年用户在不中断视频观看的情况下实时提问并获得解答。</p>
</blockquote>
<p><strong>YouTube</strong> 宣布将其 <code>对话式 AI 工具</code> 作为实验性功能扩展至 <code>智能电视</code>、<code>游戏主机</code>及 <code>流媒体设备</code>。该功能允许部分 <strong>18</strong> 岁以上选定用户，通过 <code>遥控器麦克风</code> 或“Ask”按钮，在不中断视频播放的情况下提问并获得即时解答，目前支持英语等 <strong>五种</strong> 语言。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://support.google.com/youtube/thread/18138167?hl=en">https://support.google.com/youtube/thread/18138167?hl=en</a></li>
</ul>
<hr>
<h2><a href="https://openai.com/index/advancing-independent-research-ai-alignment/">OpenAI向AI对齐研究基金捐赠 750 万美元</a> <code>#16</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 宣布向 <strong>英国 AI 安全研究所</strong> 设立的独立研究基金 <strong>The Alignment Project</strong> 捐赠 <strong>750 万美元</strong>，以支持全球范围内的 <code>AI 对齐</code> 与 <code>AI 安全</code> 研究。</p>
</blockquote>
<p><strong>OpenAI</strong>宣布向由<strong>英国AI安全研究所（UK AISI）<strong>创建的独立基金</strong>The Alignment Project</strong>捐赠<strong>750万美元</strong>（约<strong>560万英镑</strong>）。该基金总额超<strong>2700万英镑</strong>，由<strong>Renaissance Philanthropy</strong>协助管理，重点资助<code>计算复杂性</code>、<code>博弈论</code>等领域的全球独立研究以缓解<code>AI风险</code>。单个项目资助额度通常在<strong>5万</strong>至<strong>100万英镑</strong>之间。<strong>OpenAI</strong>强调，此次注资旨在增加当前轮次已通过审查的高质量项目数量，而非干预现有流程，以支持与内部前沿研究互补的外部独立生态，确保<code>AGI</code>的安全性。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/a2ce6d67-a4f0-49fd-9afe-b39c7a6664e4/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://openai.com/index/advancing-independent-research-ai-alignment/">https://openai.com/index/advancing-independent-research-ai-alignment/</a></li>
</ul>
<hr>
<h2><a href="https://openai.com/openai-for-india/">OpenAI联手塔塔集团布局印度市场</a> <code>#17</code></h2>
<blockquote>
<p><strong>OpenAI</strong>与印度<strong>Tata集团</strong>达成战略合作，成为其数据中心的客户，首批锁定<strong>100MW</strong>容量并计划扩展至<strong>1GW</strong>，而<strong>Tata集团</strong>将在内部部署<code>ChatGPT Enterprise</code>。</p>
</blockquote>
<p>据媒体报道，<strong>OpenAI</strong>与印度<strong>Tata Group</strong>达成战略合作。<strong>OpenAI</strong>将成为<strong>TCS</strong>旗下<code>HyperVault</code>数据中心业务的首个客户，初步锁定<strong>100MW</strong>容量并计划扩展至<strong>1GW</strong>，以满足印度<code>数据驻留</code>及<code>低延迟</code>需求。双方还将在<strong>Tata集团</strong>内部署<code>ChatGPT Enterprise</code>覆盖数十万员工，并利用<code>Codex</code>工具标准化软件开发。此外，<strong>OpenAI</strong>计划<strong>今年晚些时候</strong>在孟买和班加罗尔设立新办事处，并将扩展认证项目，<strong>TCS</strong>将成为美国以外首个参与该项目的组织。据官方引用CEO <strong>Sam Altman</strong>估算，印度目前拥有超<strong>1亿</strong><code>ChatGPT</code>周活跃用户。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://openai.com/openai-for-india/">https://openai.com/openai-for-india/</a></li>
<li><a href="https://techcrunch.com/2026/02/18/openai-taps-tata-for-100mw-ai-data-center-capacity-in-india-eyes-1gw">https://techcrunch.com/2026/02/18/openai-taps-tata-for-100mw-ai-data-center-capacity-in-india-eyes-1gw</a></li>
</ul>
<hr>
<h2><a href="https://www.ft.com/content/dffe72d0-4064-4412-8ebc-50198a30d40e">传Ineffable寻求十亿美元种子轮融资</a> <code>#18</code></h2>
<blockquote>
<p>据报道，<code>AlphaGo</code>核心贡献者<strong>David Silver</strong>创立的<strong>Ineffable Intelligence</strong>正在筹集约<strong>10亿美元</strong><code>种子轮融资</code>，<strong>红杉资本</strong>领投，投前估值高达<strong>40亿美元</strong>。</p>
</blockquote>
<p>据<strong>金融时报</strong>报道，<code>AlphaGo</code>核心贡献者、前<strong>Google</strong> <strong>DeepMind</strong>资深研究员<strong>David Silver</strong>正在为伦敦初创公司<strong>Ineffable Intelligence</strong>筹集约<strong>10亿美元</strong>种子轮融资，由<strong>红杉资本</strong>领投，投前估值约<strong>40亿美元</strong>。若交易完成，这将创下欧洲史上最大种子轮融资纪录。据悉，<strong>英伟达</strong>、<strong>Google</strong>和<strong>微软</strong>也正参与谈判。</p>
<p>该公司致力于构建“无尽学习的超级智能”，其技术路径不同于主流<code>LLM</code>，而是基于Silver在<code>强化学习</code>领域的积累，利用<code>世界模型</code>在模拟环境中通过试错和自主经验持续进化。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.ft.com/content/dffe72d0-4064-4412-8ebc-50198a30d40e">https://www.ft.com/content/dffe72d0-4064-4412-8ebc-50198a30d40e</a></li>
</ul>
<hr>
<h2><a href="https://www.anthropic.com/research/measuring-agent-autonomy">Anthropic发布关于AI Agent自主性的实证研究报告</a> <code>#19</code></h2>
<blockquote>
<p><strong>Anthropic</strong>发布关于<code>AI Agent</code>自主性的实证研究报告，报告指出，用户信任积累使Agent单次自主运行时长已增长至<strong>45分钟</strong>以上。</p>
</blockquote>
<p><strong>Anthropic</strong>发布**《Measuring AI agent autonomy in practice》<strong>报告显示，<code>Agent</code>自主性取得显著进展。过去三个月内，<code>Claude Code</code>单次免干预最长运行时间从</strong>不到25分钟<strong>增至</strong>超过45分钟**，主要归因于用户信任度提升。在监督模式上，资深开发者相比新手更倾向全自动批准（<strong>超40%</strong> vs <strong>20%</strong>），但主动打断频率也更高（<strong>9%</strong> vs <strong>5%</strong>），体现了“充分放权但保持敏锐监控”的策略。此外，<code>Agent</code>在复杂任务中主动求助次数是人类打断次数的<strong>两倍多</strong>，确立了关键的安全机制。目前<strong>近半数</strong><code>Agent</code>操作集中在软件工程低风险领域，医疗、金融等高危行业虽已探索，但距离<code>规模化部署</code>尚有距离。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/b4168262-a53a-4f59-9516-4ae46025221b/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/b4168262-a53a-4f59-9516-4ae46025221b/m002.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.anthropic.com/research/measuring-agent-autonomy">https://www.anthropic.com/research/measuring-agent-autonomy</a></li>
</ul>
<hr>
<h2><a href="https://www.youtube.com/watch?v=lieqoaBV6ww">强化学习奠基人Sutton提出经验时代论</a> <code>#20</code></h2>
<blockquote>
<p><strong>图灵奖</strong>得主<strong>理查德·萨顿</strong>发表**《AI 的未来》**演讲，指出当前依赖人类数据的<code>大模型</code>仅是缺乏理解的<code>弱心智</code>，且正面临<code>数据枯竭</code>的天花板。让<code>智能体</code>通过与真实环境交互产生的<code>数据流</code>进行<code>持续学习</code>，是实现<code>超级智能</code>的必由之路。</p>
</blockquote>
<p>图灵奖得主、<code>强化学习</code>奠基人<strong>Richard Sutton</strong>近日在洛杉矶加州大学纯粹与应用数学研究所（IPAM）发表了题为《AI的未来》的演讲。<strong>Sutton</strong>直指当前基于人类数据训练的<code>大模型</code>仅为“弱心智”，虽拥有海量知识但缺乏理解与真值判断能力。他称这种智能的本质是“理解太少、调参太多”，并认为AI正面临人类高质量数据枯竭的天花板。</p>
<p><strong>Sutton</strong>提出，AI的未来属于“<code>经验时代</code>”。其核心是让<code>AI Agent</code>通过与环境的交互，从持续的经验流中学习，而非依赖静态的人类数据集。他指出，经验数据能随Agent能力提升而增长，这是实现突破、创造新知识的必由之路。他将过去十年划分为<code>模拟时代</code>、<code>人类数据时代</code>，以及正在开启的<code>经验时代</code>。</p>
<p>在政治与哲学层面，<strong>Sutton</strong>呼吁抵制对AI的集中控制，主张<code>去中心化合作</code>。他进一步提出宏大的宇宙演化视角，认为宇宙正进入“<code>设计时代</code>”，人类作为“<code>复制者</code>”的极限，其使命是创造具有设计能力的心智——即AI。因此，人类在这一进程中扮演着催化剂与先驱的角色，而资源与权力最终将流向更具智能的存在。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=lieqoaBV6ww">https://www.youtube.com/watch?v=lieqoaBV6ww</a></li>
<li><a href="https://mp.weixin.qq.com/s/N773VlnwHkUA-hNKRI_YtA">https://mp.weixin.qq.com/s/N773VlnwHkUA-hNKRI_YtA</a></li>
</ul>
<hr>
<h2><a href="https://x.com/testingcatalog/status/2024492284184563899">传OpenAI正开发ChatGPT成人模式</a> <code>#21</code></h2>
<blockquote>
<p>有用户在<code>ChatGPT</code>网页代码中发现，<strong>OpenAI</strong>疑似正在开发代号为<code>Citron Mode</code>的成人模式。</p>
</blockquote>
<p>据媒体报道，<strong>OpenAI</strong> 正在为 <code>ChatGPT</code> 开发 <code>成人模式</code>。开发者 <strong>Tibor Blaho</strong> 在其 <code>网页代码</code> 中发现了内部代号为 <code>Citron Mode</code> 的设置，据推测即为此功能。该模式引入 <code>敏感内容警告机制</code>，当用户分享被标记为 <code>citron-only</code> 的对话时，系统将显示警告，提示接收者可能需要验证年满 <strong>18岁</strong> 才能查看内容。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/f96fac1c-7916-4cdd-871b-23b35f1671b5/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/f96fac1c-7916-4cdd-871b-23b35f1671b5/m002.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/testingcatalog/status/2024492284184563899">https://x.com/testingcatalog/status/2024492284184563899</a></li>
<li><a href="https://x.com/TiborBlaho">https://x.com/TiborBlaho</a></li>
</ul>
<hr>
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
<p>作者<code>橘鸦Juya</code>，视频版在同名<strong>哔哩哔哩</strong>。欢迎<strong>点赞、关注、分享</strong>。</p>
]]></content:encoded><guid isPermaLink="false">https://github.com/imjuya/juya-ai-daily/issues/3</guid><pubDate>Fri, 20 Feb 2026 01:01:35 +0000</pubDate></item><item><title>2026-02-19</title><link>https://imjuya.github.io/juya-ai-daily/issue-2/</link><description>AI 早报 2026-02-19 视频版：YouTube ｜ 哔哩哔哩 概览 模型发布 Google DeepMind发布Lyria 3音乐生成模型 #1 xAI 发布16-Agent协作模式 Grok 4.20 Heavy #2 Prime Intellect开源106B参数MoE模型 #3 印度AI企业Sarvam发布Sarvam-30B与105B #4 开发生态 OpenAI 开源 Codex App Server 支持ChatGPT登录 #5 Figma 推出 Claude Code to Figma 功能 #6 OpenAI发布智能合约安全基准EVMbench #7 Gemini CLI 推出 v0.29.0 版本每周更新 #8 行业动态 谷歌、OpenAI 和微软宣布在印计划 #9 Perplex…</description><content:encoded><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260219/20260219090351005487a008_cover_73fa.png" alt=""></p>
<h1>AI 早报 2026-02-19</h1>
<p><strong>视频版</strong>：<a href="https://www.youtube.com/watch?v=qaQ1uDPjCqk">YouTube</a> ｜ <a href="https://www.bilibili.com/video/BV1WfZ8BqEu6">哔哩哔哩</a></p>
<h2>概览</h2>
<h3>模型发布</h3>
<ul>
<li>Google DeepMind发布Lyria 3音乐生成模型 <code>#1</code></li>
<li>xAI 发布16-Agent协作模式 Grok 4.20 Heavy <code>#2</code></li>
<li>Prime Intellect开源106B参数MoE模型 <code>#3</code></li>
<li>印度AI企业Sarvam发布Sarvam-30B与105B <code>#4</code></li>
</ul>
<h3>开发生态</h3>
<ul>
<li>OpenAI 开源 Codex App Server 支持ChatGPT登录 <code>#5</code></li>
<li>Figma 推出 Claude Code to Figma 功能 <code>#6</code></li>
<li>OpenAI发布智能合约安全基准EVMbench <code>#7</code></li>
<li>Gemini CLI 推出 v0.29.0 版本每周更新 <code>#8</code></li>
</ul>
<h3>行业动态</h3>
<ul>
<li>谷歌、OpenAI 和微软宣布在印计划 <code>#9</code></li>
<li>Perplexity撤下搜索平台广告 <code>#10</code></li>
<li>World Labs完成融资并与Autodesk合作 <code>#11</code></li>
</ul>
<h3>技术与洞察</h3>
<ul>
<li>智谱AI发布GLM-5技术报告 <code>#12</code></li>
</ul>
<hr>
<h2><a href="https://deepmind.google/models/lyria/">Google DeepMind发布Lyria 3音乐生成模型</a> <code>#1</code></h2>
<blockquote>
<p><strong>Google DeepMind</strong> 发布音乐生成模型 <code>Lyria 3</code>，并已在 <code>Gemini</code> 桌面端开启测试。用户只需输入文字描述或上传图片、视频，即可生成 <strong>30 秒</strong> 带歌词的 <code>高保真</code> 音乐，且支持对风格和人声的精细控制。该功能面向 <strong>18 岁</strong> 以上用户开放，生成的所有音轨均嵌入 <code>SynthID</code> 水印，以确保可追溯性。</p>
</blockquote>
<p><strong>Google DeepMind</strong> 发布最先进音乐生成模型 <strong>Lyria 3</strong>，并已在 <strong>Gemini App</strong> 中推出 Beta 版。用户可以通过 <code>文本转音轨</code> 功能，描述特定的流派、情绪、记忆甚至内部笑话来生成音乐；也可以利用 <code>图像/视频转音轨</code> 功能，上传照片或视频，让 AI 根据视觉内容的氛围自动谱曲并填写歌词。<strong>Gemini App</strong> 生成的音轨时长固定为 <strong>30</strong> 秒，并附带由 <code>Nano Banana</code> 生成的自定义封面图。</p>
<p>官方指出，<strong>Lyria 3</strong> 的 <strong>三大</strong> 改进点包括：自动生成歌词无需用户提供、提供对风格及人声和节奏的更强控制、以及生成更真实且音乐结构更复杂的曲目。该服务目前向所有 <strong>18</strong> 岁及以上的 <strong>Gemini</strong> 用户开放，支持英语、德语、西班牙语、法语、印地语、日语、韩语和葡萄牙语。桌面端现已可用，移动端预计将在未来几天内上线，<strong>Google AI Plus</strong>、<strong>Pro</strong> 和 <strong>Ultra</strong> 订阅用户将享有更高的使用额度。在 <strong>Gemini</strong> 应用中生成的所有音轨均嵌入了 <code>SynthID</code>，<strong>Gemini</strong> 亦上线了 <code>音频验证工具</code>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/f050b0b0-bd7f-4176-b7e3-b545c975855d/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://deepmind.google/models/lyria/">https://deepmind.google/models/lyria/</a></li>
<li><a href="https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/">https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/</a></li>
</ul>
<hr>
<h2><a href="https://x.com/elonmusk/status/2024194618930401590">xAI 发布16-Agent协作模式 Grok 4.20 Heavy</a> <code>#2</code></h2>
<blockquote>
<p><strong>Elon Musk</strong> 宣布<strong>xAI</strong>上线 <code>Grok 4.20 Heavy</code> 并向 Heavy 订阅用户开放。该模型核心架构为由 <strong>16</strong> 个专门化 <code>Agent</code> 组成的协作团队。</p>
</blockquote>
<p><strong>Elon Musk</strong>宣布推出<code>Grok 4.20 Heavy</code>，称其为重大升级，现已向<strong>Heavy</strong>订阅者开放。该版本核心变化在于底层架构调整，即在<code>grok-4.20架构</code>下运行由<strong>16</strong>个专门化<code>Agent</code>组成的团队进行<code>实时协作</code>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/e0145bc4-033f-4528-bfb5-5821485d31b6/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/elonmusk/status/2024194618930401590">https://x.com/elonmusk/status/2024194618930401590</a></li>
<li><a href="https://x.com/tetsuoai/status/2024121909286494435">https://x.com/tetsuoai/status/2024121909286494435</a></li>
</ul>
<hr>
<h2><a href="https://huggingface.co/PrimeIntellect/INTELLECT-3.1">Prime Intellect开源106B参数MoE模型</a> <code>#3</code></h2>
<blockquote>
<p><strong>Prime Intellect</strong> 发布了基于 <code>GLM-4.5-Air-Base</code> 通过 <code>强化学习</code> 训练的 <code>INTELLECT-3.1</code> 模型，显著提升了在数学、编程及 <code>Agent</code> 任务上的表现。</p>
</blockquote>
<p><strong>Prime Intellect</strong> 发布开源推理模型 <code>INTELLECT-3.1</code>。该模型采用 <code>Mixture-of-Experts (MoE)</code> 架构，拥有 <strong>106B</strong> 总参数及 <strong>A12B</strong> 活跃参数，基于 <code>zai-org/GLM-4.5-Air-Base</code> 并结合 <code>prime-rl</code> 框架进行了强化学习训练，重点提升了数学、编程、软件工程和 <code>Agent</code> 任务的能力。</p>
<p>官方已将模型、训练框架及环境以 <code>MIT</code> 和 <code>Apache 2.0</code> 协议完全开源，并提供了技术报告。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://huggingface.co/PrimeIntellect/INTELLECT-3.1">https://huggingface.co/PrimeIntellect/INTELLECT-3.1</a></li>
</ul>
<hr>
<h2><a href="https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai">印度AI企业Sarvam发布Sarvam-30B与105B</a> <code>#4</code></h2>
<blockquote>
<p>印度AI初创公司<strong>Sarvam</strong>发布了从零训练的<code>Sarvam-30B</code>和<code>Sarvam-105B</code>混合专家架构模型。根据官方数据，这两款模型针对印度本土语言进行了优化，在多项基准测试中表现出色。</p>
</blockquote>
<p>印度AI初创公司<strong>Sarvam</strong>近日发布了<strong>两款</strong>从零训练的<code>大型语言模型``Sarvam-30B</code>和<code>Sarvam-105B</code>，并同步推出语音及视觉模型。核心模型采用<code>混合专家架构</code>，获<strong>印度政府</strong>、<strong>Yotta</strong>及<strong>Nvidia</strong>支持。其中，<strong>30B</strong>模型预训练数据达<strong>16T</strong> <code>Token</code>，支持<strong>32k</strong> <code>上下文</code>；<strong>105B</strong>模型支持<strong>128k</strong> <code>上下文</code>，专攻复杂推理。官方数据显示，其性能优于或持平<code>Gemma</code>、<code>Qwen</code>等竞品。<strong>Sarvam</strong>计划开源<strong>这两款</strong>模型，并推出**“Sarvam for Work”<strong>企业工具及</strong>“Samvaad”**对话<code>Agent</code>平台。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/d06d1a70-4751-4a0e-a57a-33b53050c804/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/d06d1a70-4751-4a0e-a57a-33b53050c804/m002.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai">https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai</a></li>
</ul>
<hr>
<h2><a href="https://developers.openai.com/codex/app-server/">OpenAI 开源 Codex App Server 支持ChatGPT登录</a> <code>#5</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 开源了驱动 Codex 应用的底层框架 <code>Codex App Server</code>，允许开发者将 <code>Codex Agent</code> 深度集成到自有产品中。该工具支持通过 <strong>ChatGPT</strong> 账号 <code>OAuth</code> 直接接入第三方应用。</p>
</blockquote>
<p><strong>OpenAI</strong> 已开源其核心接口 <code>Codex App Server</code>，旨在让开发者在自有产品中深度集成 <code>Codex Agent</code>。该服务器是 Codex 富客户端（如 <code>VS Code</code> 扩展）的底层驱动，支持通过 <strong>ChatGPT</strong> 账号 <code>OAuth</code> 直接接入第三方应用，并提供身份验证、会话历史、审批流和流式 Agent 事件等完整功能。在协议层面，其采用类似 <code>MCP</code> 的 <code>JSON-RPC 2.0</code> 进行双向通信，支持 <code>stdio</code> 和实验性的 <code>websocket</code> 传输方式。客户端必须在连接后立即发送 <code>initialize</code> 请求并携带标识信息，企业级集成需在 <strong>OpenAI</strong> 平台注册。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/f1458b74-fc09-407d-9990-8504ee226fb2/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://developers.openai.com/codex/app-server/">https://developers.openai.com/codex/app-server/</a></li>
<li><a href="https://github.com/openai/codex/tree/main/codex-rs/app-server">https://github.com/openai/codex/tree/main/codex-rs/app-server</a></li>
</ul>
<hr>
<h2><a href="https://www.figma.com/blog/introducing-claude-code-to-figma/">Figma 推出 Claude Code to Figma 功能</a> <code>#6</code></h2>
<blockquote>
<p><strong>Figma</strong> 近期推出 <code>Claude Code to Figma</code> 功能，利用 <code>Figma MCP Server</code>，能够将 <code>Claude Code</code> 生成的 <code>UI</code> 直接转化为 <strong>Figma</strong> 画布上的可编辑 <code>Frame</code>。</p>
</blockquote>
<p><strong>Figma</strong> 近期推出“<code>Claude Code</code> to <strong>Figma</strong>”功能，通过更新<strong>Figma</strong><code>MCP server</code>，打通代码构建与设计协作。开发者可将<code>Claude Code</code>生成的真实<code>UI</code>转化为<strong>Figma</strong>画布上可编辑的<code>Frame</code>，支持捕捉完整流程并保留上下文，从而实现从“代码收敛”到“画布发散”的高效转换。该功能允许团队直接对代码生成的界面进行协作，避免了截图反馈的摩擦，并支持从设计回到代码的“往返”工作流。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/1aadc184-cda8-4630-858b-7a5f6b3a2db2/m001.gif" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.figma.com/blog/introducing-claude-code-to-figma/">https://www.figma.com/blog/introducing-claude-code-to-figma/</a></li>
</ul>
<hr>
<h2><a href="https://openai.com/index/introducing-evmbench/">OpenAI发布智能合约安全基准EVMbench</a> <code>#7</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 与 <strong>Paradigm</strong> 联合推出了<code>智能合约安全基准</code> <code>EVMbench</code>，旨在评估 <code>AI Agent</code> 在检测、修补及利用高危漏洞方面的<code>实战能力</code>。</p>
</blockquote>
<p><strong>OpenAI</strong> 联合 <strong>Paradigm</strong> 发布 <code>EVMbench</code> 基准，旨在评估 <code>AI Agent</code> 在 <code>智能合约</code> 安全领域（<code>检测</code>、<code>修补</code>、<code>利用</code>）的能力。该基准包含 <strong>120</strong> 个源自 <strong>40</strong> 次审计的漏洞场景，并配备基于 <code>Rust</code> 的测试工具和 <code>隔离沙盒</code> 环境。</p>
<p>官方评估显示，<code>GPT-5.3-Codex</code> 在 <code>Exploit</code> 模式得分 <strong>72.2%</strong>，显著优于 <code>GPT-5</code> 的 <strong>31.9%</strong>，但在 <code>检测</code> 和 <code>修补</code> 方面仍有提升空间。<strong>OpenAI</strong> 承认该基准存在环境与评分机制局限，不完全代表现实难度。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://openai.com/index/introducing-evmbench/">https://openai.com/index/introducing-evmbench/</a></li>
</ul>
<hr>
<h2><a href="https://github.com/google-gemini/gemini-cli/discussions/19473">Gemini CLI 推出 v0.29.0 版本每周更新</a> <code>#8</code></h2>
<blockquote>
<p><code>Gemini CLI</code> 推出 <code>v0.29.0</code> 版本更新，新增 <code>Ask User Tool</code> 支持模型交互式提问以澄清指令，同时引入 <code>Conductor</code> 和 <code>Firebase Agent Skills</code> 扩展，并上线了实验性 <code>Plan Mode</code>。</p>
</blockquote>
<p><strong>Gemini CLI</strong> 近日推出 <strong>v0.29.0</strong> 版本更新，新增 <code>Ask User Tool</code>，支持模型交互式暂停并询问用户以获取澄清。官方扩展了生态系统，引入 <strong>Conductor</strong> 扩展用于自动化逻辑审查与合规报告，以及 <strong>Firebase Agent Skills</strong> 扩展以优化开发体验。性能方面，更新优化了对海量工具输出的处理，防止 <code>上下文窗口</code> 过载，从而支持更长时间的高质量推理；同时改进了 <code>Vim</code> 编辑体验（支持 <code>W</code>、<code>B</code>、<code>E</code> 动作）及快捷键可发现性（按 <code>?</code> 唤起）。此外，官方首推实验性 <code>Plan Mode</code>，该只读模式旨在帮助用户在不修改文件的前提下映射代码库并验证假设。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/google-gemini/gemini-cli/discussions/19473">https://github.com/google-gemini/gemini-cli/discussions/19473</a></li>
</ul>
<hr>
<h2><a href="https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-india/">谷歌、OpenAI 和微软宣布在印计划</a> <code>#9</code></h2>
<blockquote>
<p>在新德里 <code>AI Impact Summit</code> 上，<strong>谷歌</strong>、<strong>OpenAI</strong> 和 <strong>微软</strong> 密集公布了它们在印度的最新计划。<strong>谷歌</strong>启动了连接美印的<code>战略光纤倡议</code>；<strong>OpenAI</strong> 联合当地顶尖高校，将 <code>ChatGPT Edu</code> 引入高等教育体系；<strong>微软</strong> 则承诺在印度培训 <strong>2000 万人</strong>。</p>
</blockquote>
<p>本周在新德里<strong>AI Impact Summit</strong>期间，<strong>Google</strong>、<strong>OpenAI</strong>和<strong>Microsoft</strong>密集公布在印扩展计划。<strong>Google</strong>启动“<strong>America-India Connect</strong>”光缆基建倡议，连接美印及南半球；<strong>Google.org</strong>投入共<strong>6000万美元</strong>用于科学及政府创新挑战赛，并深化在教育、农业及能源领域的<code>AI模型</code>部署。<strong>OpenAI</strong>通过与印度顶尖高校合作，将<code>ChatGPT Edu</code>整合进高等教育体系，覆盖逾<strong>10万</strong>师生。<strong>Microsoft</strong>宣布到本十年末向“<strong>全球南方</strong>”投资<strong>500亿美元</strong>，其中计划在<strong>2030年</strong>前培训<strong>2000万</strong>印度人。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-india/">https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-india/</a></li>
<li><a href="https://techcrunch.com/2026/02/18/openai-pushes-into-higher-education-as-india-seeks-to-scale-ai-skills">https://techcrunch.com/2026/02/18/openai-pushes-into-higher-education-as-india-seeks-to-scale-ai-skills</a></li>
</ul>
<hr>
<h2><a href="https://www.ft.com/content/6eec07a5-34a8-4f78-a9ed-93ab4263d43c">Perplexity撤下搜索平台广告</a> <code>#10</code></h2>
<blockquote>
<p>据报道，<strong>Perplexity</strong>将撤下平台所有广告，以确保用户信任和搜索准确性。公司战略重心现已转向订阅服务和企业销售，并计划积极扩充销售团队。</p>
</blockquote>
<p>据报道，AI 搜索初创公司 <strong>Perplexity</strong> 将从平台撤下广告，以维护用户信任，坚持“准确性企业”定位。该公司高管表示不会在聊天机器人答案中投放广告，未来将专注于订阅服务和企业销售。公司目前正锁定大型企业及财务、医疗等高端用户，企业销售计划积极扩张。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.ft.com/content/6eec07a5-34a8-4f78-a9ed-93ab4263d43c">https://www.ft.com/content/6eec07a5-34a8-4f78-a9ed-93ab4263d43c</a></li>
</ul>
<hr>
<h2><a href="https://www.worldlabs.ai/blog/funding-2026">World Labs完成融资并与Autodesk合作</a> <code>#11</code></h2>
<blockquote>
<p><strong>李飞飞</strong>创立的 <strong>World Labs</strong> 宣布完成 <strong>10亿美元</strong> 新一轮融资，<strong>AMD</strong> 和 <strong>英伟达</strong> 等巨头参投。与此同时，<strong>Autodesk</strong>向其投入 <strong>2亿美元</strong> 并达成战略合作，计划将 <strong>World Labs</strong> 的 <code>空间智能模型</code> 与自家的 <code>3D 工具</code> 相结合。</p>
</blockquote>
<p><strong>李飞飞</strong>创立的AI初创公司<strong>World Labs</strong>近日宣布完成<strong>10亿美元</strong>新一轮融资，本轮融资由<strong>AMD</strong>、<strong>Autodesk</strong>、<strong>NVIDIA</strong>等机构共同参与。<strong>World Labs</strong>致力于通过构建<code>World Models</code>来推进空间智能发展。</p>
<p>软件设计巨头<strong>Autodesk</strong>在本轮融资中投资了<strong>2亿美元</strong>，并与<strong>World Labs</strong>达成战略合作。双方初期将聚焦于媒体和娱乐领域，探索将<strong>World Labs</strong>的模型与<strong>Autodesk</strong>的<code>3D工具</code>及正在开发的新一代生成式AI模型<code>Neural CAD</code>相结合，旨在为设计、建筑及娱乐行业提供更高级的物理AI解决方案。据<strong>Autodesk</strong>首席科学家<strong>Daron Green</strong>称，合作尚处早期阶段，且双方协议明确不包含数据共享。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.worldlabs.ai/blog/funding-2026">https://www.worldlabs.ai/blog/funding-2026</a></li>
</ul>
<hr>
<h2><a href="https://arxiv.org/abs/2602.15763">智谱AI发布GLM-5技术报告</a> <code>#12</code></h2>
<blockquote>
<p><strong>智谱AI</strong>在arXiv发布了<code>GLM-5</code>技术报告。该模型采用<code>DSA架构</code>，并已适配<strong>7种</strong>国产芯片。官方宣称，通过<code>异步Agent RL基础设施</code>及<code>Slime RL工具包</code>等创新， <code>GLM-5</code> 在开源模型中实现了<code>SOTA性能</code>。</p>
</blockquote>
<p><strong>智谱AI</strong>近日在<strong>arXiv</strong>上发布<code>GLM-5</code>技术报告，详述其架构与训练细节。该模型采用<code>DSA</code>架构，拥有<strong>750B</strong>总参数与<strong>40B</strong>激活参数，训练数据量达<strong>30T</strong>，并已完成对<strong>7</strong>种国产芯片的适配。</p>
<p>报告揭示了多项核心创新。<code>DSA</code>架构旨在降低训练推理成本并保持长上下文保真度。模型引入<code>Slime RL</code>工具包与<code>异步Agent RL</code>基础设施，通过解耦生成与训练过程提升后训练效率。技术实现细节上，<code>GLM-5</code>的<code>RL</code>算法使用了带有双向<code>Token级掩码</code>的<code>GRPO</code>。为提升效率，系统采用<code>FP8</code>减少Token间延迟，实施平均接受长度为<strong>2.76</strong>的<code>多Token预测</code>，并利用<code>数据并行感知路由</code>最大化<code>KV-cache</code>复用。此外，<code>Prefill-Decode分离技术</code>可避免处理干扰。其<code>异步Agent RL</code>系统基于样本阈值更新模型，会主动丢弃过旧或崩溃环境的样本，并通过<code>Token-in Token-out</code>机制对齐推理与训练，<code>混合式奖励系统</code>则衡量基础正确性、情商与任务质量。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/f93b154d-a72b-4e76-8770-06eec166737e/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://arxiv.org/abs/2602.15763">https://arxiv.org/abs/2602.15763</a></li>
<li><a href="https://x.com/Zai_org/status/2023951884826849777">https://x.com/Zai_org/status/2023951884826849777</a></li>
</ul>
<hr>
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
<p>作者<code>橘鸦Juya</code>，视频版在同名<strong>哔哩哔哩</strong>。欢迎<strong>点赞、关注、分享</strong>。</p>
]]></content:encoded><guid isPermaLink="false">https://github.com/imjuya/juya-ai-daily/issues/2</guid><pubDate>Thu, 19 Feb 2026 01:57:23 +0000</pubDate></item><item><title>2026-02-18</title><link>https://imjuya.github.io/juya-ai-daily/issue-1/</link><description>AI 早报 2026-02-18 视频版：YouTube ｜ 哔哩哔哩 概览 精选 Anthropic 发布 Claude Sonnet 4.6 #1 xAI 上线 Grok 4.20 测试版 #2 NotebookLM推出幻灯片Prompt修订与PPTX导出 #3 模型发布 蚂蚁集团开源Ming-omni-tts音频生成模型 #4 Cohere Labs发布Tiny Aya多语言模型 #5 字节跳动研究团队开源 BitDance 多模态模型 #6 开发生态 Cursor 发布 2.5 版本更新，推出插件市场 #7 OpenAI修复GPT-5.3-Codex请求重定向问题 #8 Cerebras下调部分免费层级的推理额度 #9 Intelligent Internet 开源多Agent协作系统 Common…</description><content:encoded><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260218/202602180850442485579dde_cover_e48a.jpg" alt=""></p>
<h1>AI 早报 2026-02-18</h1>
<p><strong>视频版</strong>：<a href="https://www.youtube.com/watch?v=8jAigWfpDKU">YouTube</a> ｜ <a href="https://www.bilibili.com/video/BV1uAZDBiEKF">哔哩哔哩</a></p>
<h2>概览</h2>
<h3>精选</h3>
<ul>
<li>Anthropic 发布 Claude Sonnet 4.6 <code>#1</code></li>
<li>xAI 上线 Grok 4.20 测试版 <code>#2</code></li>
<li>NotebookLM推出幻灯片Prompt修订与PPTX导出 <code>#3</code></li>
</ul>
<h3>模型发布</h3>
<ul>
<li>蚂蚁集团开源Ming-omni-tts音频生成模型 <code>#4</code></li>
<li>Cohere Labs发布Tiny Aya多语言模型 <code>#5</code></li>
<li>字节跳动研究团队开源 BitDance 多模态模型 <code>#6</code></li>
</ul>
<h3>开发生态</h3>
<ul>
<li>Cursor 发布 2.5 版本更新，推出插件市场 <code>#7</code></li>
<li>OpenAI修复GPT-5.3-Codex请求重定向问题 <code>#8</code></li>
<li>Cerebras下调部分免费层级的推理额度 <code>#9</code></li>
<li>Intelligent Internet 开源多Agent协作系统 Common Ground Core <code>#10</code></li>
</ul>
<h3>行业动态</h3>
<ul>
<li>Nerve加入OpenAI构建ChatGPT搜索 <code>#11</code></li>
<li>传 Moonshot AI 完成7亿美元融资 <code>#12</code></li>
</ul>
<hr>
<h2><a href="https://www.anthropic.com/news/claude-sonnet-4-6">Anthropic 发布 Claude Sonnet 4.6</a> <code>#1</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 正式发布了 <code>Claude Sonnet 4.6</code> 模型。该模型在编程、长上下文推理及 <code>Agent</code> 规划能力上全面升级，并支持 <strong>100 万</strong> <code>token</code> 上下文。同步推出的还有改进版网页搜索工具，在提升准确率的同时大幅降低了 <code>Token</code> 消耗。目前，<code>Sonnet 4.6</code> 已上线 <code>API</code> 及各类AI应用，价格与上一代保持一致，免费版用户现已可在<strong>Claude</strong>体验。</p>
</blockquote>
<p><strong>Anthropic</strong> 正式发布 <code>Claude Sonnet 4.6</code>，官方称其为迄今最强的 <code>Sonnet</code> 模型。该模型在编程、长上下文推理、<code>Agent</code> 规划、知识工作及设计等领域全面升级，并提供支持 <strong>100 万</strong> token 的上下文窗口（<code>Beta版</code>）。价格维持每百万 token 输入 <strong>3</strong> 美元、输出 <strong>15</strong> 美元不变。</p>
<p>性能提升显著。在编程方面，根据 <code>Claude Code</code> 的早期测试，约 <strong>70%</strong> 的开发者更偏好 <code>Sonnet 4.6</code> 而非上代模型，<strong>59%</strong> 的用户选择它而非旗舰 <code>Opus 4.5</code>。用户反馈其在修改代码前能更有效阅读上下文，并减少“偷懒”行为。在计算机使用能力上，<code>OSWorld</code> 基准测试得分从 <strong>14.0%</strong> 大幅提升至 <strong>72.5%</strong>，能更有效地处理复杂电子表格和多步网页表单任务。据外部评估，<code>Sonnet 4.6</code> 在部分真实工作任务基准上略微优于 <code>Opus 4.6</code>。</p>
<p><strong>Anthropic</strong> 同步推出改进版 <code>Web Search</code> 和 <code>Web Fetch</code> 工具，通过 <code>代码执行</code> 对搜索结果进行动态过滤，官方数据显示平均准确率提升 <strong>11%</strong>，输入 Token 消耗减少 <strong>24%</strong>。<code>Sonnet 4.6</code> 现已上线 <code>API</code> 及各类AI应用，免费版 <strong>Claude</strong> 也可体验<code>Sonnet 4.6</code>。官方建议，对于大规模代码重构等超复杂任务，<code>Opus 4.6</code> 仍是最佳选择，但对多数任务，<code>Sonnet 4.6</code> 提供了极高性价比。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/37ae8237-3741-4ff4-950b-a7944f9f7c68/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/37ae8237-3741-4ff4-950b-a7944f9f7c68/m002.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/37ae8237-3741-4ff4-950b-a7944f9f7c68/m003.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.anthropic.com/news/claude-sonnet-4-6">https://www.anthropic.com/news/claude-sonnet-4-6</a></li>
<li><a href="https://claude.com/blog/improved-web-search-with-dynamic-filtering">https://claude.com/blog/improved-web-search-with-dynamic-filtering</a></li>
</ul>
<hr>
<h2><a href="https://x.com/elonmusk/status/2023828048580387001">xAI 上线 Grok 4.20 测试版</a> <code>#2</code></h2>
<blockquote>
<p><strong>xAI</strong> 上线了 <code>Grok 4.20</code> 公开测试版，该版本引入了由四个 <code>Agent</code> 组成的 <code>原生协作系统</code>，用于处理复杂查询。据 <strong>Elon Musk</strong> 称，该版本基于 <strong>5000 亿</strong>参数的 <code>V8</code> 模型，凭借快速学习与每周迭代，<strong>下个月</strong>测试结束时，其智能水平和速度预计将比 <code>Grok 4</code> 提升约一个数量级。</p>
</blockquote>
<p><strong>xAI</strong>上线了<code>Grok 4.20</code>公开测试版，用户需在应用内手动选择。据创始人<strong>Elon Musk</strong>透露，该模型并非单纯迭代，而是基于<strong>500B</strong>参数的<code>V8</code>小型基础模型构建。官方声明指出，<code>Grok 4.2</code>基础设施支持快速学习与每周更新，以实现“<code>递归智能增长</code>”。官方预计，在下个月测试版结束时，其智能水平和速度将比<code>Grok 4</code>提升约一个数量级。</p>
<p>该版本引入的原生<code>多Agent协作系统</code>是其核心亮点。据了解，该系统包含<code>Grok/Captain</code>、<code>Harper</code>、<code>Benjamin</code>和<code>Lucas</code> <strong>四个</strong> Agent，在处理复杂查询时自动运行。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/7078bb72-ab29-4eeb-9a0a-1c0a2666c81d/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/7078bb72-ab29-4eeb-9a0a-1c0a2666c81d/m002.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/7078bb72-ab29-4eeb-9a0a-1c0a2666c81d/m003.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/7078bb72-ab29-4eeb-9a0a-1c0a2666c81d/m004.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/elonmusk/status/2023828048580387001">https://x.com/elonmusk/status/2023828048580387001</a></li>
</ul>
<hr>
<h2><a href="https://x.com/NotebookLM/status/2023851190102986970">NotebookLM推出幻灯片Prompt修订与PPTX导出</a> <code>#3</code></h2>
<blockquote>
<p><strong>NotebookLM</strong> 发布重要更新，现在可以直接输入提示词来微调和修改幻灯片内容。同时，系统新增了 <code>PPTX</code> 导出支持，允许用户将生成的演示文稿直接下载为 <code>PPTX</code> 文件。这两项功能目前正在向 <strong>Ultra</strong> 和 <strong>Pro</strong> 会员推送。</p>
</blockquote>
<p><code>NotebookLM</code> 发布两项重要更新：<code>Prompt-Based Revisions</code> 与 <code>PPTX Support</code>，以回应用户强烈需求。</p>
<p>核心功能 <code>Prompt-Based Revisions</code> 允许用户通过 <code>Prompt</code> 描述直接对幻灯片进行调整、定制和微调。此外，<code>NotebookLM</code> 现已支持将生成的幻灯片导出为 <code>PPTX</code> 格式，官方透露 <strong>Google Slides</strong> 的支持即将推出。<code>NotebookLM</code> 正为 <code>Ultra</code> 和 <code>Pro</code> 会员推送这两项新功能：</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/a726e5fc-b654-42ea-9d19-ca3d11dc9ace/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/NotebookLM/status/2023851190102986970">https://x.com/NotebookLM/status/2023851190102986970</a></li>
</ul>
<hr>
<h2><a href="https://xqacmer.github.io/Ming-Flash-Omni-V2-TTS/">蚂蚁集团开源Ming-omni-tts音频生成模型</a> <code>#4</code></h2>
<blockquote>
<p><strong>蚂蚁集团</strong> <code>Inclusion AI</code> 开源了统一音频生成模型 <code>Ming-Omni-TTS</code>。该模型不仅能生成语音，还能合成音乐和环境音，包含 <strong>0.5B</strong> 和 <strong>16.8B-A3B</strong> 两个版本。</p>
</blockquote>
<p><strong>蚂蚁集团</strong> <strong>inclusionAI</strong> 开源统一音频生成模型 <code>Ming-omni-tts</code>，提供 <strong>0.5B</strong> 及 <code>16.8B-A3B</code> 两个版本。该模型是业界首个在单通道内联合生成语音、环境音和音乐的 <code>自回归模型</code>，通过定制 <strong>12.5Hz</strong> 连续 <code>Tokenizer</code> 实现了 <strong>3.1Hz</strong> 的高效推理帧率。官方评测显示，<code>Ming-omni-tts-16.8B-A3B</code> 在粤语生成、情感控制及零样本语音克隆等基准测试中达到 <code>SOTA</code> 水平，其文本规范化能力媲美 <code>Gemini-2.5 Pro</code>。模型权重及推理代码已上线 <strong>Hugging Face</strong>、<strong>ModelScope</strong> 及 <strong>GitHub</strong>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/ea284cf1-f5d6-42cf-a715-7f1e71cee91c/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://xqacmer.github.io/Ming-Flash-Omni-V2-TTS/">https://xqacmer.github.io/Ming-Flash-Omni-V2-TTS/</a></li>
<li><a href="https://github.com/inclusionAI/Ming-omni-tts">https://github.com/inclusionAI/Ming-omni-tts</a></li>
<li><a href="https://modelscope.cn/studios/antsipan/ming-uniaudio-demo">https://modelscope.cn/studios/antsipan/ming-uniaudio-demo</a></li>
</ul>
<hr>
<h2><a href="https://cohere.com/blog/cohere-labs-tiny-aya">Cohere Labs发布Tiny Aya多语言模型</a> <code>#5</code></h2>
<blockquote>
<p><strong>Cohere Labs</strong> 发布了名为 <code>Tiny Aya</code> 的多语言小型模型家族。该系列拥有 <strong>33.5 亿</strong> 参数，覆盖全球 <strong>70 多种</strong> 语言。</p>
</blockquote>
<p><strong>Cohere Labs</strong> 发布多语言小型模型家族 <code>Tiny Aya</code>。该系列包含 <strong>3.35B</strong> 参数基座模型及 <strong>4</strong> 个针对全球及特定区域（南亚、西亚/非洲、欧亚）优化的指令微调模型，覆盖 <strong>70+</strong> 种语言，侧重低资源语言支持。模型上下文 <strong>8K</strong>，采用 <code>CC-BY-NC</code> 协议，支持在笔记本电脑及手机端离线运行。官方指出模型擅长翻译与摘要，但在思维链推理任务上表现较弱。目前模型已在 <strong>Hugging Face</strong>、<strong>Kaggle</strong> 等平台开源，提供 <code>GGUF</code> 格式。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/88832ab7-c4cc-48f2-9407-70a7fc40e493/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://cohere.com/blog/cohere-labs-tiny-aya">https://cohere.com/blog/cohere-labs-tiny-aya</a></li>
<li><a href="https://github.com/Cohere-Labs/tiny-aya-tech-report/blob/main/tiny_aya_tech_report.pdf">https://github.com/Cohere-Labs/tiny-aya-tech-report/blob/main/tiny_aya_tech_report.pdf</a></li>
<li><a href="https://huggingface.co/collections/CohereLabs/tiny-aya">https://huggingface.co/collections/CohereLabs/tiny-aya</a></li>
</ul>
<hr>
<h2><a href="https://github.com/shallowdream204/BitDance">字节跳动研究团队开源 BitDance 多模态模型</a> <code>#6</code></h2>
<blockquote>
<p><strong>字节跳动</strong>研究团队发布了名为 <code>BitDance</code> 的开源多模态模型，参数量达 <strong>140 亿</strong>，该模型专为视觉生成优化，通过 <code>并行预测 Token</code>，推理速度比标准模型提升超过 <strong>30 倍</strong>。</p>
</blockquote>
<p><strong>字节跳动</strong>研究团队近日发布开源离散自回归多模态模型 <code>BitDance</code>，参数量为 <strong>14B</strong>。模型引入<code>大词汇量二元分词器</code>及<code>下一块扩散范式</code>，支持每步并行预测最多 <strong>64</strong> 个 <code>Token</code>，官方数据显示其比标准 <code>AR 模型</code>推理速度快 <strong>30 倍</strong>以上。</p>
<p>官方发布了 <code>BitDance-14B-64x</code> 和 <code>16x</code> 两个版本，配套 <code>UniWeTok</code> 分词器。在性能方面，<code>BitDance</code> 在 <code>DPG-Bench</code>（<strong>88.28</strong> 分）和 <code>GenEval</code>（<strong>0.86</strong> 分）上表现优异。目前，该模型代码与权重已在 <strong>GitHub</strong> 和 <strong>Hugging Face</strong> 开源（<code>Apache 2.0</code>），并提供在线演示，相关论文已发布于 <strong>arXiv</strong>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/a5632f31-cd75-4f9a-b20b-abc61940866e/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/shallowdream204/BitDance">https://github.com/shallowdream204/BitDance</a></li>
<li><a href="https://bitdance.csuhan.com/">https://bitdance.csuhan.com/</a></li>
<li><a href="https://huggingface.co/collections/shallowdream204/bitdance">https://huggingface.co/collections/shallowdream204/bitdance</a></li>
</ul>
<hr>
<h2><a href="https://cursor.com/changelog/2-5">Cursor 发布 2.5 版本更新，推出插件市场</a> <code>#7</code></h2>
<blockquote>
<p><strong>Cursor</strong> 发布了 <strong>2.5</strong> 版本更新，上线了 <strong>Cursor Marketplace</strong> 插件市场。首批整合了 <strong>Figma</strong>、<strong>Stripe</strong> 和 <strong>AWS</strong> 等工具。此外，<code>子智能体</code>现在支持<code>异步运行</code>与<code>树状协作</code>，<code>沙箱功能</code>新增了<code>细粒度访问控制</code>。</p>
</blockquote>
<p>近日，代码编辑器 <strong>Cursor</strong> 正式发布 <code>2.5</code> 版本，上线了 <code>Cursor Marketplace</code> 插件市场，并对核心 <code>Agent</code> 功能与 <code>沙盒</code> 安全机制进行了升级。</p>
<p>在扩展性方面，新版本引入统一<code>插件</code>机制，将 <code>Skills</code>、<code>Subagents</code>、<code>MCP servers</code> 等能力打包。<code>Cursor Marketplace</code> 已汇集 <strong>Linear</strong>、<strong>Figma</strong>、<strong>Stripe</strong>、<strong>AWS</strong> 等首批合作伙伴插件，覆盖设计、支付、部署及数据分析全流程。用户可通过网页或编辑器内 <code>/add-plugin</code> 命令直接安装。官方已开放插件提交入口，并发布了其内部 <code>CI</code> 和 <code>代码审查</code> 工作流模板 <code>Cursor Team Kit</code>，未来将推出支持统一治理的私有团队插件市场。</p>
<p>在 <code>Agent</code> 性能方面，<code>子智能体</code> 现已支持异步运行与树状层级协作，使<code>父智能体</code>可在后台执行任务，以更低的延迟处理大型重构或多文件任务。基于此，官方推出了具备自主规划与执行能力的 <code>长期运行智能体</code>，官方称在测试中已能生成更完整的 <code>PR</code> 并减少后续干预。</p>
<p>在安全与权限控制方面，<code>沙盒</code> 新增了对域名和本地文件系统的细粒度访问控制，提供 <code>仅用户配置</code>、<code>用户配置+默认值</code> 及 <code>允许全部</code> 三种模式。企业版管理员可通过 <code>管理控制台</code> 强制实施网络策略，确保组织级的出站访问安全。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/be845020-a5ba-43a5-a15f-fac997938c77/m001.png" alt=""></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/be845020-a5ba-43a5-a15f-fac997938c77/m002.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://cursor.com/changelog/2-5">https://cursor.com/changelog/2-5</a></li>
<li><a href="https://cursor.com/blog/marketplace">https://cursor.com/blog/marketplace</a></li>
</ul>
<hr>
<h2><a href="https://developers.openai.com/codex/concepts/cyber-safety">OpenAI修复GPT-5.3-Codex请求重定向问题</a> <code>#8</code></h2>
<blockquote>
<p>针对部分用户使用 <code>GPT-5.3-Codex</code> 却被路由至 <code>GPT-5.2</code> 的问题，<strong>OpenAI</strong> 称已修复相关 <code>Bug</code> 并校准了 <code>分类器</code>，同时在 <code>CLI</code> <strong>v0.102.0</strong> 版本中加入了显眼的降级通知功能。</p>
</blockquote>
<p><strong>OpenAI</strong> 将 <code>GPT-5.3-Codex</code> 定义为其 <strong>Preparedness Framework</strong> 下的首个**“高网络安全能力”**模型。鉴于网络能力具备支持防御性研究与潜在恶意滥用的双重用途属性，<strong>OpenAI</strong> 实施了包括<code>安全训练</code>和<code>自动监控</code>在内的多重防护措施，会将检测到的<code>可疑网络活动流量</code> <code>重路由</code>至网络能力较弱的 <code>GPT-5.2</code> 模型。</p>
<p>针对近期用户遭遇请求被意外降级的情况，<strong>OpenAI</strong> 团队成员承认，系统曾在特定时段出现<code>过度标记问题</code>，影响了约 <strong>9%</strong> 的用户。该问题已修复，团队通过<code>校准分类器</code>将预期受影响用户比例降至 <strong>1%</strong> 以下，并修复了<code>信任访问权限</code>未生效的 <code>Bug</code>。为提升透明度，<code>CLI v0.102.0</code> 版本已加入请求被降级时的<code>显眼通知</code>，并将在未来几天内扩展至所有客户端。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/01abe632-e2e8-4802-9ff8-8b94bfbd5b27/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://developers.openai.com/codex/concepts/cyber-safety">https://developers.openai.com/codex/concepts/cyber-safety</a></li>
<li><a href="https://x.com/embirico/status/2023891414623592653">https://x.com/embirico/status/2023891414623592653</a></li>
</ul>
<hr>
<h2><a href="https://inference-docs.cerebras.ai/models/overview">Cerebras下调部分免费层级的推理额度</a> <code>#9</code></h2>
<blockquote>
<p><strong>Cerebras</strong> 官方宣布，由于部分模型需求量激增，已暂时下调相关模型免费层级的 <code>速率限制</code>。</p>
</blockquote>
<p><strong>Cerebras</strong>官方宣布，因<code>zai-glm-4.7</code>和<code>qwen-3-235b-a22b-instruct-2507</code>模型需求激增，已暂时下调免费层级<code>速率限制</code>，正致力恢复原有设置。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/c0ebb726-a3e0-4afc-8ae0-a410a7df87ea/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://inference-docs.cerebras.ai/models/overview">https://inference-docs.cerebras.ai/models/overview</a></li>
</ul>
<hr>
<h2><a href="https://github.com/Intelligent-Internet/CommonGround">Intelligent Internet 开源多Agent协作系统 Common Ground Core</a> <code>#10</code></h2>
<blockquote>
<p><strong>Intelligent Internet</strong> 宣布开源 <code>多 Agent</code> 协作操作系统 <code>Common Ground Core</code>，这是一个协议优先的 <code>OS</code> 内核，旨在解决 <code>多 Agent 系统</code> 常见的上下文丢失等问题。</p>
</blockquote>
<p><strong>Intelligent Internet</strong> 团队近日开源 <code>多 Agent 协作操作系统</code> <strong>Common Ground Core (CGC)</strong>。该系统定位为 <code>协议优先的 OS 内核</code>，旨在解决 <code>多 Agent</code> 扩展时的 <code>上下文丢失</code>、<code>死锁</code> 及 <code>协调崩溃</code> 等问题。<strong>CGC</strong> 采用 <code>边缘自由、内核约束</code> 设计，利用 <strong>Postgres</strong> 维护 <code>不可变共享认知账本</code> 作为 <code>真理源</code>，通过 <strong>NATS</strong> 消除 <code>分布式消息重排序风险</code>。系统将人类视为与 AI 平等的 <code>异步节点</code>，支持介入协作。目前项目已在 <strong>GitHub</strong> 发布 <code>预览版</code>，提供 <strong>Docker</strong> 部署并集成 <strong>CardBox</strong> 状态模型。官方特别提示，当前版本 <code>API</code> 无认证且具备 <code>任意命令执行能力</code>，严禁直接暴露于 <code>公网</code>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/b928c84e-5235-405d-819a-51c14e1ad9d8/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/Intelligent-Internet/CommonGround">https://github.com/Intelligent-Internet/CommonGround</a></li>
<li><a href="https://ii.inc/web/blog/post/common-ground-core-cgc">https://ii.inc/web/blog/post/common-ground-core-cgc</a></li>
</ul>
<hr>
<h2><a href="https://www.usenerve.com/blog/joining-openai">Nerve加入OpenAI构建ChatGPT搜索</a> <code>#11</code></h2>
<blockquote>
<p>初创公司 <strong>Nerve</strong> 宣布加入 <strong>OpenAI</strong>，团队将致力于在更大规模上为 <strong>ChatGPT</strong> 构建搜索功能。</p>
</blockquote>
<p>企业级 <code>AI Agent</code> 初创公司 <strong>Nerve</strong> 官方宣布加入 <strong>OpenAI</strong>，旨在为 <code>ChatGPT</code> 构建更大规模的搜索功能。<strong>Nerve</strong> 过去 <strong>两年</strong> 专注于以搜索为核心的企业级 <code>Agent</code>，因认可 <strong>OpenAI</strong> 在 <code>信息检索</code> 领域的深度与雄心而决定加入。针对现有客户，<strong>Nerve</strong> 宣布产品将在 <strong>30 天后</strong> 正式关停，即日起暂停所有计费；未来 <strong>30 天内</strong> 服务将继续运行并提供支持，过渡期结束后将安全删除所有客户数据。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/970fab9f-d63e-4427-96e6-c64530e0cae8/m001.png" alt=""></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.usenerve.com/blog/joining-openai">https://www.usenerve.com/blog/joining-openai</a></li>
</ul>
<hr>
<h2><a href="https://mp.weixin.qq.com/s/MRx63AOgKZcn9ug8aSiH6w">传 Moonshot AI 完成7亿美元融资</a> <code>#12</code></h2>
<blockquote>
<p>据媒体报道，<strong>月之暗面</strong>完成<strong>7亿美元</strong>融资，<strong>阿里巴巴</strong>和<strong>腾讯</strong>参与投资，公司投后估值超过<strong>100亿美元</strong>。</p>
</blockquote>
<p>据媒体报道，<strong>Moonshot AI（月之暗面）<strong>完成</strong>7亿美元</strong>融资，投后估值超<strong>100亿美元</strong>。本轮融资由<strong>Alibaba</strong>与<strong>Tencent</strong>参与。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/MRx63AOgKZcn9ug8aSiH6w">https://mp.weixin.qq.com/s/MRx63AOgKZcn9ug8aSiH6w</a></li>
</ul>
<hr>
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
<p>作者<code>橘鸦Juya</code>，视频版在同名<strong>哔哩哔哩</strong>。欢迎<strong>点赞、关注、分享</strong>。</p>
]]></content:encoded><guid isPermaLink="false">https://github.com/imjuya/juya-ai-daily/issues/1</guid><pubDate>Tue, 17 Feb 2026 13:18:21 +0000</pubDate></item></channel></rss>